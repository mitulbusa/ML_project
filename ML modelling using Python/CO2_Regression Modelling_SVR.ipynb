{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 99.]\n",
      " [ 99.]\n",
      " [103.]\n",
      " [103.]\n",
      " [104.]\n",
      " [104.]\n",
      " [104.]\n",
      " [104.]\n",
      " [106.]\n",
      " [109.]\n",
      " [109.]\n",
      " [107.]\n",
      " [107.]\n",
      " [110.]\n",
      " [108.]\n",
      " [105.]\n",
      " [110.]\n",
      " [110.]\n",
      " [109.]\n",
      " [109.]\n",
      " [109.]\n",
      " [109.]\n",
      " [116.]\n",
      " [112.]\n",
      " [112.]\n",
      " [110.]\n",
      " [ 99.]\n",
      " [ 99.]\n",
      " [116.]\n",
      " [115.]\n",
      " [119.]\n",
      " [119.]\n",
      " [119.]\n",
      " [117.]\n",
      " [119.]\n",
      " [119.]\n",
      " [118.]\n",
      " [119.]\n",
      " [117.]\n",
      " [118.]\n",
      " [119.]\n",
      " [119.]\n",
      " [120.]\n",
      " [106.]\n",
      " [120.]\n",
      " [120.]\n",
      " [120.]\n",
      " [119.]\n",
      " [109.]\n",
      " [107.]\n",
      " [109.]\n",
      " [106.]\n",
      " [123.]\n",
      " [124.]\n",
      " [123.]\n",
      " [125.]\n",
      " [125.]\n",
      " [125.]\n",
      " [110.]\n",
      " [127.]\n",
      " [130.]\n",
      " [127.]\n",
      " [113.]\n",
      " [110.]\n",
      " [112.]\n",
      " [130.]\n",
      " [129.]\n",
      " [128.]\n",
      " [131.]\n",
      " [132.]\n",
      " [133.]\n",
      " [118.]\n",
      " [119.]\n",
      " [134.]\n",
      " [135.]\n",
      " [134.]\n",
      " [135.]\n",
      " [136.]\n",
      " [138.]\n",
      " [138.]\n",
      " [138.]\n",
      " [119.]\n",
      " [119.]\n",
      " [120.]\n",
      " [120.]\n",
      " [119.]\n",
      " [119.]\n",
      " [135.]\n",
      " [135.]\n",
      " [136.]\n",
      " [139.]\n",
      " [139.]\n",
      " [140.]\n",
      " [140.]\n",
      " [140.]\n",
      " [124.]\n",
      " [124.]\n",
      " [124.]\n",
      " [138.]\n",
      " [138.]\n",
      " [140.]\n",
      " [141.]\n",
      " [143.]\n",
      " [140.]\n",
      " [143.]\n",
      " [143.]\n",
      " [139.]\n",
      " [122.]\n",
      " [139.]\n",
      " [146.]\n",
      " [143.]\n",
      " [145.]\n",
      " [144.]\n",
      " [143.]\n",
      " [146.]\n",
      " [129.]\n",
      " [127.]\n",
      " [125.]\n",
      " [125.]\n",
      " [125.]\n",
      " [128.]\n",
      " [145.]\n",
      " [149.]\n",
      " [145.]\n",
      " [145.]\n",
      " [146.]\n",
      " [147.]\n",
      " [149.]\n",
      " [143.]\n",
      " [129.]\n",
      " [126.]\n",
      " [128.]\n",
      " [127.]\n",
      " [127.]\n",
      " [131.]\n",
      " [148.]\n",
      " [149.]\n",
      " [150.]\n",
      " [129.]\n",
      " [134.]\n",
      " [133.]\n",
      " [130.]\n",
      " [130.]\n",
      " [133.]\n",
      " [133.]\n",
      " [133.]\n",
      " [151.]\n",
      " [150.]\n",
      " [149.]\n",
      " [152.]\n",
      " [149.]\n",
      " [154.]\n",
      " [154.]\n",
      " [153.]\n",
      " [153.]\n",
      " [154.]\n",
      " [154.]\n",
      " [152.]\n",
      " [152.]\n",
      " [128.]\n",
      " [128.]\n",
      " [133.]\n",
      " [134.]\n",
      " [134.]\n",
      " [136.]\n",
      " [156.]\n",
      " [154.]\n",
      " [155.]\n",
      " [154.]\n",
      " [142.]\n",
      " [136.]\n",
      " [138.]\n",
      " [136.]\n",
      " [136.]\n",
      " [136.]\n",
      " [136.]\n",
      " [135.]\n",
      " [138.]\n",
      " [159.]\n",
      " [159.]\n",
      " [158.]\n",
      " [156.]\n",
      " [155.]\n",
      " [161.]\n",
      " [161.]\n",
      " [161.]\n",
      " [161.]\n",
      " [156.]\n",
      " [156.]\n",
      " [159.]\n",
      " [159.]\n",
      " [157.]\n",
      " [157.]\n",
      " [161.]\n",
      " [161.]\n",
      " [161.]\n",
      " [161.]\n",
      " [159.]\n",
      " [139.]\n",
      " [139.]\n",
      " [139.]\n",
      " [139.]\n",
      " [139.]\n",
      " [156.]\n",
      " [139.]\n",
      " [158.]\n",
      " [158.]\n",
      " [159.]\n",
      " [162.]\n",
      " [158.]\n",
      " [158.]\n",
      " [138.]\n",
      " [139.]\n",
      " [139.]\n",
      " [139.]\n",
      " [149.]\n",
      " [149.]\n",
      " [141.]\n",
      " [144.]\n",
      " [144.]\n",
      " [142.]\n",
      " [142.]\n",
      " [144.]\n",
      " [144.]\n",
      " [158.]\n",
      " [163.]\n",
      " [161.]\n",
      " [161.]\n",
      " [163.]\n",
      " [160.]\n",
      " [165.]\n",
      " [165.]\n",
      " [160.]\n",
      " [161.]\n",
      " [164.]\n",
      " [147.]\n",
      " [147.]\n",
      " [149.]\n",
      " [149.]\n",
      " [146.]\n",
      " [142.]\n",
      " [142.]\n",
      " [145.]\n",
      " [145.]\n",
      " [146.]\n",
      " [164.]\n",
      " [163.]\n",
      " [164.]\n",
      " [165.]\n",
      " [170.]\n",
      " [170.]\n",
      " [167.]\n",
      " [163.]\n",
      " [146.]\n",
      " [143.]\n",
      " [143.]\n",
      " [152.]\n",
      " [150.]\n",
      " [150.]\n",
      " [146.]\n",
      " [146.]\n",
      " [146.]\n",
      " [167.]\n",
      " [154.]\n",
      " [154.]\n",
      " [154.]\n",
      " [150.]\n",
      " [150.]\n",
      " [145.]\n",
      " [145.]\n",
      " [150.]\n",
      " [151.]\n",
      " [149.]\n",
      " [173.]\n",
      " [173.]\n",
      " [172.]\n",
      " [168.]\n",
      " [168.]\n",
      " [175.]\n",
      " [173.]\n",
      " [173.]\n",
      " [169.]\n",
      " [169.]\n",
      " [169.]\n",
      " [169.]\n",
      " [155.]\n",
      " [155.]\n",
      " [154.]\n",
      " [154.]\n",
      " [154.]\n",
      " [173.]\n",
      " [176.]\n",
      " [176.]\n",
      " [176.]\n",
      " [171.]\n",
      " [175.]\n",
      " [153.]\n",
      " [153.]\n",
      " [153.]\n",
      " [153.]\n",
      " [153.]\n",
      " [152.]\n",
      " [153.]\n",
      " [154.]\n",
      " [153.]\n",
      " [152.]\n",
      " [152.]\n",
      " [150.]\n",
      " [156.]\n",
      " [156.]\n",
      " [174.]\n",
      " [172.]\n",
      " [178.]\n",
      " [173.]\n",
      " [178.]\n",
      " [177.]\n",
      " [178.]\n",
      " [181.]\n",
      " [181.]\n",
      " [181.]\n",
      " [174.]\n",
      " [174.]\n",
      " [152.]\n",
      " [151.]\n",
      " [151.]\n",
      " [151.]\n",
      " [156.]\n",
      " [158.]\n",
      " [158.]\n",
      " [158.]\n",
      " [158.]\n",
      " [158.]\n",
      " [149.]\n",
      " [149.]\n",
      " [160.]\n",
      " [161.]\n",
      " [159.]\n",
      " [161.]\n",
      " [159.]\n",
      " [158.]\n",
      " [158.]\n",
      " [155.]\n",
      " [153.]\n",
      " [158.]\n",
      " [154.]\n",
      " [153.]\n",
      " [179.]\n",
      " [177.]\n",
      " [176.]\n",
      " [160.]\n",
      " [160.]\n",
      " [160.]\n",
      " [160.]\n",
      " [160.]\n",
      " [160.]\n",
      " [162.]\n",
      " [159.]\n",
      " [158.]\n",
      " [157.]\n",
      " [159.]\n",
      " [159.]\n",
      " [177.]\n",
      " [179.]\n",
      " [178.]\n",
      " [179.]\n",
      " [179.]\n",
      " [179.]\n",
      " [178.]\n",
      " [159.]\n",
      " [159.]\n",
      " [159.]\n",
      " [163.]\n",
      " [161.]\n",
      " [163.]\n",
      " [162.]\n",
      " [159.]\n",
      " [163.]\n",
      " [161.]\n",
      " [164.]\n",
      " [164.]\n",
      " [163.]\n",
      " [182.]\n",
      " [180.]\n",
      " [186.]\n",
      " [159.]\n",
      " [163.]\n",
      " [158.]\n",
      " [163.]\n",
      " [161.]\n",
      " [165.]\n",
      " [166.]\n",
      " [166.]\n",
      " [165.]\n",
      " [165.]\n",
      " [164.]\n",
      " [165.]\n",
      " [165.]\n",
      " [165.]\n",
      " [166.]\n",
      " [166.]\n",
      " [185.]\n",
      " [189.]\n",
      " [189.]\n",
      " [184.]\n",
      " [189.]\n",
      " [161.]\n",
      " [166.]\n",
      " [166.]\n",
      " [159.]\n",
      " [159.]\n",
      " [262.]\n",
      " [159.]\n",
      " [165.]\n",
      " [164.]\n",
      " [165.]\n",
      " [164.]\n",
      " [168.]\n",
      " [165.]\n",
      " [168.]\n",
      " [168.]\n",
      " [187.]\n",
      " [192.]\n",
      " [190.]\n",
      " [192.]\n",
      " [192.]\n",
      " [187.]\n",
      " [188.]\n",
      " [192.]\n",
      " [189.]\n",
      " [190.]\n",
      " [187.]\n",
      " [190.]\n",
      " [169.]\n",
      " [166.]\n",
      " [167.]\n",
      " [170.]\n",
      " [191.]\n",
      " [194.]\n",
      " [194.]\n",
      " [194.]\n",
      " [190.]\n",
      " [190.]\n",
      " [190.]\n",
      " [190.]\n",
      " [190.]\n",
      " [194.]\n",
      " [192.]\n",
      " [192.]\n",
      " [192.]\n",
      " [189.]\n",
      " [189.]\n",
      " [165.]\n",
      " [165.]\n",
      " [171.]\n",
      " [172.]\n",
      " [171.]\n",
      " [172.]\n",
      " [170.]\n",
      " [172.]\n",
      " [173.]\n",
      " [173.]\n",
      " [191.]\n",
      " [194.]\n",
      " [191.]\n",
      " [196.]\n",
      " [197.]\n",
      " [191.]\n",
      " [175.]\n",
      " [174.]\n",
      " [176.]\n",
      " [176.]\n",
      " [177.]\n",
      " [177.]\n",
      " [177.]\n",
      " [177.]\n",
      " [175.]\n",
      " [174.]\n",
      " [172.]\n",
      " [178.]\n",
      " [176.]\n",
      " [176.]\n",
      " [201.]\n",
      " [180.]\n",
      " [180.]\n",
      " [180.]\n",
      " [180.]\n",
      " [180.]\n",
      " [180.]\n",
      " [180.]\n",
      " [179.]\n",
      " [179.]\n",
      " [174.]\n",
      " [177.]\n",
      " [178.]\n",
      " [178.]\n",
      " [179.]\n",
      " [202.]\n",
      " [202.]\n",
      " [183.]\n",
      " [179.]\n",
      " [175.]\n",
      " [181.]\n",
      " [182.]\n",
      " [182.]\n",
      " [182.]\n",
      " [182.]\n",
      " [181.]\n",
      " [181.]\n",
      " [183.]\n",
      " [183.]\n",
      " [183.]\n",
      " [183.]\n",
      " [183.]\n",
      " [184.]\n",
      " [184.]\n",
      " [187.]\n",
      " [187.]\n",
      " [177.]\n",
      " [183.]\n",
      " [185.]\n",
      " [185.]\n",
      " [188.]\n",
      " [188.]\n",
      " [187.]\n",
      " [187.]\n",
      " [187.]\n",
      " [168.]\n",
      " [186.]\n",
      " [186.]\n",
      " [186.]\n",
      " [188.]\n",
      " [188.]\n",
      " [188.]\n",
      " [188.]\n",
      " [187.]\n",
      " [187.]\n",
      " [213.]\n",
      " [213.]\n",
      " [213.]\n",
      " [213.]\n",
      " [190.]\n",
      " [190.]\n",
      " [190.]\n",
      " [190.]\n",
      " [212.]\n",
      " [210.]\n",
      " [210.]\n",
      " [210.]\n",
      " [192.]\n",
      " [192.]\n",
      " [192.]\n",
      " [192.]\n",
      " [192.]\n",
      " [192.]\n",
      " [192.]\n",
      " [192.]\n",
      " [192.]\n",
      " [193.]\n",
      " [193.]\n",
      " [190.]\n",
      " [190.]\n",
      " [192.]\n",
      " [192.]\n",
      " [190.]\n",
      " [190.]\n",
      " [192.]\n",
      " [191.]\n",
      " [192.]\n",
      " [192.]\n",
      " [212.]\n",
      " [212.]\n",
      " [219.]\n",
      " [219.]\n",
      " [214.]\n",
      " [219.]\n",
      " [216.]\n",
      " [194.]\n",
      " [191.]\n",
      " [193.]\n",
      " [191.]\n",
      " [193.]\n",
      " [194.]\n",
      " [194.]\n",
      " [218.]\n",
      " [218.]\n",
      " [221.]\n",
      " [199.]\n",
      " [199.]\n",
      " [189.]\n",
      " [194.]\n",
      " [193.]\n",
      " [196.]\n",
      " [196.]\n",
      " [194.]\n",
      " [196.]\n",
      " [196.]\n",
      " [194.]\n",
      " [224.]\n",
      " [224.]\n",
      " [224.]\n",
      " [199.]\n",
      " [199.]\n",
      " [199.]\n",
      " [198.]\n",
      " [211.]\n",
      " [198.]\n",
      " [199.]\n",
      " [198.]\n",
      " [224.]\n",
      " [224.]\n",
      " [224.]\n",
      " [221.]\n",
      " [221.]\n",
      " [227.]\n",
      " [224.]\n",
      " [224.]\n",
      " [224.]\n",
      " [204.]\n",
      " [200.]\n",
      " [202.]\n",
      " [202.]\n",
      " [200.]\n",
      " [200.]\n",
      " [202.]\n",
      " [224.]\n",
      " [225.]\n",
      " [225.]\n",
      " [199.]\n",
      " [202.]\n",
      " [198.]\n",
      " [204.]\n",
      " [205.]\n",
      " [203.]\n",
      " [206.]\n",
      " [206.]\n",
      " [202.]\n",
      " [206.]\n",
      " [206.]\n",
      " [206.]\n",
      " [206.]\n",
      " [222.]\n",
      " [208.]\n",
      " [208.]\n",
      " [208.]\n",
      " [207.]\n",
      " [209.]\n",
      " [208.]\n",
      " [209.]\n",
      " [209.]\n",
      " [232.]\n",
      " [232.]\n",
      " [232.]\n",
      " [232.]\n",
      " [232.]\n",
      " [238.]\n",
      " [209.]\n",
      " [209.]\n",
      " [209.]\n",
      " [209.]\n",
      " [209.]\n",
      " [211.]\n",
      " [211.]\n",
      " [210.]\n",
      " [211.]\n",
      " [211.]\n",
      " [211.]\n",
      " [211.]\n",
      " [211.]\n",
      " [240.]\n",
      " [240.]\n",
      " [240.]\n",
      " [240.]\n",
      " [213.]\n",
      " [238.]\n",
      " [243.]\n",
      " [243.]\n",
      " [243.]\n",
      " [238.]\n",
      " [224.]\n",
      " [217.]\n",
      " [212.]\n",
      " [215.]\n",
      " [215.]\n",
      " [215.]\n",
      " [215.]\n",
      " [240.]\n",
      " [240.]\n",
      " [241.]\n",
      " [241.]\n",
      " [217.]\n",
      " [217.]\n",
      " [220.]\n",
      " [220.]\n",
      " [218.]\n",
      " [214.]\n",
      " [218.]\n",
      " [218.]\n",
      " [219.]\n",
      " [218.]\n",
      " [243.]\n",
      " [246.]\n",
      " [246.]\n",
      " [246.]\n",
      " [220.]\n",
      " [220.]\n",
      " [218.]\n",
      " [221.]\n",
      " [221.]\n",
      " [221.]\n",
      " [221.]\n",
      " [199.]\n",
      " [246.]\n",
      " [223.]\n",
      " [223.]\n",
      " [221.]\n",
      " [221.]\n",
      " [222.]\n",
      " [223.]\n",
      " [223.]\n",
      " [223.]\n",
      " [217.]\n",
      " [224.]\n",
      " [223.]\n",
      " [223.]\n",
      " [223.]\n",
      " [223.]\n",
      " [223.]\n",
      " [223.]\n",
      " [248.]\n",
      " [250.]\n",
      " [226.]\n",
      " [226.]\n",
      " [226.]\n",
      " [224.]\n",
      " [226.]\n",
      " [224.]\n",
      " [224.]\n",
      " [226.]\n",
      " [224.]\n",
      " [226.]\n",
      " [226.]\n",
      " [226.]\n",
      " [253.]\n",
      " [228.]\n",
      " [228.]\n",
      " [228.]\n",
      " [227.]\n",
      " [228.]\n",
      " [228.]\n",
      " [228.]\n",
      " [228.]\n",
      " [259.]\n",
      " [230.]\n",
      " [230.]\n",
      " [231.]\n",
      " [231.]\n",
      " [231.]\n",
      " [233.]\n",
      " [230.]\n",
      " [262.]\n",
      " [232.]\n",
      " [232.]\n",
      " [232.]\n",
      " [232.]\n",
      " [233.]\n",
      " [233.]\n",
      " [233.]\n",
      " [225.]\n",
      " [233.]\n",
      " [233.]\n",
      " [233.]\n",
      " [231.]\n",
      " [233.]\n",
      " [264.]\n",
      " [264.]\n",
      " [264.]\n",
      " [265.]\n",
      " [265.]\n",
      " [260.]\n",
      " [260.]\n",
      " [260.]\n",
      " [260.]\n",
      " [235.]\n",
      " [235.]\n",
      " [235.]\n",
      " [262.]\n",
      " [262.]\n",
      " [262.]\n",
      " [263.]\n",
      " [263.]\n",
      " [263.]\n",
      " [238.]\n",
      " [238.]\n",
      " [270.]\n",
      " [237.]\n",
      " [237.]\n",
      " [237.]\n",
      " [250.]\n",
      " [237.]\n",
      " [242.]\n",
      " [242.]\n",
      " [241.]\n",
      " [276.]\n",
      " [276.]\n",
      " [270.]\n",
      " [245.]\n",
      " [274.]\n",
      " [274.]\n",
      " [247.]\n",
      " [247.]\n",
      " [246.]\n",
      " [247.]\n",
      " [247.]\n",
      " [279.]\n",
      " [277.]\n",
      " [250.]\n",
      " [250.]\n",
      " [245.]\n",
      " [245.]\n",
      " [245.]\n",
      " [245.]\n",
      " [245.]\n",
      " [245.]\n",
      " [252.]\n",
      " [252.]\n",
      " [283.]\n",
      " [282.]\n",
      " [282.]\n",
      " [279.]\n",
      " [248.]\n",
      " [248.]\n",
      " [248.]\n",
      " [248.]\n",
      " [248.]\n",
      " [248.]\n",
      " [248.]\n",
      " [248.]\n",
      " [248.]\n",
      " [252.]\n",
      " [283.]\n",
      " [255.]\n",
      " [256.]\n",
      " [256.]\n",
      " [287.]\n",
      " [287.]\n",
      " [288.]\n",
      " [288.]\n",
      " [287.]\n",
      " [287.]\n",
      " [288.]\n",
      " [288.]\n",
      " [259.]\n",
      " [259.]\n",
      " [288.]\n",
      " [288.]\n",
      " [261.]\n",
      " [259.]\n",
      " [262.]\n",
      " [267.]\n",
      " [267.]\n",
      " [264.]\n",
      " [264.]\n",
      " [263.]\n",
      " [264.]\n",
      " [292.]\n",
      " [292.]\n",
      " [266.]\n",
      " [266.]\n",
      " [266.]\n",
      " [266.]\n",
      " [267.]\n",
      " [271.]\n",
      " [271.]\n",
      " [271.]\n",
      " [271.]\n",
      " [271.]\n",
      " [270.]\n",
      " [273.]\n",
      " [273.]\n",
      " [273.]\n",
      " [273.]\n",
      " [274.]\n",
      " [274.]\n",
      " [274.]\n",
      " [278.]\n",
      " [278.]\n",
      " [313.]\n",
      " [313.]\n",
      " [275.]\n",
      " [275.]\n",
      " [275.]\n",
      " [275.]\n",
      " [283.]\n",
      " [282.]\n",
      " [286.]\n",
      " [286.]\n",
      " [288.]\n",
      " [288.]\n",
      " [288.]\n",
      " [288.]\n",
      " [288.]\n",
      " [288.]\n",
      " [293.]\n",
      " [295.]\n",
      " [295.]\n",
      " [295.]\n",
      " [292.]\n",
      " [295.]\n",
      " [116.]\n",
      " [291.]\n",
      " [298.]\n",
      " [298.]\n",
      " [298.]\n",
      " [295.]\n",
      " [295.]\n",
      " [295.]\n",
      " [304.]\n",
      " [310.]\n",
      " [312.]\n",
      " [314.]\n",
      " [314.]\n",
      " [245.]\n",
      " [245.]\n",
      " [245.]\n",
      " [245.]\n",
      " [275.]\n",
      " [275.]\n",
      " [275.]\n",
      " [275.]\n",
      " [275.]\n",
      " [317.]\n",
      " [317.]\n",
      " [317.]\n",
      " [310.]\n",
      " [324.]\n",
      " [320.]\n",
      " [324.]\n",
      " [326.]\n",
      " [325.]\n",
      " [333.]\n",
      " [346.]\n",
      " [348.]\n",
      " [349.]\n",
      " [350.]\n",
      " [355.]\n",
      " [387.]\n",
      " [387.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Support Vecctor Regression\n",
    "#1 Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "#2 Importing the dataset\n",
    "#dataset = pd.read_csv(r'C:\\Users\\shubh\\Desktop\\IITM\\Courses\\Sem 2\\ML in civil eng\\term paper\\CE6051- vehicular emission data set - Sheet12.csv')\n",
    "dataset = pd.read_csv(r'C:\\Users\\shubh\\Desktop\\IITM\\Courses\\Sem 2\\ML in civil eng\\term paper\\CE6051- vehicular emission data set - Sheet20.csv')\n",
    "X = dataset.iloc[1:,0:5].values.astype(float)\n",
    "y = dataset.iloc[1:,9:10].values.astype(float)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4 Fitting the Support Vector Regression Model to the dataset\n",
    "# Create your support vector regressor here\n",
    "from sklearn.svm import SVR\n",
    "# most important SVR parameter is Kernel type. It can be linear,polynomial or gaussian.\n",
    "#SVR. We have a non-linear condition so we can select polynomial or gaussian but here\n",
    "#we select RBF(a gaussian type) while here I substituted it with 'linear' kernel. \n",
    "regressor = SVR(kernel='rbf')\n",
    "regressor.fit(X_train, y_train, sample_weight = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([229.58078236, 187.84408143, 167.92498149, 152.27366549,\n",
       "       179.40741104, 215.14824739, 225.88246929, 218.85122131,\n",
       "       143.35053388, 144.37785289, 247.50421902, 220.35048989,\n",
       "       239.70263447, 178.42240074, 169.69182114, 157.31619722,\n",
       "       208.85580949, 139.50855166, 239.22230393, 155.6718802 ,\n",
       "       240.44067092, 158.50116456, 225.65107717, 166.63622175,\n",
       "       135.30663636, 191.7779541 , 187.80189704, 176.16810968,\n",
       "       162.72288951, 186.18587087, 208.92626324, 231.89583218,\n",
       "       191.98100706, 215.20643669, 138.69236805, 179.315793  ,\n",
       "       192.72402781, 139.24431516, 165.2274101 , 221.67764127,\n",
       "       167.17124575, 233.32343857, 172.8335907 , 191.50330077,\n",
       "       183.4804635 , 160.42489524, 165.34660955, 164.51566039,\n",
       "       160.38000823, 229.80586667, 226.89324507, 228.12128648,\n",
       "       200.12990465, 168.12507399, 163.06921091, 222.37641675,\n",
       "       219.78861847, 179.98872394, 168.01386841, 136.34547291,\n",
       "       157.98526898, 214.64466258, 132.54376685, 210.70415809,\n",
       "       157.74559657, 226.88142132, 206.19337584, 234.51474952,\n",
       "       165.0548465 , 226.55432807, 133.52311418, 242.58150663,\n",
       "       165.0548465 , 205.47837331, 141.02776678, 228.32339442,\n",
       "       145.77207068, 234.44355877, 184.29966658, 156.98214003,\n",
       "       175.19870889, 210.19069049, 156.33612272, 144.01528144,\n",
       "       137.74415938, 234.28363712, 239.17801049, 156.16075242,\n",
       "       192.03435107, 195.64383608, 220.43660208, 191.73682425,\n",
       "       234.30724361, 211.61632043, 154.88023954, 213.01467022,\n",
       "       183.22405187, 159.5873979 , 143.07282017, 239.10065189,\n",
       "       193.128872  , 240.85110078, 170.01239563, 219.6299476 ,\n",
       "       153.47461575, 138.4379609 , 161.24624065, 159.35805961,\n",
       "       222.1698092 , 154.14386733, 222.91705842, 161.43922225,\n",
       "       136.01894857, 164.51566039, 162.06171714, 229.00544022,\n",
       "       230.87231685, 243.13313852, 233.00905716, 134.62303161,\n",
       "       221.5078858 , 235.13251637, 137.99063682, 230.65366917,\n",
       "       235.84967555, 244.32841123, 177.9796536 , 223.37378213,\n",
       "       227.72860363, 220.85331808, 191.7642937 , 167.6409582 ,\n",
       "       169.89980864, 196.01880349, 168.74524254, 223.77794365,\n",
       "       175.35958859, 227.14049012, 198.92090564, 175.19564318,\n",
       "       238.76934332, 232.7945094 , 230.74398813, 194.24179345,\n",
       "       220.8088022 , 196.59597271, 166.64493151, 207.73941502,\n",
       "       184.61200075, 197.95074879, 141.57717294, 165.94691899,\n",
       "       138.99270614, 216.07516787, 169.83018203, 225.83108936,\n",
       "       166.8048995 , 159.88558023, 151.01736052, 234.83610507,\n",
       "       178.94409357, 222.21768853, 225.60194074, 186.43719615,\n",
       "       146.99686978, 182.14252559, 184.34766331, 231.25009855,\n",
       "       238.29296958, 147.35207463, 217.96062951, 132.16156364,\n",
       "       231.76245888, 156.94235733, 155.48056072, 155.91663061,\n",
       "       131.99720276, 211.05250493, 166.78421937, 199.1420452 ,\n",
       "       172.11425295, 166.48194513, 213.23648033, 166.75088589,\n",
       "       150.17002462, 162.65528178, 179.49010395, 222.87545882,\n",
       "       150.57044036, 245.99548221])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, y_pred, color = 'black')\n",
    "plt.title('y_pred vs y_test')\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('y_pred')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "coef_ is only available when using a linear kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-219-9af10c4a7808>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#weight vector, slope\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mcoef_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcoef_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'linear'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m             raise AttributeError('coef_ is only available when using a '\n\u001b[0m\u001b[0;32m    466\u001b[0m                                  'linear kernel')\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: coef_ is only available when using a linear kernel"
     ]
    }
   ],
   "source": [
    "#weight vector, slope\n",
    "w = regressor.coef_\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7579353035266239"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.score(X, y, sample_weight = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([196.5525041])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept = regressor.intercept_\n",
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   5 4660   10  100   27]\n",
      "Predicted CO2 emissions: \n",
      " [242.71761691]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X.shape[1] = 5 should be equal to 6, the number of features at training time",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-38c06260d3bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Predicted CO2 emissions: \\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mNew_age\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNew_enginecapacity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNew_fuelconsumption\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNew_Noise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNew_fueltype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNew_gearbox\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Predicted CO2 emissions: \\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_new\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \"\"\"\n\u001b[1;32m--> 308\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    457\u001b[0m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[0;32m    458\u001b[0m                              \u001b[1;34m\"the number of features at training time\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m                              (n_features, self.shape_fit_[1]))\n\u001b[0m\u001b[0;32m    460\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X.shape[1] = 5 should be equal to 6, the number of features at training time"
     ]
    }
   ],
   "source": [
    "#New prediction with sklearn\n",
    "X_new = np.array([5,4660,10,100,27])\n",
    "print(X_new)\n",
    "New_age = 5\n",
    "New_enginecapacity = 4660\n",
    "New_fuelconsumption = 10\n",
    "New_Noise = 70\n",
    "New_fueltype = 100 \n",
    "New_gearbox = 27\n",
    "\n",
    "print('Predicted CO2 emissions: \\n', regressor.predict([[New_age, New_enginecapacity, New_fuelconsumption, New_Noise, New_fueltype, New_gearbox]]))\n",
    "print('Predicted CO2 emissions: \\n', regressor.predict([X_new]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[274.00781839],\n",
       "       [192.39074562],\n",
       "       [169.10183559],\n",
       "       [154.42455388],\n",
       "       [175.94047643],\n",
       "       [215.70764684],\n",
       "       [251.06910337],\n",
       "       [212.55203759],\n",
       "       [111.27341361],\n",
       "       [126.71277479],\n",
       "       [273.92136597],\n",
       "       [249.74237687],\n",
       "       [264.45665868],\n",
       "       [178.42674762],\n",
       "       [163.00602674],\n",
       "       [145.46046246],\n",
       "       [207.24188304],\n",
       "       [136.77699681],\n",
       "       [242.56254854],\n",
       "       [146.57410677],\n",
       "       [270.80598155],\n",
       "       [155.50656503],\n",
       "       [241.84595977],\n",
       "       [158.58318578],\n",
       "       [137.19211881],\n",
       "       [191.46516743],\n",
       "       [191.6361393 ],\n",
       "       [178.49646097],\n",
       "       [162.93440104],\n",
       "       [190.56467019],\n",
       "       [216.77279754],\n",
       "       [317.47608707],\n",
       "       [187.64845182],\n",
       "       [274.87541384],\n",
       "       [128.12293244],\n",
       "       [179.00883961],\n",
       "       [190.80064063],\n",
       "       [135.84813524],\n",
       "       [147.26961455],\n",
       "       [232.93133187],\n",
       "       [165.37150883],\n",
       "       [225.49278211],\n",
       "       [174.26357909],\n",
       "       [193.04458584],\n",
       "       [178.74760663],\n",
       "       [139.24564178],\n",
       "       [163.1806946 ],\n",
       "       [153.42144228],\n",
       "       [160.40696057],\n",
       "       [228.08370556],\n",
       "       [279.5197217 ],\n",
       "       [229.90515586],\n",
       "       [214.86194931],\n",
       "       [178.1866448 ],\n",
       "       [171.8689696 ],\n",
       "       [349.87542172],\n",
       "       [305.42642447],\n",
       "       [173.3479458 ],\n",
       "       [176.97642452],\n",
       "       [122.60119631],\n",
       "       [145.6452452 ],\n",
       "       [304.50558721],\n",
       "       [125.73530303],\n",
       "       [220.67395986],\n",
       "       [155.32550716],\n",
       "       [227.78871487],\n",
       "       [210.86642506],\n",
       "       [269.77061115],\n",
       "       [161.40702138],\n",
       "       [319.05766898],\n",
       "       [129.96818496],\n",
       "       [264.59183334],\n",
       "       [161.40702138],\n",
       "       [205.97948324],\n",
       "       [127.58925725],\n",
       "       [237.86678949],\n",
       "       [147.32676375],\n",
       "       [261.06896799],\n",
       "       [184.14848949],\n",
       "       [160.71351928],\n",
       "       [173.55046089],\n",
       "       [222.27296516],\n",
       "       [140.78651585],\n",
       "       [125.9637495 ],\n",
       "       [131.6619348 ],\n",
       "       [254.83133621],\n",
       "       [272.4572121 ],\n",
       "       [149.41721685],\n",
       "       [182.25359818],\n",
       "       [196.4812635 ],\n",
       "       [233.86019344],\n",
       "       [178.70566332],\n",
       "       [251.75606313],\n",
       "       [217.7429274 ],\n",
       "       [134.90480184],\n",
       "       [211.06572553],\n",
       "       [177.80720642],\n",
       "       [166.39421973],\n",
       "       [107.57458697],\n",
       "       [258.50122832],\n",
       "       [188.57731339],\n",
       "       [257.90875516],\n",
       "       [168.31870231],\n",
       "       [227.81493842],\n",
       "       [155.35341545],\n",
       "       [132.59079637],\n",
       "       [161.32297145],\n",
       "       [160.39410988],\n",
       "       [242.56679937],\n",
       "       [115.22627362],\n",
       "       [231.55874905],\n",
       "       [155.60160256],\n",
       "       [140.74932087],\n",
       "       [153.42144228],\n",
       "       [161.84084852],\n",
       "       [223.49750509],\n",
       "       [260.90184029],\n",
       "       [249.3562898 ],\n",
       "       [257.05954864],\n",
       "       [100.99925482],\n",
       "       [233.48632932],\n",
       "       [253.87250407],\n",
       "       [124.85505165],\n",
       "       [252.92682652],\n",
       "       [300.48441628],\n",
       "       [281.65481606],\n",
       "       [178.54090858],\n",
       "       [250.1402418 ],\n",
       "       [231.02047775],\n",
       "       [249.21138023],\n",
       "       [189.67909614],\n",
       "       [172.61461963],\n",
       "       [170.53166078],\n",
       "       [198.40357778],\n",
       "       [166.20226132],\n",
       "       [325.82118928],\n",
       "       [178.51658126],\n",
       "       [231.94933932],\n",
       "       [197.16503445],\n",
       "       [178.34904577],\n",
       "       [249.43507938],\n",
       "       [253.85568809],\n",
       "       [241.69661016],\n",
       "       [192.91708157],\n",
       "       [230.90586483],\n",
       "       [182.42767396],\n",
       "       [167.76684098],\n",
       "       [212.32259184],\n",
       "       [180.34594007],\n",
       "       [194.2124629 ],\n",
       "       [134.99884575],\n",
       "       [163.19354529],\n",
       "       [107.04336553],\n",
       "       [229.4759888 ],\n",
       "       [175.25222129],\n",
       "       [233.51792849],\n",
       "       [163.86291715],\n",
       "       [151.69574   ],\n",
       "       [153.77359838],\n",
       "       [299.41855803],\n",
       "       [169.19711668],\n",
       "       [259.10861226],\n",
       "       [225.67227393],\n",
       "       [177.66650932],\n",
       "       [141.27542883],\n",
       "       [187.92069301],\n",
       "       [190.43465342],\n",
       "       [253.45782316],\n",
       "       [252.06895595],\n",
       "       [148.84085371],\n",
       "       [219.21704263],\n",
       "       [123.22722152],\n",
       "       [299.07764252],\n",
       "       [149.62756059],\n",
       "       [153.75935456],\n",
       "       [157.13453446],\n",
       "       [123.64799165],\n",
       "       [224.38940615],\n",
       "       [152.18323106],\n",
       "       [203.66272583],\n",
       "       [164.88187684],\n",
       "       [176.10185153],\n",
       "       [216.83971153],\n",
       "       [174.49926515],\n",
       "       [140.79070399],\n",
       "       [163.41567661],\n",
       "       [179.46977015],\n",
       "       [231.37312321],\n",
       "       [151.63796916],\n",
       "       [274.3959584 ]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Multiple Linear Regression\n",
    "#6 Fit multiple Linear Regression model to our Train set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#Create an object called regressor in the LinearRegression class...\n",
    "regr = LinearRegression()\n",
    "#Fit the linear regression model to the training set... We use the fit method\n",
    "#the arguments of the fit method will be training sets \n",
    "regr.fit(X_train,y_train)\n",
    "\n",
    "#7 Predicting the Test set results: \n",
    "y_pred= regr.predict(X_test)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9676980630789437"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEXCAYAAABYsbiOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xuc3HV97/HXezcXWKhCJlER2Fm01JaqRYiIRVsqnoqpLb1oH7RLiEAfKxttYy+22j314DlnT6096omnDZAKErJzVLy0cnyk5YEotcdDwYARgpGaHndDlGo2yCXknCQkn/PH/CbM7s5v9je789udy/v5eMxjZ76/y3y/TJjPfO+KCMzMzGrpWewMmJlZ63KQMDOzVA4SZmaWykHCzMxSOUiYmVkqBwkzM0vlIGHWAEnXSRpb7HyYLRQHCbMOIOluSb/ThPtcLGlvM/JkncFBwrqWpCWLnQezVucgYS1J0nskfW5a2n+X9N9mue5uSX8u6T5JT0r6gqQVybEBSSHpGkl7gC8n6RdK+t+SnpD0TUkXV93vLEn/KOlpSXcCK+u89y5Jb6l6vUTSpKTzJJ0gaUzS/uR9vi7phc0ot6RR4PXAX0k6IOmvkvSflHSnpMclPSLpN6uuWSPpW0m5vifpjySdBPw98OLkPgckvbjef2/rAhHhhx8t9wBOA54BTkleLwF+CJw/y3V3A98DXg6cBHwOGEuODQAB3JocOxE4HdgPrKH8o+nfJa9XJdfcA3wEWA78HPB05X413vv9QKnq9S8B306evwP4n0Af0AucDzyvyeX+narXJwGPAlcl9zgPmAR+Ojn+GPD65PmpwHnJ84uBvYv9+fvROg/XJKwlRcRjwFeBtyVJlwKTEXF/hsu3RsTOiHgG+DPgNyX1Vh2/LiKeiYj/C1wBbIuIbRFxLCLuBLYDayT1A68G/iwiDkXEVyl/0af5H8CvSOpLXv92kgZwBCgAPx4RRyPi/oh4qsnlrvYWYDwiPhERz0bEA5QD5lur8nOOpOdFxI+S42YzOEhYK9tC+Uuc5O/WjNc9WvV8AljK1Gai6uNF4G1JE9ATkp4AXkf5F/2LgR8lwab6fjVFxG5gF/DLSaD4FZ4LEluBO4BPSfq+pA9JWppyq7mWu1oReM20cg0CL0qO/wbl2tNE0pz22jm8h3UBBwlrZX8HvFLSyyn/Mi5lvO7Mquf9lH81T1alVS99/CjlmscpVY+TIuKDlJtkTk3a6qvvV88ngd8CLgO+lQQOIuJIRHwgIs4BfjYpz5Up95hLuacv5/wo8I/TynVyRAwn+fl6RFwGvCB5v9tS7mNdzkHCWlZE/D/gs5R/jd8XEXsyXnqFpHOSX/P/EfhsRBxNOXeM8i//N0nqTTqYL5Z0RkRMUG56+oCkZZJeB/zyLO/9KeAXgWGeq0Ug6RckvSJp9nqKcuCqmac5lvsHwEuqXn8R+AlJayUtTR6vlvRTSVkGJT0/Io4k+TladZ+CpOdneE/rAg4S1uq2AK+gsSaXrcAtwL8BJwC/l3ZiRDxK+Vf/nwL7KP8Cfw/P/b/x28BrgMeB/0C50ztV0qdwD+XawqerDr2I8hf/U5SbpP6RcoBK02i5NwJvlfQjSR+LiKcpB6vLge9T/m/xF5Q74AHWAuOSngKuJWneiohvU64N/Z+kmcqjm7qcIly7tNaVdB5/G3hRrY7eGuffTXn00cfzzlueGi23WV5ck7CWJakH+APgU930Rdmt5bbW5Bmn1pKSzuIfUB5NdOm0YwdSLntz3vnK21zLHRH/lHferDu5ucnMzFK5ucnMzFI5SJiZWaq275NYuXJlDAwMLHY2zMzayv333z8ZEatmO6/tg8TAwADbt29f7GyYmbUVSalLzFRzc5OZmaVykDAzs1QOEmZmlspBwszMUuUaJJIVNe9LtoR8WNIHkvRbJH1X0o7kcW6SLkkfk7Rb0oOSzsszf2ZmVl/eNYlDwBsi4meAc4FLJV2YHHtPRJybPHYkaW8Gzk4eQ8D1OefPzKztlEolBgYG6OnpYWBggFIp61Yrjct1CGyU1/yorDezNHnUWwfkMuDW5Lp/lnSKpNOS5ZfNzLpeqVRiaGiIgwcPAjAxMcHQ0BAAg4ODTX+/3Pskko1cdlDezP3OiLg3OTSaNCl9VFJljfvTmbq15N4kzczMgJGRkeMBouLgwYOMjIzk8n65B4lk0/dzgTOAC5ItGd8H/CTlTeZXAH+SnK5at5ieIGlI0nZJ2/ft25dTzs3MWs+ePbU3KkxLn68FG90UEU8AdwOXRsRjUXYI+ARwQXLaXqbuT3wG5V21pt9rc0SsjojVq1bNOqvczKxj9PfX3mY9LX2+8h7dtErSKcnzE4E3At+WdFqSJuBXgZ3JJbcDVyajnC4EnnR/hJnZc0ZHR+nr65uS1tfXx+joaC7vl/faTacBW5LN33uA2yLii5K+LGkV5ealHZT32AXYBqwBdgMHgatyzp+ZWVupdE6PjIywZ88e+vv7GR0dzaXTGjpg06HVq1eHF/gzM2uMpPsjYvVs53nGtZmZpXKQMDOzVA4SZmaWykHCzMxSOUiYmVkqBwkzM0vlIGFmZqkcJMzMLJWDhJmZpXKQMDOzVA4SZmaWykHCzKyOhdwqtBXlvQqsmVnbWuitQluRaxJmZikWeqvQVuQgYWaWYqG3Cm1FDhJmZikWeqvQVuQgYWZdL61zeqG3Cm1F7rg2s66WpXN6obYKbUXevtTMutrAwAATExMz0ovFIuPj4zWvKZVKbR84sm5f6pqEmXW1Rjunu21YrPskzKyrNdo53W3DYh0kzKyrNdo53W3DYh0kzKyrDQ4OsnnzZorFIpIoFots3rw5temo24bFOkiYWdcbHBxkfHycY8eOMT4+XrdvoduGxTpImJk1oNGaR7vzEFgzsy6UdQisaxJmZpbKQcKsDXX7Hge2cBwkzNpMZTLXxMQEEXF8MtdiBwoHrs7kPgmzNjOXZSTyNn0WMpRH/HRyh267y9on4SBh1mZ6enqo9f+tJI4dO7YIOWrNwGX1tUTHtaQTJN0n6ZuSHpb0gST9LEn3SvqOpE9LWpakL09e706OD+SZP7N21IqTuRZjFrKbtxZG3n0Sh4A3RMTPAOcCl0q6EPgL4KMRcTbwI+Ca5PxrgB9FxI8DH03OM7MqrTiZq9mBa7YAMFu/jANIE0XEgjyAPuAB4DXAJLAkSX8tcEfy/A7gtcnzJcl5qnff888/P8y6zdjYWBSLxZAUxWIxxsbGFj0/fX19ARx/9PX1zSlfWe5VLBanHK88Kv8tmpWXTgZsjyzf3VlOms8D6AV2AAco1wxWArurjp8J7Eye7wTOqDr2r8DKGvccArYD2/v7+/P6b2hmDWhW4KoXACok1Tyn8t6zXW/Zg8SCdVxLOgX4W+D9wCei3KSEpDOBbRHxCkkPA2+KiL3JsX8FLoiI/Wn3dce1WWfJ0jFfr6N8z549Ldex34paouO6WkQ8AdwNXAicIqmy4dEZwPeT53sp1yxIjj8feHyh8mhmiy9L/0a9fplW7NhvZ3mPblqV1CCQdCLwRmAX8BXgrclp64AvJM9vT16THP9yLFRVx8xaQpaO+XqL7LVix35by9ImNdcH8ErgG8CDlPsb3p+kvwS4D9gNfAZYnqSfkLzenRx/yWzv4Y5rs84z3/6NVuvYb0W0Wp9EXtwnYWbWuJbrkzAzs/bjIGFmZqkcJMzMLJWDhJmZpXKQMDOzVA4SZmaWykHCzBaNV2ttfUtmP8XMrPmm72ZXWe4b8G52LcQ1CTNrikZrBSMjI1O2OwU4ePAgIyMjeWbTGuSahJnN21xqBYuxm501zjUJM5u3udQKvFpre3CQMLN5m0utwKu1tgcHCTOrq15fw/r161myZEnNTX4AVqxYkXrfest9W+vwKrBmlmp6XwOUf+2vW7eOW2+9lWeeeabu9YVCgcnJybyzaXOQdRVYBwkzS5W2Taik1NrD9PO8ZWhr8lLhZjZvaX0KWX9cNtIJ7Yl1rclBwsxSzWekUSOd0JVmrYmJCSLi+BBaB4rF5yBhZqlqjUDKotFOaE+sa10OEmaWqtYIpHqGh4eJCMbHxxsapeSJda3LQcLM6hocHGR8fJxjx44xPj6eGiiKxSKbNm2a03t4Yl3rcpAwsymqO5BXrlzJypUrp3Qm5zEJzhPrWpeDhJkdN70Def/+/ezfv39KZzLQ9ElwnljXujxPwsyOS5sXUa1YLDI+Pj6n+5dKJUZGRtizZw/9/f2Mjo46ECySrPMkvAqsmR2XpaN4tiCSxvtHtCc3N5l1qVqT17J0FEua0/wFD3NtTw4SZl2kEhgksXbt2hmT19asWTPrvIiImNMXu4e5ticHCbMuUd0pDTOX1jh48CCbN2+e8Wu/lrl8sXuYa3tykDDrAqVSiXXr1s0aAI4ePZrpfnP5Yvcw1/bkIGHWhqb3J6xfvz51cbxKDSJrAJjNXL/YPcy1PXkIrFmbKZVKXH311Rw+fDj1nL6+vuNfwFmGtWZVKBTYuHGjv9g7QEssFS7pTElfkbRL0sOSNiTp10n6nqQdyWNN1TXvk7Rb0iOS3pRn/sza0YYNG+oGCCj3L2zYsGHWACEp03sWi0XGxsaYnJx0gOgyec+TeBb4w4h4QNKPAfdLujM59tGI+K/VJ0s6B7gc+GngxcCXJP1ERDSnnmzWAfbv35/5vHrn9vb2MjQ0xJYtW+r2VUia8+Q5a3+51iQi4rGIeCB5/jSwCzi9ziWXAZ+KiEMR8V1gN3BBnnk060Z9fX1s2bKFbdu2zdqZ7dFH3W3BOq4lDQCvAu5Nkt4l6UFJN0s6NUk7HXi06rK91A8qZtag6g7j2YayevSRLUiQkHQy8Dng3RHxFHA98FLgXOAx4MOVU2tcPqNnXdKQpO2Stu/bty+nXJt1nsq6S5V+hXq1BI8+MliAICFpKeUAUYqIzwNExA8i4mhEHAP+huealPYCZ1Zdfgbw/en3jIjNEbE6IlavWrUq3wKYdYhatYK0uQtjY2MNbxxknSnv0U0CbgJ2RcRHqtJPqzrt14CdyfPbgcslLZd0FnA2cF+eeTRrN4VCoeFr0moFnrtgs8m7JnERsBZ4w7Thrh+S9JCkB4FfAH4fICIeBm4DvgX8A/BOj2yyblRr8b2KjRs3smzZskz3yVIrmL7zHJD63taFIqKtH+eff36YdZKxsbHo6+sLyv1xAcTSpUujUCiEpCgWizE8PBzFYjEkRaFQiJNOOun4uT09PQFEsViMsbGxeb93X19fw/ex1gdsjwzfsZ5xbdZissyQrp5RPX2fhunHm/He89loyFpT1hnXdYOEpIeoMbqoIiJeObfsNY+DhHWanp6eGSu01lL54m7mF3vae0vi2LFjDd3LWluzdqZ7S/L3ncnfrcnfQWD29YTNrGH9/f2Z1lqqzHFo5j4Nae/tCXXdq27HdURMRMQEcFFE/HFEPJQ83gt4XSWzHNQallrLihUrgObu0+DlvG26rKObTpL0usoLST8LnJRPlsy62/RhqT099f83beYXu4fE2gxZereB84FvAuPAd4EdwHlZrs374dFN1q7GxsaOj1BKG4k0PDw8ZaRR9UNSQ/cyq0Yeo5skPY9yZ/eTTYxT8+KOa2tHWUYkrV+/nuuvvz71Hh5xZPPR1P0kJL1Q0k3ApyPiSUnnSLpm3rk060D1JsJVjIyMzFh9tbIHRMWNN95Y930OHDjgiW6Wu6x9ErcAd1De4wHgX4B355Ehs3ZWqSFMTEwQEUxMTDA0NDRje9G00Uv79+8//sU/25DT/fv3MzQ05EBhucrU3CTp6xHxaknfiIhXJWk7IuLc3HM4Czc3WStJCwCSMs19gPLaTJOTkw3tGudmJ2tUs7cvfUZSgWRinaQLgZbplzBrFWlzExrp+6vsJnfSSdkGEM5lPoRZVlmDxB9QXqH1pZK+BtwK/G5uuTJrU1m/2LO48cYbZx3+Cp7oZvmadY9rST3ACcDPAy+jvDHQIxFxJOe8mbWVUqnEgQMH5n2fylLglVFOIyMj7NmzhxUrVvD0009z+PDh4+d6opvlbdafKVHeGOjDEfFsRDwcETsdIKxb1Ru5NDIy0pT32Lhx4/Hn1ct4T05OcvPNN3uimy2orB3XHwAeBD4fjTSuLgB3XNtCmW1uQ9aF+eqpdFqb5a3ZHdd/AHwGOCzpKUlPS3pqXjk0azNpcxsqNYhG+wamj17q6+ubUoswawWZgkRE/FhE9ETE0oh4XvL6eXlnzqyVzLbaataF+Soiwk1H1vJm7biukPTrwOsoD4P9p4j4u9xyZdaC0pbR7unpoaenh/7+ftatW8e2bdsyLfXd29vr+Q3W8rIuy7EJuBZ4CNgJXCvpr/PMmFmrSaspHD169Pjs6i1btrBmzRp6e3tnvd/Ro96+3Vpf1prEzwMvr3RaS9pCOWCYdY3pQ1Jh5iS5gwcP1l2Ur1qxWGxuBs1ykLXj+hGgulfuTMqjncy6SmVI6tatW+c1ksnzG6xdZA0SBWCXpLsl3Q18C1gl6XZJt+eWO7MWNZc5Ee6ktnaUtbnp/bnmwqxFlEql481J/f39jI6OMjg4OCM9S8f0dO6ktnbU0KZDqTeR7omI1zYhPw3zZDprlvXr13PDDTdMaUZaunQpy5Yt45lnnplybiOrula02DxU63JZJ9NlHgI7ixOadB+zRVEqlWYECIAjR45w5MjMVWga/cKvrMdk1m6y9knMxj+RrK2NjIzM6Zd+9Zd/oVBgeHiYZcuWTTln2bJlnkltbatZNQmztlUqlebUx5C22c9FF11Us1/DrB1lnUz3Lkmn1julSfkxy02tFVwri/Y1qt4Q1uqVW8fHxx0grK1lrUm8CPi6pAeAm4E7pq0Gu7bpOTNroukruFb2nj7xxBNnLNpXrbe3d8bM6EKhwMaNG/3lb10h6wJ//x44G7gJeDvwHUn/RdJLk+M7c8uhWROkreBa2Sq0lkKhwNDQ0JT5DWNjY0xOTjpAWNfI3CcRESHp34B/A54FTgU+K+nOiPjjvDJo1gxz2Qd6//79bNmyxRPfrKtl7ZP4PUn3Ax8Cvga8IiKGgfOB36hz3ZmSviJpl6SHJW1I0ldIulPSd5K/pybpkvQxSbslPSjpvHmX0Iz0vR4KhULd5b2r94sw60ZZh8CuBH49It4UEZ+pbF+abG36ljrXPQv8YUT8FHAh8E5J5wDvBe6KiLOBu5LXAG+m3Kx1NjAEZFspzWwWtVZwrWzys3nz5rqL7c2lFmLWKbL2Sbw/ImqOEYyIXXWueywiHkiePw3sAk4HLgO2JKdtAX41eX4ZcGuU/TNwiqTTMpXEbJrq0UwjIyOsW7eu5vpJldFIaYGi0R3nzDpJsybTzUrSAPAq4F7ghRHxGJQDCfCC5LTTgUerLtubpJk1pFQqcdVVVzExMXF8r4ePf/zjjI6Opg5NTatteLVW62YLEiQknQx8Dnh3RNTbG7vWfIsZ02AlDUnaLmn7vn37mpVN6xClUom1a9fOWE7jyJEjbNiwIfW6wcHB401PXq3VrCz3ICFpKeUAUYqIzyfJP6g0IyV/f5ik76W8V0XFGcD3p98zIjZHxOqIWL1q1ar8Mm8tqdakuOpjQ0NDqUts1BvyCp4IZzZdrkFCkijPrdgVER+pOnQ7sC55vg74QlX6lckopwuBJyvNUmbwXBCobka6+uqrWblyJT09Paxbt67u5Dgza0zeazddRHk29kOSdiRpfwp8ELhN0jXAHuBtybFtwBpgN3AQuCrn/FmbqTUp7vDhw8drCLPtG+3VWM0ak2uQiIj/Rfq6TpfUOD+Ad+aZJ2tPlU1/5rIQX4VXYzVrnFeBtZY3fd2lufB6S2Zzs2BDYM3molQqzamfobe31+stmTWBaxLWskqlEldfffWs/QzT9fX1eeiqWZO4JmEta8OGDRw+fLihazy3way5HCSspVTPgZhtTsN0hULBcxvMmszNTdYy5tNB7ZFLZvlwTcIWxfr161myZAmSWLJkCevXr685ByKLQqHAzTff7BqEWQ5ck7AF98Y3vpG77rrr+OujR49y/fXZVoXv6enh1FNP5fHHH6e/v5/R0VEHB7McOUjYgiqVSlMCRBa9vb0cO3bMQcFsEbi5yXKRtghfo7u89fX1sWXLFi+4Z7ZIXJOwppveAT0xMcHQ0BBf+9rXGlpWo1gsuuZgtsiUtqRyu1i9enVs3759sbNhVQYGBmoGA0mpS3hP19vby7PPPtvsrJlZQtL9EbF6tvPc3GRNl7YndCM/SBqdZW1m+XCQsKZbsWLFvO/R29vbhJyY2Xw5SFhTVDqqJTU8U7qWoaGhJuTKzObLHdc2b81Yyrva8PAwmzZtasq9zGx+HCRsXipLeTejD2FsbMwjmcxajJubbM7Wr1/P2rVr5x0gJDE8POwAYdaCHCRsTkqlEjfccENDI5aqFQqF45sCbd261c1LZi3KzU2WWalUYsOGDfPqmJbEtdde66Bg1iYcJCyTUqnEVVddxZEjR+Z8D+8zbdZ+3NxkM1QPZ60s533FFVc0HCAkAXifabM25pqETTF9OOtcO6VdazDrDA4SNsVcN/6pVigUmJycbFKOzGwxubnJpkhbdymrvr4+byNq1kEcJGyK/v7+OV9bLBbZvHmzm5jMOoiDRBertTHQ6OjonO5VKBS8KZBZB3KfRJcolUqMjIywZ88e+vv7WbNmDTfddBOHDx8GyhsDXXHFFRQKBZYvX86hQ4caur+bmMw6k4NEF6i1U9z1119f89y5TJTzkhpmncvNTV2gGSOWaikUCoyNjXn2tFkHc02iCzSyr3RWXs7brDvkWpOQdLOkH0raWZV2naTvSdqRPNZUHXufpN2SHpH0pjzz1k0qM5+badu2bU2/p5m1nrybm24BLq2R/tGIODd5bAOQdA5wOfDTyTWbJHkPyzmqXlpjriu11jPf+RRm1h5yDRIR8VXg8YynXwZ8KiIORcR3gd3ABbllrgNVB4a1a9fOqZmpUChkOm8+8ynMrH0sVsf1uyQ9mDRHnZqknQ48WnXO3iTNMqiMYKoEhrnUHpYvX87GjRsZHh6u20TV19c35/kUZtZeFiNIXA+8FDgXeAz4cJJe61up5jedpCFJ2yVt37dvXz65bDPNGMF06NAh3v72t3PRRRexdetWisUikigUClM2CfKsarPuoTzaq6e8gTQAfDEiXl7vmKT3AUTEnyfH7gCui4h76t1/9erVsX379ibnuv309PQ0re+hWCwyPj7elHuZWWuSdH9ErJ7tvAWvSUg6rerlrwGVkU+3A5dLWi7pLOBs4L6Fzl+7amYfgTulzawi7yGwnwTuAV4maa+ka4APSXpI0oPALwC/DxARDwO3Ad8C/gF4Z0TMbTODLjQ6OkpfX9+UtLkOfXWntJlV5D266bci4rSIWBoRZ0TETRGxNiJeERGvjIhfiYjHqs4fjYiXRsTLIuLv88xbK6q14F6W8yWxbt26KX0Svb29XHvttUQExWKxoXy4U9rMjouItn6cf/750QnGxsair68vKHfWBxB9fX0xNjZW8/zh4eGQNOX86Y/K9bXuvXTp0ujp6ZlxzfDw8AKX3MwWA7A9MnzHLvqX/HwfnRIkisVizS/6YrE449yxsbFZA8T068fGxqJYLIakKBaLx4PH9DQz6w5Zg0Tuo5vy1imjm9JGJ0ni2LFjU5b67unpybz3dOV6M7NqLTu6yWpL6yzu7++nVCpx1VVXMTExQURkDhD17mtmloWDRIuoNTqpMrN5w4YNHDlypOF7ema0mc2Xg0SLGBwcZPPmzcdnOReLRdatW8fIyEhDGwH19pbXRPTMaDNrBvdJtKhSqcTVV199fHvRrNr98zSzheE+iTZUPU/iyiuvbDhAmJk1m3emaxHT96GeS40g6zLfZmZZuSbRIhpZxbVQKBzve5hutlnaZmaNcJDISaNLbGTdIKhQKDA5OcmWLVtm1Bz279/P0NCQA4WZNY2DRA6qNwCKCCYmJqZ8edcKIGk1g2pLly5l48aNQHk01MknnzzjnIMHDzIyMtLcAplZ1/LophwMDAzUrBkUi0VGR0en9D1AeT5DvaYmSfT39zM6OjplSOtss7TNzNJkHd3kjuscpDUdTUxMsGHDhhkBoV6A6O3t5dlnn615rL+/v+Z7eZa1mTWLm5sWWCMT44C6S3DUm6VtZtYMDhItIq1Pot5eELVmaXuWtZk1k4NEixgaGppTrWBwcJDx8XGOHTvG+Pi4A4SZNZWDRA56ehr7z1ooFNi0aZNrBWbWchwkcvCOd7yjZvoll1xSs7ZQPazVtQIzayUOEjnYtGkTl1xyyZS0Sy65hC996UuuLZhZW/EQ2ByUSiXuueeeKWn33HMPpVKJwcFBBwUzaxuuSeSg1jpMngltZu3IQWIWja7BBLBnz56G0s3MWpWDRB2zrcGUpt5+1WZm7cRBoo65Nht5JrSZdQoHiRSlUil1DabZmo08E9rMOoVXga1SKpUYGRlhYmICSam7wxWLRcbHx5vynmZmi8GrwDYo6/ahbjYys27i5qZE1u1D3WxkZt3EQSKRZXhqsVh0gDCzrtKVQaLW3IfZhqe6mcnMulGuQULSzZJ+KGlnVdoKSXdK+k7y99QkXZI+Jmm3pAclnZdHntLmPqxZs2bGsFVJAB6dZGZdK++axC3ApdPS3gvcFRFnA3clrwHeDJydPIaA6/PIUNrch23bts0Ytrp161YiwiuymlnXyn0IrKQB4IsR8fLk9SPAxRHxmKTTgLsj4mWSbkyef3L6efXu3+gQ2J6enpojlyRx7NixzPcxM2tnWYfALkafxAsrX/zJ3xck6acDj1adtzdJm0HSkKTtkrbv27evoTf3khlmZtm1Use1aqTVrOZExOaIWB0Rq1etWtXQm3jJDDOz7BYjSPwgaWYi+fvDJH0vcGbVeWcA32/2m3vJDDOz7BYjSNwOrEuerwO+UJV+ZTLK6ULgydn6I+bK24SamWWT67Ickj4JXAyslLQX+A/AB4HbJF0D7AHelpy+DVgD7AYOAlflmTczM5tdrkEiIn4r5dAl0xOiPOTonXnmx8zMGtNKHddmZtZiHCTMzCyVg4SZmaVq+02HJO0Dam++By++AAAFn0lEQVQhl91KYLIJ2WkX3VZe6L4yd1t5wWVuVDEiZp1o1vZBohkkbc8yPb1TdFt5ofvK3G3lBZc5L25uMjOzVA4SZmaWykGibPNiZ2CBdVt5ofvK3G3lBZc5F+6TMDOzVK5JmJlZKgcJMzNL1fFBohX32c5bSpmvk/Q9STuSx5qqY+9LyvyIpDctTq7nTtKZkr4iaZekhyVtSNI79nOuU+aO/JwlnSDpPknfTMr7gST9LEn3Jp/xpyUtS9KXJ693J8cHFjP/c1GnzLdI+m7VZ3xukp7Pv+uI6OgH8HPAecDOqrQPAe9Nnr8X+Ivk+Rrg7ylvgHQhcO9i57+JZb4O+KMa554DfBNYDpwF/CvQu9hlaLC8pwHnJc9/DPiXpFwd+znXKXNHfs7JZ3Vy8nwpcG/y2d0GXJ6k3wAMJ8/XAzckzy8HPr3YZWhimW8B3lrj/Fz+XXd8TSIivgo8Pi35MmBL8nwL8KtV6bdG2T8Dp1Q2SGonKWVOcxnwqYg4FBHfpbxU+wW5ZS4HEfFYRDyQPH8a2EV569uO/ZzrlDlNW3/OyWd1IHm5NHkE8Abgs0n69M+48tl/FrhEUq3dL1tWnTKnyeXfdccHiRTz3me7Tb0rqYbeXGl6ocPKnDQrvIryr66u+JynlRk69HOW1CtpB+XdLO+kXBt6IiKeTU6pLtPx8ibHnwQKC5vj+Zte5oiofMajyWf8UUnLk7RcPuNuDRJpMu+z3YauB14KnAs8Bnw4Se+YMks6Gfgc8O6IeKreqTXSOqXMHfs5R8TRiDiX8tbGFwA/Veu05G/blxdmllnSy4H3AT8JvBpYAfxJcnouZe7WILGo+2wvhoj4QfIP7hjwNzzX1NARZZa0lPKXZSkiPp8kd/TnXKvMnf45A0TEE8DdlNvdT5FU2TytukzHy5scfz7Zm2BbTlWZL02aGiMiDgGfIOfPuFuDxKLvs73QprVN/hpQGfl0O3B5MhrkLOBs4L6Fzt98JG3NNwG7IuIjVYc69nNOK3Onfs6SVkk6JXl+IvBGyv0wXwHempw2/TOufPZvBb4cSe9uu0gp87erfviIch9M9Wfc/H/Xi92Dn/cD+CTlavcRypH2Gsptk3cB30n+rojnRhP8NeW2zoeA1Yud/yaWeWtSpgeTf0ynVZ0/kpT5EeDNi53/OZT3dZSr1Q8CO5LHmk7+nOuUuSM/Z+CVwDeScu0E3p+kv4RysNsNfAZYnqSfkLzenRx/yWKXoYll/nLyGe8ExnhuBFQu/669LIeZmaXq1uYmMzPLwEHCzMxSOUiYmVkqBwkzM0vlIGHWJJIGJP32PK7/02bmx6wZHCTMmmcAmHOQABwkrOU4SJjNQtJ/qizFnbwelfR7NU79IPD6ZPnm30/W3flLSV9P1tl5R3L9aZK+mpy3U9LrJX0QODFJKy1Q0cxm5XkSZrNIFtD7fEScJ6mH8uS8CyJi/7TzLqa8TPdbktdDwAsi4j8ni7B9DXgb8OvACRExKqkX6IuIpyUdiIiTF6xgZhksmf0Us+4WEeOS9kt6FfBC4BvTA0SKXwReKamybMTzKS+H8XXg5mTtpb+LiB25ZNysCRwkzLL5OPB24EXAzRmvEfC7EXHHjAPSzwG/BGyV9JcRcWuzMmrWTO6TMMvmb4FLKS/PPONLP/E05V3iKu4AhpMaA5J+QtJJkorADyPibygv0lfZZvJI5VyzVuGahFkGEXFY0lcob3JzNOW0B4FnJX2T8haTGymPeHogWbFzH+VVOy8G3iPpCHAAuDK5fjPwoKQHImIwr7KYNcId12YZJB3WDwBvi4jvLHZ+zBaKm5vMZiHpHMpLTt/lAGHdxjUJswZJegXlfRuqHYqI1yxGfszy5CBhZmap3NxkZmapHCTMzCyVg4SZmaVykDAzs1QOEmZmlspBwszMUv1/zDy/hAMGLqcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, y_pred, color = 'black')\n",
    "plt.title('y_pred vs y_test')\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('y_pred')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([192.11303687])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.01873655,  5.6196331 , 47.4274282 ,  4.18643627, -6.65501259,\n",
       "        -0.98620848]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age of vehicle</th>\n",
       "      <th>engine capacity (cc)</th>\n",
       "      <th>Fuel consumption (metric combined)</th>\n",
       "      <th>Noise level (dB(A))</th>\n",
       "      <th>fuel type</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>PM emissions (g/km)</th>\n",
       "      <th>Nox emissions (g/km)</th>\n",
       "      <th>HC emissions (g/km)</th>\n",
       "      <th>CO2 emission (g/km)</th>\n",
       "      <th>CO emissions (g/km)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.121242</td>\n",
       "      <td>-0.951063</td>\n",
       "      <td>-1.912784</td>\n",
       "      <td>-0.213765</td>\n",
       "      <td>-1.277345</td>\n",
       "      <td>0.76859</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age of vehicle  engine capacity (cc)  Fuel consumption (metric combined)  \\\n",
       "0       -2.121242             -0.951063                           -1.912784   \n",
       "\n",
       "   Noise level (dB(A))  fuel type  gearbox PM emissions (g/km)  \\\n",
       "0            -0.213765  -1.277345  0.76859                   0   \n",
       "\n",
       "   Nox emissions (g/km) HC emissions (g/km)  CO2 emission (g/km)  \\\n",
       "0                 0.057                 NaN                   92   \n",
       "\n",
       "   CO emissions (g/km)  \n",
       "0                0.054  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.964\n",
      "Model:                            OLS   Adj. R-squared:                  0.964\n",
      "Method:                 Least Squares   F-statistic:                     3387.\n",
      "Date:                Sat, 17 Apr 2021   Prob (F-statistic):               0.00\n",
      "Time:                        18:30:48   Log-Likelihood:                -2814.5\n",
      "No. Observations:                 757   AIC:                             5643.\n",
      "Df Residuals:                     750   BIC:                             5675.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        192.1130      0.368    521.630      0.000     191.390     192.836\n",
      "x1             4.0187      0.427      9.420      0.000       3.181       4.856\n",
      "x2             5.6196      0.822      6.835      0.000       4.005       7.234\n",
      "x3            47.4274      0.896     52.924      0.000      45.668      49.187\n",
      "x4             4.1864      2.211      1.894      0.059      -0.154       8.527\n",
      "x5            -6.6550      0.493    -13.492      0.000      -7.623      -5.687\n",
      "x6            -0.9862      0.393     -2.507      0.012      -1.759      -0.214\n",
      "==============================================================================\n",
      "Omnibus:                     1128.965   Durbin-Watson:                   1.956\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           761831.434\n",
      "Skew:                          -8.019   Prob(JB):                         0.00\n",
      "Kurtosis:                     157.583   Cond. No.                         8.41\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X_train = sm.add_constant(X_train)\n",
    "model=sm.OLS(y_train,X_train).fit()\n",
    "predictions=model.predict(X_train)\n",
    "results=model.summary()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.968\n",
      "Model:                            OLS   Adj. R-squared:                  0.968\n",
      "Method:                 Least Squares   F-statistic:                     5667.\n",
      "Date:                Sat, 17 Apr 2021   Prob (F-statistic):               0.00\n",
      "Time:                        18:36:04   Log-Likelihood:                -3466.5\n",
      "No. Observations:                 947   AIC:                             6945.\n",
      "Df Residuals:                     941   BIC:                             6974.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        192.0190      0.307    626.070      0.000     191.417     192.621\n",
      "x1             4.1087      0.351     11.714      0.000       3.420       4.797\n",
      "x2             4.3754      0.685      6.386      0.000       3.031       5.720\n",
      "x3            48.6028      0.760     63.950      0.000      47.111      50.094\n",
      "x4            -7.2757      0.417    -17.435      0.000      -8.095      -6.457\n",
      "x5            -0.6478      0.325     -1.991      0.047      -1.286      -0.009\n",
      "==============================================================================\n",
      "Omnibus:                     1434.757   Durbin-Watson:                   1.375\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1192397.442\n",
      "Skew:                          -8.396   Prob(JB):                         0.00\n",
      "Kurtosis:                     176.024   Cond. No.                         4.77\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X= sm.add_constant(X)\n",
    "model=sm.OLS(y,X).fit()\n",
    "predictions=model.predict(X)\n",
    "results=model.summary()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.814</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.813</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1028.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 17 Apr 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:49:25</td>     <th>  Log-Likelihood:    </th> <td> -4298.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   947</td>      <th>  AIC:               </th> <td>   8608.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   942</td>      <th>  BIC:               </th> <td>   8632.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   96.0138</td> <td>    0.369</td> <td>  260.121</td> <td> 0.000</td> <td>   95.289</td> <td>   96.738</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   96.0138</td> <td>    0.369</td> <td>  260.121</td> <td> 0.000</td> <td>   95.289</td> <td>   96.738</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   15.2392</td> <td>    0.742</td> <td>   20.540</td> <td> 0.000</td> <td>   13.783</td> <td>   16.695</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   43.7075</td> <td>    0.741</td> <td>   59.011</td> <td> 0.000</td> <td>   42.254</td> <td>   45.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    1.3905</td> <td>    0.740</td> <td>    1.879</td> <td> 0.061</td> <td>   -0.062</td> <td>    2.843</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   11.4608</td> <td>    0.741</td> <td>   15.468</td> <td> 0.000</td> <td>   10.007</td> <td>   12.915</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>100.106</td> <th>  Durbin-Watson:     </th> <td>   1.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 185.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.676</td>  <th>  Prob(JB):          </th> <td>6.08e-41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.693</td>  <th>  Cond. No.          </th> <td>1.67e+17</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 6.81e-32. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.814\n",
       "Model:                            OLS   Adj. R-squared:                  0.813\n",
       "Method:                 Least Squares   F-statistic:                     1028.\n",
       "Date:                Sat, 17 Apr 2021   Prob (F-statistic):               0.00\n",
       "Time:                        17:49:25   Log-Likelihood:                -4298.8\n",
       "No. Observations:                 947   AIC:                             8608.\n",
       "Df Residuals:                     942   BIC:                             8632.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         96.0138      0.369    260.121      0.000      95.289      96.738\n",
       "x1            96.0138      0.369    260.121      0.000      95.289      96.738\n",
       "x2            15.2392      0.742     20.540      0.000      13.783      16.695\n",
       "x3            43.7075      0.741     59.011      0.000      42.254      45.161\n",
       "x4             1.3905      0.740      1.879      0.061      -0.062       2.843\n",
       "x5            11.4608      0.741     15.468      0.000      10.007      12.915\n",
       "==============================================================================\n",
       "Omnibus:                      100.106   Durbin-Watson:                   1.179\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              185.201\n",
       "Skew:                           0.676   Prob(JB):                     6.08e-41\n",
       "Kurtosis:                       4.693   Cond. No.                     1.67e+17\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 6.81e-32. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api  as sm \n",
    "#The 0th column contains only 1 in each n rows \n",
    "X= np.append(arr = np.ones((947,1)).astype(int), values = X, axis=1) \n",
    "#Optimal X contains the highly impacted independent variables\n",
    "X_opt= X[:,[0,1,2,3,5,6]] \n",
    "#OLS: Oridnary Least Square Class. endog is the dependent variable, \n",
    "#exog is the number of observations\n",
    "regressor_OLS=sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api  as sm \n",
    "#The 0th column contains only 1 in each 352 rows \n",
    "X= np.append(arr = np.ones((949,1)).astype(int), values = X, axis=1) \n",
    "X_opt= X[:,[0,1,3,4,5,6]] #Optimal X contains the highly impacted independent variables\n",
    "#OLS: Oridnary Least Square Class. endog is the dependent variable, exog is the number of observations\n",
    "regressor_OLS=sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "object too deep for desired array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;31mValueError\u001b[0m: object too deep for desired array"
     ]
    },
    {
     "ename": "error",
     "evalue": "Result from function call is not a proper array of floats.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-7056a7651a7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# curve fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurve_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# summarize the parameter values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpopt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\minpack.py\u001b[0m in \u001b[0;36mcurve_fit\u001b[1;34m(f, xdata, ydata, p0, sigma, absolute_sigma, check_finite, bounds, method, jac, **kwargs)\u001b[0m\n\u001b[0;32m    749\u001b[0m         \u001b[1;31m# Remove full_output from kwargs, otherwise we're passing it in twice.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m         \u001b[0mreturn_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'full_output'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleastsq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDfun\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    752\u001b[0m         \u001b[0mpopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpcov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfodict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfodict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fvec'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\minpack.py\u001b[0m in \u001b[0;36mleastsq\u001b[1;34m(func, x0, args, Dfun, full_output, col_deriv, ftol, xtol, gtol, maxfev, epsfcn, factor, diag)\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_MINPACK_LOCK\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m             retval = _minpack._lmdif(func, x0, args, full_output, ftol, xtol,\n\u001b[1;32m--> 394\u001b[1;33m                                      gtol, maxfev, epsfcn, factor, diag)\n\u001b[0m\u001b[0;32m    395\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcol_deriv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: Result from function call is not a proper array of floats."
     ]
    }
   ],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "from matplotlib import pyplot\n",
    "# curve fit\n",
    "popt, _ = curve_fit(objective, X_train, y_train)\n",
    "# summarize the parameter values\n",
    "a, b = popt\n",
    "print('y = %.5f * X + %.5f' % (a, b))\n",
    "# plot input vs output\n",
    "pyplot.scatter(X_train, y_train)\n",
    "# define a sequence of inputs between the smallest and largest known inputs\n",
    "X_line = arange(min(X_train), max(X_train), 1)\n",
    "# calculate the output for the range\n",
    "y_line = objective(X_line, a, b)\n",
    "# create a line plot for the mapping function\n",
    "pyplot.plot(X_line, y_line, '**', color='black')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected 1D vector for x",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-39beab6b9830>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\polynomial.py\u001b[0m in \u001b[0;36mpolyfit\u001b[1;34m(x, y, deg, rcond, full, w, cov)\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected deg >= 0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 548\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected 1D vector for x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected non-empty vector for x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected 1D vector for x"
     ]
    }
   ],
   "source": [
    "model=np.polyfit(X_train,y_train,1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[313.]\n",
      " [192.]\n",
      " [192.]\n",
      " [288.]\n",
      " [288.]\n",
      " [177.]\n",
      " [177.]\n",
      " [159.]\n",
      " [161.]\n",
      " [106.]\n",
      " [110.]\n",
      " [119.]\n",
      " [122.]\n",
      " [123.]\n",
      " [ 99.]\n",
      " [103.]\n",
      " [109.]\n",
      " [107.]\n",
      " [109.]\n",
      " [109.]\n",
      " [112.]\n",
      " [123.]\n",
      " [124.]\n",
      " [119.]\n",
      " [ 99.]\n",
      " [103.]\n",
      " [109.]\n",
      " [107.]\n",
      " [109.]\n",
      " [109.]\n",
      " [109.]\n",
      " [112.]\n",
      " [ 92.]\n",
      " [108.]\n",
      " [106.]\n",
      " [108.]\n",
      " [110.]\n",
      " [113.]\n",
      " [125.]\n",
      " [127.]\n",
      " [143.]\n",
      " [130.]\n",
      " [125.]\n",
      " [127.]\n",
      " [143.]\n",
      " [130.]\n",
      " [112.]\n",
      " [125.]\n",
      " [128.]\n",
      " [126.]\n",
      " [262.]\n",
      " [279.]\n",
      " [283.]\n",
      " [262.]\n",
      " [262.]\n",
      " [246.]\n",
      " [224.]\n",
      " [246.]\n",
      " [224.]\n",
      " [246.]\n",
      " [241.]\n",
      " [224.]\n",
      " [210.]\n",
      " [191.]\n",
      " [210.]\n",
      " [155.]\n",
      " [159.]\n",
      " [191.]\n",
      " [210.]\n",
      " [150.]\n",
      " [176.]\n",
      " [176.]\n",
      " [176.]\n",
      " [173.]\n",
      " [240.]\n",
      " [173.]\n",
      " [240.]\n",
      " [188.]\n",
      " [267.]\n",
      " [188.]\n",
      " [267.]\n",
      " [188.]\n",
      " [187.]\n",
      " [187.]\n",
      " [192.]\n",
      " [187.]\n",
      " [166.]\n",
      " [231.]\n",
      " [232.]\n",
      " [192.]\n",
      " [161.]\n",
      " [163.]\n",
      " [231.]\n",
      " [175.]\n",
      " [166.]\n",
      " [161.]\n",
      " [159.]\n",
      " [161.]\n",
      " [163.]\n",
      " [159.]\n",
      " [159.]\n",
      " [159.]\n",
      " [176.]\n",
      " [188.]\n",
      " [165.]\n",
      " [228.]\n",
      " [196.]\n",
      " [206.]\n",
      " [211.]\n",
      " [274.]\n",
      " [241.]\n",
      " [246.]\n",
      " [247.]\n",
      " [271.]\n",
      " [165.]\n",
      " [161.]\n",
      " [218.]\n",
      " [247.]\n",
      " [211.]\n",
      " [219.]\n",
      " [228.]\n",
      " [256.]\n",
      " [176.]\n",
      " [188.]\n",
      " [192.]\n",
      " [211.]\n",
      " [218.]\n",
      " [196.]\n",
      " [206.]\n",
      " [211.]\n",
      " [181.]\n",
      " [183.]\n",
      " [247.]\n",
      " [271.]\n",
      " [211.]\n",
      " [247.]\n",
      " [164.]\n",
      " [274.]\n",
      " [228.]\n",
      " [256.]\n",
      " [215.]\n",
      " [210.]\n",
      " [230.]\n",
      " [237.]\n",
      " [165.]\n",
      " [145.]\n",
      " [159.]\n",
      " [252.]\n",
      " [200.]\n",
      " [241.]\n",
      " [139.]\n",
      " [165.]\n",
      " [165.]\n",
      " [146.]\n",
      " [198.]\n",
      " [200.]\n",
      " [146.]\n",
      " [187.]\n",
      " [221.]\n",
      " [224.]\n",
      " [213.]\n",
      " [233.]\n",
      " [263.]\n",
      " [190.]\n",
      " [188.]\n",
      " [259.]\n",
      " [218.]\n",
      " [224.]\n",
      " [150.]\n",
      " [165.]\n",
      " [187.]\n",
      " [221.]\n",
      " [224.]\n",
      " [212.]\n",
      " [223.]\n",
      " [221.]\n",
      " [218.]\n",
      " [317.]\n",
      " [310.]\n",
      " [317.]\n",
      " [187.]\n",
      " [264.]\n",
      " [324.]\n",
      " [221.]\n",
      " [202.]\n",
      " [223.]\n",
      " [317.]\n",
      " [187.]\n",
      " [274.]\n",
      " [277.]\n",
      " [274.]\n",
      " [277.]\n",
      " [320.]\n",
      " [283.]\n",
      " [276.]\n",
      " [276.]\n",
      " [212.]\n",
      " [218.]\n",
      " [212.]\n",
      " [218.]\n",
      " [178.]\n",
      " [214.]\n",
      " [227.]\n",
      " [194.]\n",
      " [219.]\n",
      " [194.]\n",
      " [178.]\n",
      " [219.]\n",
      " [270.]\n",
      " [273.]\n",
      " [245.]\n",
      " [226.]\n",
      " [227.]\n",
      " [233.]\n",
      " [288.]\n",
      " [282.]\n",
      " [282.]\n",
      " [248.]\n",
      " [238.]\n",
      " [282.]\n",
      " [387.]\n",
      " [387.]\n",
      " [291.]\n",
      " [224.]\n",
      " [216.]\n",
      " [174.]\n",
      " [169.]\n",
      " [171.]\n",
      " [176.]\n",
      " [270.]\n",
      " [189.]\n",
      " [178.]\n",
      " [209.]\n",
      " [209.]\n",
      " [209.]\n",
      " [209.]\n",
      " [295.]\n",
      " [295.]\n",
      " [295.]\n",
      " [192.]\n",
      " [192.]\n",
      " [183.]\n",
      " [152.]\n",
      " [152.]\n",
      " [275.]\n",
      " [275.]\n",
      " [275.]\n",
      " [238.]\n",
      " [275.]\n",
      " [275.]\n",
      " [275.]\n",
      " [275.]\n",
      " [275.]\n",
      " [275.]\n",
      " [245.]\n",
      " [245.]\n",
      " [245.]\n",
      " [245.]\n",
      " [245.]\n",
      " [245.]\n",
      " [245.]\n",
      " [245.]\n",
      " [245.]\n",
      " [245.]\n",
      " [217.]\n",
      " [287.]\n",
      " [287.]\n",
      " [287.]\n",
      " [287.]\n",
      " [232.]\n",
      " [237.]\n",
      " [232.]\n",
      " [252.]\n",
      " [232.]\n",
      " [252.]\n",
      " [199.]\n",
      " [237.]\n",
      " [237.]\n",
      " [231.]\n",
      " [221.]\n",
      " [192.]\n",
      " [162.]\n",
      " [159.]\n",
      " [197.]\n",
      " [192.]\n",
      " [179.]\n",
      " [175.]\n",
      " [179.]\n",
      " [194.]\n",
      " [192.]\n",
      " [233.]\n",
      " [192.]\n",
      " [226.]\n",
      " [233.]\n",
      " [206.]\n",
      " [238.]\n",
      " [233.]\n",
      " [194.]\n",
      " [194.]\n",
      " [167.]\n",
      " [223.]\n",
      " [155.]\n",
      " [223.]\n",
      " [149.]\n",
      " [223.]\n",
      " [149.]\n",
      " [155.]\n",
      " [217.]\n",
      " [295.]\n",
      " [209.]\n",
      " [192.]\n",
      " [201.]\n",
      " [295.]\n",
      " [223.]\n",
      " [199.]\n",
      " [223.]\n",
      " [159.]\n",
      " [179.]\n",
      " [159.]\n",
      " [175.]\n",
      " [159.]\n",
      " [119.]\n",
      " [145.]\n",
      " [153.]\n",
      " [145.]\n",
      " [153.]\n",
      " [139.]\n",
      " [153.]\n",
      " [139.]\n",
      " [153.]\n",
      " [152.]\n",
      " [153.]\n",
      " [119.]\n",
      " [157.]\n",
      " [164.]\n",
      " [158.]\n",
      " [165.]\n",
      " [136.]\n",
      " [142.]\n",
      " [136.]\n",
      " [134.]\n",
      " [136.]\n",
      " [142.]\n",
      " [136.]\n",
      " [134.]\n",
      " [159.]\n",
      " [156.]\n",
      " [159.]\n",
      " [156.]\n",
      " [148.]\n",
      " [143.]\n",
      " [165.]\n",
      " [177.]\n",
      " [250.]\n",
      " [181.]\n",
      " [159.]\n",
      " [194.]\n",
      " [231.]\n",
      " [199.]\n",
      " [174.]\n",
      " [156.]\n",
      " [133.]\n",
      " [295.]\n",
      " [104.]\n",
      " [104.]\n",
      " [ 89.]\n",
      " [ 92.]\n",
      " [ 89.]\n",
      " [ 84.]\n",
      " [ 82.]\n",
      " [ 83.]\n",
      " [ 91.]\n",
      " [ 92.]\n",
      " [ 81.]\n",
      " [ 83.]\n",
      " [115.]\n",
      " [116.]\n",
      " [ 84.]\n",
      " [ 81.]\n",
      " [ 82.]\n",
      " [186.]\n",
      " [157.]\n",
      " [263.]\n",
      " [232.]\n",
      " [260.]\n",
      " [152.]\n",
      " [157.]\n",
      " [246.]\n",
      " [260.]\n",
      " [263.]\n",
      " [161.]\n",
      " [232.]\n",
      " [240.]\n",
      " [260.]\n",
      " [263.]\n",
      " [161.]\n",
      " [232.]\n",
      " [260.]\n",
      " [161.]\n",
      " [161.]\n",
      " [135.]\n",
      " [125.]\n",
      " [136.]\n",
      " [120.]\n",
      " [120.]\n",
      " [120.]\n",
      " [138.]\n",
      " [138.]\n",
      " [169.]\n",
      " [202.]\n",
      " [192.]\n",
      " [169.]\n",
      " [158.]\n",
      " [145.]\n",
      " [169.]\n",
      " [202.]\n",
      " [192.]\n",
      " [145.]\n",
      " [160.]\n",
      " [127.]\n",
      " [158.]\n",
      " [190.]\n",
      " [222.]\n",
      " [192.]\n",
      " [187.]\n",
      " [118.]\n",
      " [118.]\n",
      " [140.]\n",
      " [191.]\n",
      " [119.]\n",
      " [125.]\n",
      " [128.]\n",
      " [225.]\n",
      " [140.]\n",
      " [190.]\n",
      " [225.]\n",
      " [116.]\n",
      " [118.]\n",
      " [116.]\n",
      " [116.]\n",
      " [119.]\n",
      " [119.]\n",
      " [143.]\n",
      " [154.]\n",
      " [154.]\n",
      " [152.]\n",
      " [155.]\n",
      " [158.]\n",
      " [161.]\n",
      " [173.]\n",
      " [153.]\n",
      " [149.]\n",
      " [153.]\n",
      " [151.]\n",
      " [156.]\n",
      " [165.]\n",
      " [191.]\n",
      " [190.]\n",
      " [117.]\n",
      " [133.]\n",
      " [132.]\n",
      " [109.]\n",
      " [221.]\n",
      " [119.]\n",
      " [221.]\n",
      " [140.]\n",
      " [219.]\n",
      " [154.]\n",
      " [213.]\n",
      " [143.]\n",
      " [119.]\n",
      " [224.]\n",
      " [149.]\n",
      " [154.]\n",
      " [138.]\n",
      " [120.]\n",
      " [130.]\n",
      " [143.]\n",
      " [120.]\n",
      " [138.]\n",
      " [224.]\n",
      " [213.]\n",
      " [140.]\n",
      " [159.]\n",
      " [140.]\n",
      " [146.]\n",
      " [138.]\n",
      " [224.]\n",
      " [140.]\n",
      " [143.]\n",
      " [160.]\n",
      " [160.]\n",
      " [180.]\n",
      " [233.]\n",
      " [158.]\n",
      " [180.]\n",
      " [233.]\n",
      " [160.]\n",
      " [180.]\n",
      " [282.]\n",
      " [292.]\n",
      " [160.]\n",
      " [160.]\n",
      " [180.]\n",
      " [177.]\n",
      " [160.]\n",
      " [180.]\n",
      " [183.]\n",
      " [160.]\n",
      " [180.]\n",
      " [180.]\n",
      " [158.]\n",
      " [158.]\n",
      " [150.]\n",
      " [226.]\n",
      " [217.]\n",
      " [177.]\n",
      " [154.]\n",
      " [158.]\n",
      " [162.]\n",
      " [217.]\n",
      " [150.]\n",
      " [156.]\n",
      " [139.]\n",
      " [154.]\n",
      " [158.]\n",
      " [226.]\n",
      " [139.]\n",
      " [154.]\n",
      " [158.]\n",
      " [151.]\n",
      " [139.]\n",
      " [151.]\n",
      " [151.]\n",
      " [139.]\n",
      " [149.]\n",
      " [139.]\n",
      " [149.]\n",
      " [139.]\n",
      " [ 99.]\n",
      " [138.]\n",
      " [154.]\n",
      " [164.]\n",
      " [166.]\n",
      " [151.]\n",
      " [179.]\n",
      " [203.]\n",
      " [176.]\n",
      " [192.]\n",
      " [196.]\n",
      " [235.]\n",
      " [215.]\n",
      " [223.]\n",
      " [149.]\n",
      " [146.]\n",
      " [182.]\n",
      " [202.]\n",
      " [191.]\n",
      " [205.]\n",
      " [215.]\n",
      " [154.]\n",
      " [164.]\n",
      " [166.]\n",
      " [150.]\n",
      " [165.]\n",
      " [182.]\n",
      " [193.]\n",
      " [202.]\n",
      " [176.]\n",
      " [192.]\n",
      " [196.]\n",
      " [138.]\n",
      " [150.]\n",
      " [156.]\n",
      " [235.]\n",
      " [223.]\n",
      " [144.]\n",
      " [182.]\n",
      " [193.]\n",
      " [136.]\n",
      " [215.]\n",
      " [133.]\n",
      " [198.]\n",
      " [198.]\n",
      " [208.]\n",
      " [194.]\n",
      " [190.]\n",
      " [146.]\n",
      " [128.]\n",
      " [131.]\n",
      " [141.]\n",
      " [190.]\n",
      " [119.]\n",
      " [124.]\n",
      " [145.]\n",
      " [152.]\n",
      " [152.]\n",
      " [124.]\n",
      " [133.]\n",
      " [142.]\n",
      " [174.]\n",
      " [190.]\n",
      " [190.]\n",
      " [124.]\n",
      " [133.]\n",
      " [142.]\n",
      " [190.]\n",
      " [242.]\n",
      " [242.]\n",
      " [146.]\n",
      " [235.]\n",
      " [199.]\n",
      " [175.]\n",
      " [144.]\n",
      " [144.]\n",
      " [199.]\n",
      " [193.]\n",
      " [199.]\n",
      " [171.]\n",
      " [172.]\n",
      " [191.]\n",
      " [193.]\n",
      " [202.]\n",
      " [206.]\n",
      " [159.]\n",
      " [159.]\n",
      " [168.]\n",
      " [168.]\n",
      " [172.]\n",
      " [178.]\n",
      " [184.]\n",
      " [226.]\n",
      " [207.]\n",
      " [211.]\n",
      " [134.]\n",
      " [133.]\n",
      " [138.]\n",
      " [162.]\n",
      " [165.]\n",
      " [163.]\n",
      " [166.]\n",
      " [171.]\n",
      " [172.]\n",
      " [191.]\n",
      " [193.]\n",
      " [109.]\n",
      " [202.]\n",
      " [178.]\n",
      " [184.]\n",
      " [127.]\n",
      " [141.]\n",
      " [170.]\n",
      " [152.]\n",
      " [153.]\n",
      " [106.]\n",
      " [ 99.]\n",
      " [118.]\n",
      " [185.]\n",
      " [228.]\n",
      " [190.]\n",
      " [163.]\n",
      " [168.]\n",
      " [170.]\n",
      " [194.]\n",
      " [199.]\n",
      " [204.]\n",
      " [209.]\n",
      " [166.]\n",
      " [192.]\n",
      " [144.]\n",
      " [298.]\n",
      " [199.]\n",
      " [206.]\n",
      " [223.]\n",
      " [206.]\n",
      " [211.]\n",
      " [226.]\n",
      " [166.]\n",
      " [192.]\n",
      " [144.]\n",
      " [154.]\n",
      " [173.]\n",
      " [190.]\n",
      " [274.]\n",
      " [209.]\n",
      " [173.]\n",
      " [293.]\n",
      " [209.]\n",
      " [156.]\n",
      " [194.]\n",
      " [250.]\n",
      " [253.]\n",
      " [292.]\n",
      " [292.]\n",
      " [159.]\n",
      " [190.]\n",
      " [161.]\n",
      " [161.]\n",
      " [190.]\n",
      " [161.]\n",
      " [164.]\n",
      " [190.]\n",
      " [161.]\n",
      " [161.]\n",
      " [189.]\n",
      " [190.]\n",
      " [145.]\n",
      " [201.]\n",
      " [264.]\n",
      " [264.]\n",
      " [224.]\n",
      " [232.]\n",
      " [139.]\n",
      " [174.]\n",
      " [179.]\n",
      " [264.]\n",
      " [224.]\n",
      " [232.]\n",
      " [139.]\n",
      " [135.]\n",
      " [135.]\n",
      " [134.]\n",
      " [129.]\n",
      " [110.]\n",
      " [105.]\n",
      " [104.]\n",
      " [104.]\n",
      " [104.]\n",
      " [104.]\n",
      " [163.]\n",
      " [184.]\n",
      " [187.]\n",
      " [145.]\n",
      " [145.]\n",
      " [163.]\n",
      " [180.]\n",
      " [187.]\n",
      " [110.]\n",
      " [115.]\n",
      " [119.]\n",
      " [115.]\n",
      " [117.]\n",
      " [192.]\n",
      " [192.]\n",
      " [196.]\n",
      " [190.]\n",
      " [158.]\n",
      " [172.]\n",
      " [160.]\n",
      " [139.]\n",
      " [149.]\n",
      " [139.]\n",
      " [119.]\n",
      " [144.]\n",
      " [164.]\n",
      " [146.]\n",
      " [149.]\n",
      " [156.]\n",
      " [158.]\n",
      " [161.]\n",
      " [163.]\n",
      " [173.]\n",
      " [185.]\n",
      " [167.]\n",
      " [178.]\n",
      " [125.]\n",
      " [135.]\n",
      " [134.]\n",
      " [135.]\n",
      " [136.]\n",
      " [150.]\n",
      " [147.]\n",
      " [149.]\n",
      " [152.]\n",
      " [154.]\n",
      " [130.]\n",
      " [143.]\n",
      " [109.]\n",
      " [189.]\n",
      " [194.]\n",
      " [189.]\n",
      " [194.]\n",
      " [178.]\n",
      " [146.]\n",
      " [189.]\n",
      " [154.]\n",
      " [158.]\n",
      " [208.]\n",
      " [220.]\n",
      " [273.]\n",
      " [208.]\n",
      " [220.]\n",
      " [273.]\n",
      " [273.]\n",
      " [288.]\n",
      " [208.]\n",
      " [288.]\n",
      " [199.]\n",
      " [204.]\n",
      " [288.]\n",
      " [230.]\n",
      " [288.]\n",
      " [248.]\n",
      " [248.]\n",
      " [159.]\n",
      " [248.]\n",
      " [262.]\n",
      " [248.]\n",
      " [129.]\n",
      " [248.]\n",
      " [165.]\n",
      " [248.]\n",
      " [165.]\n",
      " [248.]\n",
      " [128.]\n",
      " [248.]\n",
      " [128.]\n",
      " [248.]\n",
      " [250.]\n",
      " [250.]\n",
      " [158.]\n",
      " [182.]\n",
      " [238.]\n",
      " [158.]\n",
      " [169.]\n",
      " [153.]\n",
      " [172.]\n",
      " [185.]\n",
      " [200.]\n",
      " [198.]\n",
      " [211.]\n",
      " [178.]\n",
      " [135.]\n",
      " [136.]\n",
      " [154.]\n",
      " [153.]\n",
      " [154.]\n",
      " [155.]\n",
      " [158.]\n",
      " [163.]\n",
      " [174.]\n",
      " [129.]\n",
      " [158.]\n",
      " [165.]\n",
      " [120.]\n",
      " [233.]\n",
      " [163.]\n",
      " [181.]\n",
      " [240.]\n",
      " [243.]\n",
      " [224.]\n",
      " [261.]\n",
      " [168.]\n",
      " [288.]\n",
      " [168.]\n",
      " [288.]\n",
      " [179.]\n",
      " [188.]\n",
      " [168.]\n",
      " [288.]\n",
      " [175.]\n",
      " [181.]\n",
      " [170.]\n",
      " [181.]\n",
      " [170.]\n",
      " [181.]\n",
      " [288.]\n",
      " [186.]\n",
      " [220.]\n",
      " [147.]\n",
      " [221.]\n",
      " [186.]\n",
      " [149.]\n",
      " [186.]\n",
      " [220.]\n",
      " [149.]\n",
      " [142.]\n",
      " [147.]\n",
      " [183.]\n",
      " [230.]\n",
      " [221.]\n",
      " [183.]\n",
      " [222.]\n",
      " [226.]\n",
      " [183.]\n",
      " [183.]\n",
      " [131.]\n",
      " [119.]\n",
      " [161.]\n",
      " [179.]\n",
      " [136.]\n",
      " [110.]\n",
      " [179.]\n",
      " [129.]\n",
      " [109.]\n",
      " [107.]\n",
      " [120.]\n",
      " [127.]\n",
      " [146.]\n",
      " [119.]\n",
      " [110.]\n",
      " [177.]\n",
      " [164.]\n",
      " [150.]\n",
      " [153.]\n",
      " [240.]\n",
      " [259.]\n",
      " [243.]\n",
      " [243.]\n",
      " [264.]\n",
      " [314.]\n",
      " [312.]\n",
      " [298.]\n",
      " [348.]\n",
      " [298.]\n",
      " [314.]\n",
      " [346.]\n",
      " [317.]\n",
      " [350.]\n",
      " [286.]\n",
      " [295.]\n",
      " [271.]\n",
      " [271.]\n",
      " [266.]\n",
      " [271.]\n",
      " [266.]\n",
      " [262.]\n",
      " [265.]\n",
      " [265.]\n",
      " [212.]\n",
      " [224.]\n",
      " [279.]\n",
      " [182.]\n",
      " [355.]\n",
      " [286.]\n",
      " [259.]\n",
      " [266.]\n",
      " [267.]\n",
      " [326.]\n",
      " [224.]\n",
      " [259.]\n",
      " [214.]\n",
      " [333.]\n",
      " [304.]\n",
      " [325.]\n",
      " [225.]\n",
      " [224.]\n",
      " [310.]\n",
      " [189.]\n",
      " [179.]\n",
      " [177.]\n",
      " [270.]\n",
      " [264.]\n",
      " [262.]\n",
      " [240.]\n",
      " [167.]\n",
      " [213.]\n",
      " [243.]\n",
      " [213.]\n",
      " [238.]\n",
      " [177.]\n",
      " [173.]\n",
      " [177.]\n",
      " [172.]\n",
      " [173.]\n",
      " [189.]\n",
      " [164.]\n",
      " [163.]\n",
      " [165.]\n",
      " [228.]\n",
      " [288.]\n",
      " [223.]\n",
      " [226.]\n",
      " [283.]\n",
      " [324.]\n",
      " [228.]\n",
      " [228.]\n",
      " [218.]\n",
      " [255.]\n",
      " [349.]\n",
      " [174.]\n",
      " [278.]\n",
      " [266.]\n",
      " [278.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Support Vecctor Regression\n",
    "#1 Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#2 Importing the dataset\n",
    "dataset = pd.read_csv(r'C:\\Users\\shubh\\Desktop\\IITM\\Courses\\Sem 2\\ML in civil eng\\term paper\\CE6051- vehicular emission data set - Sheet14.csv')\n",
    "X = dataset.iloc[1:,0:6].values.astype(float)\n",
    "y = dataset.iloc[1:,6:7].values.astype(float)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4 Fitting the Support Vector Regression Model to the dataset\n",
    "# Create your support vector regressor here\n",
    "from sklearn.svm import SVR\n",
    "# most important SVR parameter is Kernel type. It can be linear,polynomial or gaussian.\n",
    "#SVR. We have a non-linear condition so we can select polynomial or gaussian but here\n",
    "#we select RBF(a gaussian type) while here I substituted it with 'linear' kernel. \n",
    "regressor = SVR(kernel='linear')\n",
    "regressor.fit(X_train, y_train, sample_weight = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([117.53062594, 179.80997639, 233.29048096, 223.46611624,\n",
       "       191.55059757, 169.53649704, 145.82276318, 158.60845273,\n",
       "       308.79463818, 292.59435936, 160.23827479, 165.41491623,\n",
       "       153.3302949 , 192.03350607, 226.44150783, 223.9179451 ,\n",
       "       171.05355814, 229.76514915, 157.16331191, 225.62395917,\n",
       "       117.48285611, 198.31609301, 107.95928074, 193.64673362,\n",
       "       280.42956882, 179.25466271, 181.31806389, 200.9058879 ,\n",
       "       191.97168099, 168.52308799, 153.22513678, 111.37316119,\n",
       "       167.10777225, 128.67544156, 280.28215224, 188.72400825,\n",
       "       195.31806575, 228.16132184, 199.39717443, 155.91596124,\n",
       "       212.7614504 , 135.34506827, 214.99591744, 203.98747526,\n",
       "       215.17145471, 229.96072404, 214.81330802, 199.7559153 ,\n",
       "       245.58879794, 129.70081877, 120.28347225, 138.44616476,\n",
       "       156.7129944 , 189.54806468, 208.62862463, 105.08921702,\n",
       "        95.84530689, 213.00913791, 195.73551931, 276.56950044,\n",
       "       209.06582601, 113.73668136, 301.64561755, 158.5350252 ,\n",
       "       210.31104033, 160.99351623, 152.75063396, 178.53296846,\n",
       "       224.31371789, 147.83105571, 268.25277332, 141.39304722,\n",
       "       217.47400303, 136.99310299, 263.87128171, 163.09686176,\n",
       "       235.88475437, 130.9212014 , 187.5809402 , 192.8312355 ,\n",
       "       181.27249821, 147.65754197, 284.1171879 , 263.25231691,\n",
       "       244.56187289, 149.06898538, 137.31257213, 227.43136067,\n",
       "       215.79041954, 169.13915827, 155.92180346, 209.82318218,\n",
       "       135.3149693 , 147.1045764 , 226.67302403, 169.35489413,\n",
       "       195.92964663, 230.40838207, 320.32829048, 136.47980305,\n",
       "       189.52345429, 143.99415969, 193.27257443, 156.89015132,\n",
       "       224.08508105, 239.90705479, 216.05123765, 217.78110473,\n",
       "       138.7592005 , 327.6812266 , 137.82719991, 241.9540836 ,\n",
       "       255.1887574 , 205.9944298 , 180.65353332, 144.01381357,\n",
       "       120.75903339, 141.92965419, 151.60400201, 310.83966636,\n",
       "       107.62250354, 120.56640738, 299.00344026, 144.76339646,\n",
       "       129.10759013, 108.94919308, 180.03461248, 147.06903312,\n",
       "       145.51789837, 124.52197582, 176.93398595, 227.91990035,\n",
       "       178.79663883, 158.49820487, 206.53793267, 122.56327207,\n",
       "       220.00892444, 151.71563875, 176.84486202, 190.93163263,\n",
       "       134.07296535, 123.88618519, 134.35322401, 192.36867516,\n",
       "       145.25820818, 199.37442697, 189.53258952, 143.56243011,\n",
       "       207.96628771, 162.91071693, 233.76441273, 230.28776418,\n",
       "       346.75858626, 152.34928234, 189.69370297, 163.63992983,\n",
       "       187.53642118, 218.65395019, 242.65143079, 151.84961222,\n",
       "       212.36780761, 126.72340757, 147.12889715, 213.00913791,\n",
       "       243.64889267, 178.09698656, 182.69236205, 146.5155853 ,\n",
       "       141.71578311, 243.44346741, 161.11850462, 295.40709026,\n",
       "       139.57480921, 244.26785755, 257.62811101, 258.05764192,\n",
       "       290.97783682, 156.08702711, 217.66140068, 168.07512961,\n",
       "       193.89153925, 199.62683035, 173.77361324, 183.69424032,\n",
       "       218.5325626 , 210.89318212, 172.67504531, 149.71069764,\n",
       "       198.98483971, 117.69738468])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, y_pred, color = 'black')\n",
    "plt.title('y_pred vs y_test')\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('y_pred')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.18964840e-01, -4.64426658e-03,  2.52142533e+01,\n",
       "        -1.13737145e-02, -2.12359529e-01, -7.68506112e-02]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weight vector, slope\n",
    "w = regressor.coef_\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8675812337032354"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.score(X_test, y_test, sample_weight = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33.22962118])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept = regressor.intercept_\n",
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#3 Feature Scaling\\n# from sklearn.preprocessing import StandardScaler\\n# sc_X = StandardScaler()\\n# sc_y = StandardScaler()\\n# X = sc_X.fit_transform(X)\\n# y = sc_y.fit_transform(y)\\n\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\\n\\n#4 Fitting the Support Vector Regression Model to the dataset\\n# Create your support vector regressor here\\nfrom sklearn.svm import SVR\\n# most important SVR parameter is Kernel type. It can be linear,polynomial or gaussian.\\n#SVR. We have a non-linear condition so we can select polynomial or gaussian but here\\n#we select RBF(a gaussian type) while here I substituted it with 'linear' kernel. \\nregressor = SVR(kernel='linear')\\nregressor.fit(X_train, y_train)\\n\\n#5 Predicting a new result\\n# y_pred = y.inverse_transform((regressor.predict(X.transform(np.array([[6.5]])))))\\ny_pred = regressor.predict(10.11)\\n\\n#6 Visualising the Support Vector Regression results\\nplt.scatter(X, y, color = 'magenta')\\nplt.plot(X, regressor.predict(X), color = 'green')\\nplt.title('Truth or Bluff (Support Vector Regression Model)')\\nplt.xlabel('X')\\nplt.ylabel('y','regressor.predict(X)')\\nplt.show()\\n\\n#6 Visualising the Regression results (for higher resolution and smoother curve)\\n# X_grid = np.arange(min(X), max(X), 0.1)\\n# X_grid = X_grid.reshape((len(X_grid), 1))\\n# plt.scatter(X, y, color = 'red')\\n# plt.plot(X_grid, regressor.predict(X_grid), color = 'blue')\\n# plt.title('Truth or Bluff (Support Vector Regression Model(High Resolution))')\\n# plt.xlabel('Position level')\\n# plt.ylabel('Salary')\\n# plt.show()\\n\\ny_pred = regressor.predict(10.11)\\ny_pred\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#3 Feature Scaling\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc_X = StandardScaler()\n",
    "# sc_y = StandardScaler()\n",
    "# X = sc_X.fit_transform(X)\n",
    "# y = sc_y.fit_transform(y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\n",
    "\n",
    "#4 Fitting the Support Vector Regression Model to the dataset\n",
    "# Create your support vector regressor here\n",
    "from sklearn.svm import SVR\n",
    "# most important SVR parameter is Kernel type. It can be linear,polynomial or gaussian.\n",
    "#SVR. We have a non-linear condition so we can select polynomial or gaussian but here\n",
    "#we select RBF(a gaussian type) while here I substituted it with 'linear' kernel. \n",
    "regressor = SVR(kernel='linear')\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "#5 Predicting a new result\n",
    "# y_pred = y.inverse_transform((regressor.predict(X.transform(np.array([[6.5]])))))\n",
    "y_pred = regressor.predict(10.11)\n",
    "\n",
    "#6 Visualising the Support Vector Regression results\n",
    "plt.scatter(X, y, color = 'magenta')\n",
    "plt.plot(X, regressor.predict(X), color = 'green')\n",
    "plt.title('Truth or Bluff (Support Vector Regression Model)')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y','regressor.predict(X)')\n",
    "plt.show()\n",
    "\n",
    "#6 Visualising the Regression results (for higher resolution and smoother curve)\n",
    "# X_grid = np.arange(min(X), max(X), 0.1)\n",
    "# X_grid = X_grid.reshape((len(X_grid), 1))\n",
    "# plt.scatter(X, y, color = 'red')\n",
    "# plt.plot(X_grid, regressor.predict(X_grid), color = 'blue')\n",
    "# plt.title('Truth or Bluff (Support Vector Regression Model(High Resolution))')\n",
    "# plt.xlabel('Position level')\n",
    "# plt.ylabel('Salary')\n",
    "# plt.show()\n",
    "\n",
    "y_pred = regressor.predict(10.11)\n",
    "y_pred\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
