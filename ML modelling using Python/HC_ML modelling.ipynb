{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.08353612, 0.09655018, 0.07515713, 0.12943659, 0.07662185,\n",
       "       0.10657291, 0.11984775, 0.05984478, 0.096291  , 0.12383893,\n",
       "       0.09987324, 0.07955959, 0.09496946, 0.09803828, 0.1221415 ,\n",
       "       0.0812538 , 0.07519603, 0.07542524, 0.07819941, 0.10861225,\n",
       "       0.09264864, 0.11727808, 0.08940241, 0.15656635, 0.07606948,\n",
       "       0.12544532, 0.16227021, 0.08248156, 0.09884777, 0.08925292,\n",
       "       0.12364456, 0.14648948, 0.07296342, 0.08778058, 0.14172785,\n",
       "       0.10951402, 0.10488114, 0.07557607, 0.14028492, 0.08180156,\n",
       "       0.12224879, 0.09951578, 0.07617782, 0.11883395, 0.1088129 ,\n",
       "       0.11487959, 0.07267434, 0.13295946, 0.11554937, 0.16486853,\n",
       "       0.08876051, 0.08023447, 0.08229764, 0.13810301, 0.09658026,\n",
       "       0.12833774, 0.1057294 , 0.10948127, 0.08523802, 0.08598297,\n",
       "       0.12606136, 0.13611321, 0.08607253, 0.12902574, 0.07120866,\n",
       "       0.0783899 , 0.07500271, 0.09170397, 0.09726519, 0.08997284,\n",
       "       0.08817581, 0.12584201, 0.07823892, 0.13707666, 0.08821421,\n",
       "       0.08529028, 0.08148462, 0.11327488, 0.14475288, 0.0774635 ,\n",
       "       0.12640833, 0.13214783, 0.11355041, 0.08977848, 0.07204271,\n",
       "       0.12130768, 0.10706781, 0.0737294 , 0.09337481, 0.10549346,\n",
       "       0.09319575, 0.09676874, 0.08504732, 0.11878961, 0.07380761,\n",
       "       0.11887045, 0.09917834, 0.08645441, 0.09570853, 0.14973298,\n",
       "       0.12068505, 0.07448937, 0.09538496, 0.09043007, 0.0830638 ,\n",
       "       0.09265804, 0.11078419, 0.10357825, 0.11783247, 0.07826824,\n",
       "       0.0985873 , 0.10005684, 0.09029084, 0.08732433, 0.0819238 ,\n",
       "       0.15508923, 0.11545272, 0.08015172, 0.08523802, 0.08014194,\n",
       "       0.09492581, 0.07644479, 0.07243787, 0.10908374, 0.0883745 ,\n",
       "       0.11153253, 0.07483705, 0.09330999, 0.0924399 , 0.11912692,\n",
       "       0.07428218, 0.12882575, 0.1233738 , 0.12544532, 0.12164858,\n",
       "       0.09575433, 0.08927225])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Support Vecctor Regression\n",
    "#1 Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "#2 Importing the dataset\n",
    "# dataset = pd.read_csv(r'C:\\Users\\shubh\\Desktop\\IITM\\Courses\\Sem 2\\ML in civil eng\\term paper\\CE6051- vehicular emission data set - Sheet12.csv')\n",
    "dataset = pd.read_csv(r'C:\\Users\\shubh\\Desktop\\IITM\\Courses\\Sem 2\\ML in civil eng\\term paper\\vehicularemission_modified1.csv')\n",
    "#dataset=dataset[dataset['HC emissions (g/km)']<0.4]\n",
    "X = dataset.iloc[1:,0:5].values.astype(float)\n",
    "y = dataset.iloc[1:,7:8].values.astype(float)\n",
    "\n",
    "#3 selecting training dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\n",
    "\n",
    "#4 Fitting the Support Vector Regression Model to the dataset\n",
    "# Create your support vector regressor here\n",
    "from sklearn.svm import SVR\n",
    "# most important SVR parameter is Kernel type. It can be linear,polynomial or gaussian.\n",
    "#SVR. We have a non-linear condition so we can select polynomial or gaussian but here\n",
    "#we select RBF(a gaussian type) while here I substituted it with 'linear' kernel. \n",
    "regressor = SVR(kernel='rbf')\n",
    "regressor.fit(X_train, y_train, sample_weight=None)\n",
    "\n",
    "#5 finding results\n",
    "y_pred = regressor.predict(X_test)\n",
    "y_pred\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#6 obtaining plots \n",
    "plt.scatter(y_test, y_pred, color = 'black')\n",
    "plt.title('y_pred vs y_test')\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('y_pred')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "coef_ is only available when using a linear kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-c6813b421b88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#weight vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mcoef_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcoef_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'linear'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m             raise AttributeError('coef_ is only available when using a '\n\u001b[0m\u001b[0;32m    466\u001b[0m                                  'linear kernel')\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: coef_ is only available when using a linear kernel"
     ]
    }
   ],
   "source": [
    "#weight vector\n",
    "w = regressor.coef_\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7555342984327746"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.score(X_test, y_test, sample_weight = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age of vehicle</th>\n",
       "      <th>engine capacity (cc)</th>\n",
       "      <th>Fuel consumption (metric combined)</th>\n",
       "      <th>fuel type</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>Noise level (dB(A))</th>\n",
       "      <th>Nox emissions (g/km)</th>\n",
       "      <th>HC emissions (g/km)</th>\n",
       "      <th>CO2 emission (g/km)</th>\n",
       "      <th>CO emissions (g/km)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.306688</td>\n",
       "      <td>-0.863444</td>\n",
       "      <td>-1.689705</td>\n",
       "      <td>-1.277345</td>\n",
       "      <td>0.76859</td>\n",
       "      <td>-0.060878</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>104</td>\n",
       "      <td>0.063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age of vehicle  engine capacity (cc)  Fuel consumption (metric combined)  \\\n",
       "0       -2.306688             -0.863444                           -1.689705   \n",
       "\n",
       "   fuel type  gearbox  Noise level (dB(A))  Nox emissions (g/km)  \\\n",
       "0  -1.277345  0.76859            -0.060878                 0.018   \n",
       "\n",
       "   HC emissions (g/km)  CO2 emission (g/km)  CO emissions (g/km)  \n",
       "0                0.018                  104                0.063  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple Linear Regression\n",
    "#6 Fit multiple Linear Regression model to our Train set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#Create an object called regressor in the LinearRegression class...\n",
    "regr = LinearRegression()\n",
    "#Fit the linear regression model to the training set... We use the fit method\n",
    "#the arguments of the fit method will be training sets \n",
    "regr.fit(X_train,y_train)\n",
    "\n",
    "#7 Predicting the Test set results: \n",
    "y_pred= regr.predict(X_test)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred, color = 'black')\n",
    "plt.title('y_pred vs y_test')\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('y_pred')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.score(X_test, y_test, sample_weight = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.152\n",
      "Model:                            OLS   Adj. R-squared:                  0.144\n",
      "Method:                 Least Squares   F-statistic:                     19.43\n",
      "Date:                Mon, 19 Apr 2021   Prob (F-statistic):           8.18e-18\n",
      "Time:                        00:01:12   Log-Likelihood:                 1000.8\n",
      "No. Observations:                 547   AIC:                            -1990.\n",
      "Df Residuals:                     541   BIC:                            -1964.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0505      0.002     25.181      0.000       0.047       0.054\n",
      "x1             0.0075      0.002      3.956      0.000       0.004       0.011\n",
      "x2            -0.0101      0.004     -2.611      0.009      -0.018      -0.003\n",
      "x3             0.0199      0.004      4.491      0.000       0.011       0.029\n",
      "x4            -0.0030      0.003     -1.149      0.251      -0.008       0.002\n",
      "x5            -0.0009      0.002     -0.497      0.619      -0.004       0.003\n",
      "==============================================================================\n",
      "Omnibus:                      702.914   Durbin-Watson:                   2.164\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            93059.769\n",
      "Skew:                           6.361   Prob(JB):                         0.00\n",
      "Kurtosis:                      65.620   Cond. No.                         5.36\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X_train = sm.add_constant(X_train)\n",
    "model=sm.OLS(y_train,X_train).fit()\n",
    "predictions=model.predict(X_train)\n",
    "results=model.summary()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   24.26</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>1.74e-18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:01:18</td>     <th>  Log-Likelihood:    </th> <td>  1000.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   547</td>      <th>  AIC:               </th> <td>  -1991.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   542</td>      <th>  BIC:               </th> <td>  -1970.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0504</td> <td>    0.002</td> <td>   25.228</td> <td> 0.000</td> <td>    0.047</td> <td>    0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0074</td> <td>    0.002</td> <td>    3.927</td> <td> 0.000</td> <td>    0.004</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0107</td> <td>    0.004</td> <td>   -2.903</td> <td> 0.004</td> <td>   -0.018</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0207</td> <td>    0.004</td> <td>    4.947</td> <td> 0.000</td> <td>    0.012</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0031</td> <td>    0.003</td> <td>   -1.188</td> <td> 0.235</td> <td>   -0.008</td> <td>    0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>702.659</td> <th>  Durbin-Watson:     </th> <td>   2.160</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>92746.954</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 6.358</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>65.511</td>  <th>  Cond. No.          </th> <td>    5.03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.152\n",
       "Model:                            OLS   Adj. R-squared:                  0.146\n",
       "Method:                 Least Squares   F-statistic:                     24.26\n",
       "Date:                Mon, 19 Apr 2021   Prob (F-statistic):           1.74e-18\n",
       "Time:                        00:01:18   Log-Likelihood:                 1000.7\n",
       "No. Observations:                 547   AIC:                            -1991.\n",
       "Df Residuals:                     542   BIC:                            -1970.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0504      0.002     25.228      0.000       0.047       0.054\n",
       "x1             0.0074      0.002      3.927      0.000       0.004       0.011\n",
       "x2            -0.0107      0.004     -2.903      0.004      -0.018      -0.003\n",
       "x3             0.0207      0.004      4.947      0.000       0.012       0.029\n",
       "x4            -0.0031      0.003     -1.188      0.235      -0.008       0.002\n",
       "==============================================================================\n",
       "Omnibus:                      702.659   Durbin-Watson:                   2.160\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            92746.954\n",
       "Skew:                           6.358   Prob(JB):                         0.00\n",
       "Kurtosis:                      65.511   Cond. No.                         5.03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api  as sm \n",
    "#The 0th column contains only 1 in each 352 rows \n",
    "#X_train= np.append(arr = np.ones((544,1)).astype(int), values = X_train, axis=1) \n",
    "X_opt= X_train[:,[0,1,2,3,4]] #Optimal X contains the highly impacted independent variables\n",
    "#OLS: Oridnary Least Square Class. endog is the dependent variable, exog is the number of observations\n",
    "regressor_OLS=sm.OLS(endog = y_train, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   31.85</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>5.60e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:02:33</td>     <th>  Log-Likelihood:    </th> <td>  1000.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   547</td>      <th>  AIC:               </th> <td>  -1992.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   543</td>      <th>  BIC:               </th> <td>  -1975.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0495</td> <td>    0.002</td> <td>   27.241</td> <td> 0.000</td> <td>    0.046</td> <td>    0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0079</td> <td>    0.002</td> <td>    4.269</td> <td> 0.000</td> <td>    0.004</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0088</td> <td>    0.003</td> <td>   -2.651</td> <td> 0.008</td> <td>   -0.015</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0183</td> <td>    0.004</td> <td>    4.990</td> <td> 0.000</td> <td>    0.011</td> <td>    0.025</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>706.026</td> <th>  Durbin-Watson:     </th> <td>   2.162</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>93679.503</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 6.414</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>65.815</td>  <th>  Cond. No.          </th> <td>    4.33</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.150\n",
       "Model:                            OLS   Adj. R-squared:                  0.145\n",
       "Method:                 Least Squares   F-statistic:                     31.85\n",
       "Date:                Mon, 19 Apr 2021   Prob (F-statistic):           5.60e-19\n",
       "Time:                        00:02:33   Log-Likelihood:                 1000.0\n",
       "No. Observations:                 547   AIC:                            -1992.\n",
       "Df Residuals:                     543   BIC:                            -1975.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0495      0.002     27.241      0.000       0.046       0.053\n",
       "x1             0.0079      0.002      4.269      0.000       0.004       0.012\n",
       "x2            -0.0088      0.003     -2.651      0.008      -0.015      -0.002\n",
       "x3             0.0183      0.004      4.990      0.000       0.011       0.025\n",
       "==============================================================================\n",
       "Omnibus:                      706.026   Durbin-Watson:                   2.162\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            93679.503\n",
       "Skew:                           6.414   Prob(JB):                         0.00\n",
       "Kurtosis:                      65.815   Cond. No.                         4.33\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Optimal X contains the highly impacted independent variables\n",
    "#eliminating input parameters with p>0.05 significance level\n",
    "X_opt= X_train[:,[0,1,2,3]] \n",
    "regressor_OLS=sm.OLS(endog = y_train, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 4.66400000e+03 1.63000000e+01 ... 2.50000000e+07\n",
      "  6.25000000e+05 1.56250000e+04]\n",
      " [1.00000000e+00 4.66400000e+03 1.63000000e+01 ... 2.50000000e+07\n",
      "  6.25000000e+05 1.56250000e+04]\n",
      " [1.00000000e+00 5.99800000e+03 1.48000000e+01 ... 1.32710400e+10\n",
      "  1.59252480e+09 1.91102976e+08]\n",
      " ...\n",
      " [1.00000000e+00 1.46100000e+03 4.00000000e+00 ... 1.60000000e+09\n",
      "  3.20000000e+08 6.40000000e+07]\n",
      " [1.00000000e+00 1.46100000e+03 4.00000000e+00 ... 1.60000000e+09\n",
      "  3.20000000e+08 6.40000000e+07]\n",
      " [1.00000000e+00 1.46100000e+03 4.00000000e+00 ... 1.60000000e+09\n",
      "  3.20000000e+08 6.40000000e+07]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(686, 210)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#2 Importing the dataset: \n",
    "dataset = pd.read_csv(r'C:\\Users\\shubh\\Desktop\\IITM\\Courses\\Sem 2\\ML in civil eng\\term paper\\vehicularemission_modified1.csv')\n",
    "#y: dependent variable vector\n",
    "#In the first run X's type is object due to the different types of independent variables. \n",
    "#State column contains categorical variables\n",
    "X = dataset.iloc[1:,1:5].values.astype(float)\n",
    "y = dataset.iloc[1:,5:6].values.astype(float)\n",
    "\n",
    "#5 Splitting the dataset into the Training and Test dataset\n",
    "#train_set_split: Split arrays or matrices into random train and test subsets\n",
    "##random_state değeri sonuçların her seferinde aynı çıkmasını sağlamak için kullanılıyor.\n",
    "#%20 of the dataset to the test set\n",
    "\n",
    "transformer = PolynomialFeatures(degree=6, include_bias=True)\n",
    "transformer.fit(X)\n",
    "X_ = transformer.transform(X)\n",
    "X_ = PolynomialFeatures(degree=6, include_bias=True).fit_transform(X)\n",
    "print(X_)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X_, y, test_size=0.2, random_state=0)\n",
    "\n",
    "X_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = LinearRegression()\n",
    "#regressor=SVR(kernel='linear')\n",
    "#SVR(kernel='linear')\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04629948],\n",
       "       [ 0.02081914],\n",
       "       [ 0.02794136],\n",
       "       [ 0.03563784],\n",
       "       [ 0.02874198],\n",
       "       [ 0.05388214],\n",
       "       [ 0.05497093],\n",
       "       [ 0.03180469],\n",
       "       [ 0.01449678],\n",
       "       [ 0.04071731],\n",
       "       [ 0.04393128],\n",
       "       [ 0.06483855],\n",
       "       [ 0.07172089],\n",
       "       [ 0.1030815 ],\n",
       "       [ 0.0601585 ],\n",
       "       [ 0.04282588],\n",
       "       [ 0.0757962 ],\n",
       "       [ 0.05188157],\n",
       "       [ 0.04561303],\n",
       "       [ 0.03153522],\n",
       "       [ 0.03153522],\n",
       "       [ 0.04898354],\n",
       "       [ 0.03389362],\n",
       "       [ 0.04798465],\n",
       "       [ 0.04961154],\n",
       "       [ 0.0438541 ],\n",
       "       [-0.06758407],\n",
       "       [ 0.04073719],\n",
       "       [ 0.06256565],\n",
       "       [ 0.04580045],\n",
       "       [ 0.08169404],\n",
       "       [ 0.02571519],\n",
       "       [ 0.06080511],\n",
       "       [ 0.09423595],\n",
       "       [ 0.01907382],\n",
       "       [ 0.02341747],\n",
       "       [ 0.00774501],\n",
       "       [ 0.02483023],\n",
       "       [ 0.04840408],\n",
       "       [ 0.0556383 ],\n",
       "       [ 0.03683927],\n",
       "       [ 0.0090556 ],\n",
       "       [ 0.07256733],\n",
       "       [ 0.0461123 ],\n",
       "       [ 0.05858771],\n",
       "       [ 0.04282588],\n",
       "       [ 0.04282588],\n",
       "       [ 0.06599916],\n",
       "       [ 0.02960733],\n",
       "       [ 0.04983413],\n",
       "       [ 0.02544348],\n",
       "       [ 0.1049233 ],\n",
       "       [ 0.07025788],\n",
       "       [ 0.04707225],\n",
       "       [ 0.03389362],\n",
       "       [ 0.09871711],\n",
       "       [ 0.08169404],\n",
       "       [ 0.03313222],\n",
       "       [ 0.05790195],\n",
       "       [ 0.01307651],\n",
       "       [ 0.16383625],\n",
       "       [ 0.09142124],\n",
       "       [ 0.10885799],\n",
       "       [ 0.05993209],\n",
       "       [ 0.04165832],\n",
       "       [ 0.04707225],\n",
       "       [ 0.04797688],\n",
       "       [ 0.04759019],\n",
       "       [ 0.08290762],\n",
       "       [ 0.08290762],\n",
       "       [ 0.14165017],\n",
       "       [ 0.09047863],\n",
       "       [ 0.07975973],\n",
       "       [ 0.05695176],\n",
       "       [ 0.04903336],\n",
       "       [ 0.04093559],\n",
       "       [ 0.10455718],\n",
       "       [ 0.06468271],\n",
       "       [ 0.08166717],\n",
       "       [-0.00470473],\n",
       "       [ 0.03598474],\n",
       "       [ 0.09818592],\n",
       "       [ 0.05796065],\n",
       "       [ 0.08290762],\n",
       "       [ 0.04446702],\n",
       "       [ 0.04071731],\n",
       "       [ 0.04407229],\n",
       "       [ 0.04078458],\n",
       "       [ 0.10636179],\n",
       "       [ 0.04840623],\n",
       "       [ 0.07227759],\n",
       "       [ 0.06396741],\n",
       "       [ 0.03935965],\n",
       "       [ 0.02259458],\n",
       "       [ 0.023196  ],\n",
       "       [ 0.01864934],\n",
       "       [ 0.05002711],\n",
       "       [ 0.08266059],\n",
       "       [ 0.1049233 ],\n",
       "       [ 0.04138576],\n",
       "       [ 0.05518259],\n",
       "       [ 0.05006463],\n",
       "       [ 0.01782362],\n",
       "       [ 0.036141  ],\n",
       "       [ 0.04982395],\n",
       "       [ 0.01853262],\n",
       "       [ 0.0441735 ],\n",
       "       [ 0.04393128],\n",
       "       [ 0.05268156],\n",
       "       [ 0.0601741 ],\n",
       "       [ 0.04953332],\n",
       "       [ 0.05273564],\n",
       "       [ 0.03153522],\n",
       "       [ 0.03389362],\n",
       "       [ 0.05273564],\n",
       "       [ 0.04705954],\n",
       "       [ 0.04229258],\n",
       "       [ 0.02960733],\n",
       "       [-0.01563043],\n",
       "       [ 0.03755115],\n",
       "       [ 0.0248714 ],\n",
       "       [ 0.08616907],\n",
       "       [ 0.04162185],\n",
       "       [ 0.05927371],\n",
       "       [ 0.02616357],\n",
       "       [ 0.04399939],\n",
       "       [ 0.02896642],\n",
       "       [ 0.03289824],\n",
       "       [ 0.08616907],\n",
       "       [ 0.04901767],\n",
       "       [ 0.0470196 ],\n",
       "       [ 0.05849996],\n",
       "       [ 0.13906649],\n",
       "       [ 0.07287761],\n",
       "       [ 0.02259458],\n",
       "       [ 0.08316765],\n",
       "       [ 0.05188157],\n",
       "       [ 0.0489688 ]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X.shape[1] = 210 should be equal to 1, the number of features at training time",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-40755168beb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m         return r2_score(y, self.predict(X), sample_weight=sample_weight,\n\u001b[0m\u001b[0;32m    387\u001b[0m                         multioutput='variance_weighted')\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \"\"\"\n\u001b[1;32m--> 308\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    457\u001b[0m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[0;32m    458\u001b[0m                              \u001b[1;34m\"the number of features at training time\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m                              (n_features, self.shape_fit_[1]))\n\u001b[0m\u001b[0;32m    460\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X.shape[1] = 210 should be equal to 1, the number of features at training time"
     ]
    }
   ],
   "source": [
    "regressor.score(X_,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, y_pred, color = 'black')\n",
    "plt.title('y_pred vs y_test')\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('y_pred')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.000e+00 1.200e+01 2.953e+03 1.180e+01 1.000e+02 2.000e+00]\n",
      " [1.000e+00 1.100e+01 2.953e+03 1.180e+01 1.000e+02 2.000e+00]\n",
      " [1.000e+00 1.625e+01 4.164e+03 1.110e+01 1.000e+02 1.700e+01]\n",
      " ...\n",
      " [1.000e+00 7.580e+00 1.398e+03 3.800e+00 1.000e+02 2.000e+01]\n",
      " [1.000e+00 5.830e+00 1.398e+03 3.800e+00 1.000e+02 2.000e+01]\n",
      " [1.000e+00 4.830e+00 1.398e+03 3.500e+00 1.000e+02 2.000e+01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#2 Importing the dataset: \n",
    "dataset = pd.read_csv(r'C:\\Users\\shubh\\Desktop\\IITM\\Courses\\Sem 2\\ML in civil eng\\term paper\\vehicularemission_modified2.csv')\n",
    "#y: dependent variable vector\n",
    "#In the first run X's type is object due to the different types of independent variables. \n",
    "#State column contains categorical variables\n",
    "X = dataset.iloc[1:,1:6].values.astype(float)\n",
    "y = dataset.iloc[1:,6:7].values.astype(float)\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "print(X)\n",
    "\n",
    "#5 Splitting the dataset into the Training and Test dataset\n",
    "#train_set_split: Split arrays or matrices into random train and test subsets\n",
    "##random_state değeri sonuçların her seferinde aynı çıkmasını sağlamak için kullanılıyor.\n",
    "#%20 of the dataset to the test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y_train,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   8.679</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 14 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>1.18e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:42:31</td>     <th>  Log-Likelihood:    </th> <td>  11.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   281</td>      <th>  AIC:               </th> <td>  -10.27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   275</td>      <th>  BIC:               </th> <td>   11.56</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.5670</td> <td>    0.253</td> <td>    2.237</td> <td> 0.026</td> <td>    0.068</td> <td>    1.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.0193</td> <td>    0.004</td> <td>   -5.225</td> <td> 0.000</td> <td>   -0.027</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  5.27e-05</td> <td> 4.52e-05</td> <td>    1.165</td> <td> 0.245</td> <td>-3.63e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0258</td> <td>    0.014</td> <td>   -1.834</td> <td> 0.068</td> <td>   -0.053</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0009</td> <td>    0.002</td> <td>   -0.361</td> <td> 0.719</td> <td>   -0.006</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.0026</td> <td>    0.002</td> <td>   -1.164</td> <td> 0.245</td> <td>   -0.007</td> <td>    0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>175.154</td> <th>  Durbin-Watson:     </th> <td>   2.029</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1134.768</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.601</td>  <th>  Prob(JB):          </th> <td>3.88e-247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>11.358</td>  <th>  Cond. No.          </th> <td>3.97e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.97e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.136\n",
       "Model:                            OLS   Adj. R-squared:                  0.121\n",
       "Method:                 Least Squares   F-statistic:                     8.679\n",
       "Date:                Wed, 14 Apr 2021   Prob (F-statistic):           1.18e-07\n",
       "Time:                        17:42:31   Log-Likelihood:                 11.135\n",
       "No. Observations:                 281   AIC:                            -10.27\n",
       "Df Residuals:                     275   BIC:                             11.56\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.5670      0.253      2.237      0.026       0.068       1.066\n",
       "x1            -0.0193      0.004     -5.225      0.000      -0.027      -0.012\n",
       "x2           5.27e-05   4.52e-05      1.165      0.245   -3.63e-05       0.000\n",
       "x3            -0.0258      0.014     -1.834      0.068      -0.053       0.002\n",
       "x4            -0.0009      0.002     -0.361      0.719      -0.006       0.004\n",
       "x5            -0.0026      0.002     -1.164      0.245      -0.007       0.002\n",
       "==============================================================================\n",
       "Omnibus:                      175.154   Durbin-Watson:                   2.029\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1134.768\n",
       "Skew:                           2.601   Prob(JB):                    3.88e-247\n",
       "Kurtosis:                      11.358   Cond. No.                     3.97e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.97e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04204776],\n",
       "       [0.03607552],\n",
       "       [0.03835754],\n",
       "       [0.04351108],\n",
       "       [0.03766096],\n",
       "       [0.06188662],\n",
       "       [0.0557902 ],\n",
       "       [0.04120693],\n",
       "       [0.07727112],\n",
       "       [0.0503808 ],\n",
       "       [0.07691443],\n",
       "       [0.06904373],\n",
       "       [0.04884882],\n",
       "       [0.03685791],\n",
       "       [0.06531766],\n",
       "       [0.0435044 ],\n",
       "       [0.06855477],\n",
       "       [0.05829578],\n",
       "       [0.06195652],\n",
       "       [0.02217112],\n",
       "       [0.02217112],\n",
       "       [0.04921082],\n",
       "       [0.04236563],\n",
       "       [0.06701973],\n",
       "       [0.05393086],\n",
       "       [0.05221929],\n",
       "       [0.06372186],\n",
       "       [0.06693584],\n",
       "       [0.06501799],\n",
       "       [0.0550526 ],\n",
       "       [0.07086457],\n",
       "       [0.06477144],\n",
       "       [0.03380953],\n",
       "       [0.07405769],\n",
       "       [0.04299048],\n",
       "       [0.03725872],\n",
       "       [0.03601111],\n",
       "       [0.02533067],\n",
       "       [0.05176339],\n",
       "       [0.06328561],\n",
       "       [0.03728733],\n",
       "       [0.0606276 ],\n",
       "       [0.05101666],\n",
       "       [0.03153908],\n",
       "       [0.04736249],\n",
       "       [0.0435044 ],\n",
       "       [0.0435044 ],\n",
       "       [0.05192871],\n",
       "       [0.02448852],\n",
       "       [0.0561743 ],\n",
       "       [0.03163441],\n",
       "       [0.06431183],\n",
       "       [0.04653142],\n",
       "       [0.02844798],\n",
       "       [0.04236563],\n",
       "       [0.05546409],\n",
       "       [0.07086457],\n",
       "       [0.04505125],\n",
       "       [0.06526699],\n",
       "       [0.05690798],\n",
       "       [0.09251134],\n",
       "       [0.07337789],\n",
       "       [0.05196103],\n",
       "       [0.06422427],\n",
       "       [0.05103883],\n",
       "       [0.02844798],\n",
       "       [0.06294959],\n",
       "       [0.04787798],\n",
       "       [0.06326856],\n",
       "       [0.06326856],\n",
       "       [0.09078422],\n",
       "       [0.08343741],\n",
       "       [0.07150267],\n",
       "       [0.04112995],\n",
       "       [0.05567363],\n",
       "       [0.05029962],\n",
       "       [0.03661846],\n",
       "       [0.06672633],\n",
       "       [0.08056901],\n",
       "       [0.0868114 ],\n",
       "       [0.03435227],\n",
       "       [0.04570602],\n",
       "       [0.06727097],\n",
       "       [0.06326856],\n",
       "       [0.03688738],\n",
       "       [0.0503808 ],\n",
       "       [0.05080121],\n",
       "       [0.06336948],\n",
       "       [0.04721975],\n",
       "       [0.0550156 ],\n",
       "       [0.06237118],\n",
       "       [0.05577525],\n",
       "       [0.05816425],\n",
       "       [0.07504674],\n",
       "       [0.04067308],\n",
       "       [0.04192052],\n",
       "       [0.05882494],\n",
       "       [0.07597416],\n",
       "       [0.06431183],\n",
       "       [0.04240101],\n",
       "       [0.06892405],\n",
       "       [0.05292209],\n",
       "       [0.08074722],\n",
       "       [0.04442676],\n",
       "       [0.05036952],\n",
       "       [0.03581703],\n",
       "       [0.04332527],\n",
       "       [0.07691443],\n",
       "       [0.06150251],\n",
       "       [0.05796703],\n",
       "       [0.05019538],\n",
       "       [0.05686771],\n",
       "       [0.02217112],\n",
       "       [0.04236563],\n",
       "       [0.05686771],\n",
       "       [0.03076538],\n",
       "       [0.04570115],\n",
       "       [0.02448852],\n",
       "       [0.06273597],\n",
       "       [0.03613978],\n",
       "       [0.04015043],\n",
       "       [0.04643381],\n",
       "       [0.04700043],\n",
       "       [0.03496823],\n",
       "       [0.06245243],\n",
       "       [0.04692516],\n",
       "       [0.06152967],\n",
       "       [0.05550023],\n",
       "       [0.04643381],\n",
       "       [0.02896859],\n",
       "       [0.0469805 ],\n",
       "       [0.0633388 ],\n",
       "       [0.07904516],\n",
       "       [0.06874309],\n",
       "       [0.07504674],\n",
       "       [0.04494537],\n",
       "       [0.05829578],\n",
       "       [0.03342184]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Multiple Linear Regression Model \n",
    "#We will on modelling how R&D, Administration and Marketing Spending and the state will\n",
    "#influence the profit of a company. There are 50 startups data in dataset.\n",
    "\n",
    "#1 Importing the libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#2 Importing the dataset: \n",
    "dataset = pd.read_csv(r'C:\\Users\\shubh\\Desktop\\IITM\\Courses\\Sem 2\\ML in civil eng\\term paper\\vehicularemission_modified1.csv')\n",
    "#Y: dependent variable vector\n",
    "#In the first run X's type is object due to the different types of independent variables. \n",
    "#State column contains categorical variables\n",
    "X = dataset.iloc[1:,1:5].values.astype(float)\n",
    "y = dataset.iloc[1:,5:6].values.astype(float)\n",
    "\n",
    "#3 Encoding the categorical variables: \n",
    "#from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "#labelencoder_X = LabelEncoder() #Change the text into numbers 0,1,2\n",
    "#X[: ,3]= labelencoder_X.fit_transform(X[: ,3])\n",
    "#onehotencoder= OneHotEncoder(categorical_features=[3])\n",
    "#turn the numbers to dummy variables. Each column represents one state\n",
    "#Compare the X and dataset tables to understand the relationship between the state and the columns \n",
    "#X= onehotencoder.fit_transform(X).toarray()\n",
    "\n",
    "#4 Avoid the dummy variables trap\n",
    "#Delete the first column represent the California \n",
    "#X= X[:, 1:]\n",
    "\n",
    "#5 Splitting the dataset into the Training and Test dataset\n",
    "#train_set_split: Split arrays or matrices into random train and test subsets\n",
    "##random_state değeri sonuçların her seferinde aynı çıkmasını sağlamak için kullanılıyor.\n",
    "#%20 of the dataset to the test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#6 Fit multiple Linear Regression model to our Train set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#Create an object called regressor in the LinearRegression class...\n",
    "regressor = LinearRegression()\n",
    "#Fit the linear regression model to the training set... We use the fit method\n",
    "#the arguments of the fit method will be training sets \n",
    "regressor.fit(X_train,y_train)\n",
    "\n",
    "#7 Predicting the Test set results: \n",
    "y_pred= regressor.predict(X_test)\n",
    "y_pred\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEXCAYAAAC+mHPKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3X2YnHV97/H3d2c3kNlUJJP4GDILR3raKPQqiaj1obScIqYKvRQsughy5EqZlSM9Vlt167HiyVUfzinNqW5gK2BktgWkrSdtUS58AHs4VgkIKCIaOLsh4kOyi0ASNcnme/6Ye8Jkct8zv9m575nZ3c/ruubKzP00vzub3N/9/b6/B3N3REREmunrdgFERGR+UMAQEZEgChgiIhJEAUNERIIoYIiISBAFDBERCaKAITJHZvYXZlbudjlEOkUBQ2SBMbM7zOzSFK5zhpntTKNMsjAoYIgAZtbf7TKI9DoFDOl5ZvZeM/uHum1/Y2Z/3eS8O8zsL83sm2b2pJn9bzNbHu0bMjM3s3eY2Q7gK9H2l5vZ/zWzn5nZ/WZ2Rs31TjSzO83saTO7HVjR4LsfMrPX13zuN7PdZnaamR1rZmUzm46+524ze24a921mG4FXA580sz1m9slo+6+Z2e1mNmNmD5vZm2vOWW9m343u64dm9h4zGwS+ALwgus4eM3tBo79vWQTcXS+9evoFPB/YCzw7+twP/BRY2+S8O4AfAi8BBoF/AMrRviHAgc9G+5YCLwSmgfVUfpn6vejzyuicrwN/BRwDvAZ4unq9mO/+b8BEzeffB74Xvf8j4J+BPJAD1gLPSvm+L635PAg8BlwSXeM0YDfw4mj/j4BXR++PB06L3p8B7Oz2z1+v3nmphiE9z91/BHwNOD/adDaw293vCTj9Bnf/jrvvBT4IvNnMcjX7/8Ld97r7z4ELgVvd/VZ3P+TutwPbgPVmthp4KfBBd/+lu3+NykM/yd8B55hZPvr81mgbwAGgALzI3Wfd/R53fyrl+671emDS3a9394Pufi+V4HleTXnWmNmz3P2JaL/IURQwZL7YQuWBTvTnDYHnPVbzfgoY4MimpNr9ReD8qJnoZ2b2M+BVVH7TfwHwRBR4aq8Xy923Aw8Bb4iCxjk8EzBuAG4DbjSzx83s42Y2kHCpud53rSLwsrr7GgaeF+1/E5Va1VTU5PaKOXyHLAIKGDJffB441cxeQuU35onA806oeb+aym/Tu2u21U7X/BiVGsmza16D7v5RKs02x0dt+7XXa+TvgbcA5wLfjYII7n7A3T/s7muA34ru56KEa8zlvuunoH4MuLPuvpa5eykqz93ufi7wnOj7bk64jixyChgyL7j7L4BbqPyW/k133xF46oVmtib6Lf9K4BZ3n004tkylRvBaM8tFyekzzGyVu09RaZ76sJktMbNXAW9o8t03AmcBJZ6pXWBmv2Nmp0RNY09RCWKxZZrjff8EOKnm878Av2pmbzOzgej1UjP79ehehs3sOHc/EJVntuY6BTM7LuA7ZRFQwJD5ZAtwCq01y9wAfAb4MXAs8K6kA939MSq1gQ8Au6j8Zv5envl/8lbgZcAM8CEqCfNEUQ7i61RqETfV7HoelSDwFJVmqzupBKskrd73JuA8M3vCzP6Xuz9NJXBdADxO5e/iY1SS9wBvAybN7CngMqImMHf/HpVa0qNRU5Z6SS1y5q5ap8wPUeL5e8Dz4pLEMcffQaUX06ezLluWWr1vkayohiHzgpn1Ae8GblxMD83Fet/SmzS6VXpelGj+CZVeSWfX7duTcNrrsi5X1uZ63+7+b1mXTRYnNUmJiEgQNUmJiEgQBQwREQmyoHIYK1as8KGhoW4XQ0RkXrnnnnt2u/vKZsctqIAxNDTEtm3bul0MEZF5xcwSp7mppSYpEREJooAhIiJBFDBERCSIAoaIiARRwBARkSAKGCIiEkQBQ0REgihgiIhIEAUMEREJooAhIiJBFDBERCSIAoaIiARRwBARkSAKGCIiEkQBQ0REgihgiIhIEAUMEREJknnAMLOzzexhM9tuZu+L2f8aM7vXzA6a2Xl1+y42sx9Er4uzLquIiCTLNGCYWQ74FPA6YA3wFjNbU3fYDuDtwN/Vnbsc+BDwMuB04ENmdnyW5RURkWRZ1zBOB7a7+6Puvh+4ETi39gB3n3T3B4BDdee+Frjd3Wfc/QngduDsjMsrIiIJsg4YLwQeq/m8M9qW9bkiIpKyrAOGxWzzNM81sw1mts3Mtu3ataulwomISLisA8ZO4ISaz6uAx9M8193H3X2du69buXLlnAsqIiKNZR0w7gZONrMTzWwJcAGwNfDc24CzzOz4KNl9VrRNRES6INOA4e4HgcupPOgfAm529wfN7EozOwfAzF5qZjuB84FrzOzB6NwZ4CNUgs7dwJXRNhER6QJzD00p9L5169b5tm3bul0MEZF5xczucfd1zY7TSG8REQmigCEiIkEUMEREJIgChoiIBFHAEBGRIAoYIiISRAFDRESCKGBIV01MTDA0NERfXx9DQ0NMTEx0u0gikqC/2wWQxWtiYoINGzawb98+AKamptiwYQMAw8PD3SyaiMRQDUO6ZnR09HCwqNq3bx+jo6NdKpGINKKAIR0R1/S0Y8eO2GOTtotId6lJSjKX1PS0fPlypqenjzp+9erVnS6iiARQDUMyl9T0BJDP54/Yns/n2bhxY8fKJiLhFDAkc0lNTDMzM4yPj1MsFjEzisUi4+PjSniL9ChNby6ZGxoaYmpq6qjtxWKRycnJzhdIRI6g6c2lZ2zcuFFNTyILgAKGZG54eFhNTyILgJqkREQWOTVJZUDTWIjIYqZxGIE0jYWILHaqYQTSNBYistgpYATSNBYistgpYARKmq5C01iIyGKhgBFIYwlEZLFTwAiksQQistgpYLRgeHiYyclJDh06xOTkZEeChbryikivULfaHqauvCLSS1TD6GHqyisivUQBo4epK6+I9BIFjB6mrrwi0ksUMHqYuvLKfKHOGYtD5gHDzM42s4fNbLuZvS9m/zFmdlO0/xtmNhRtHzCzLWb2bTN7yMzen3VZe003u/LqASChqp0zpqamcPfDnTP0b2YBcvfMXkAOeAQ4CVgC3A+sqTtmBLg6en8BcFP0/q3AjdH7PDAJDDX6vrVr17q0r1wuez6fd+DwK5/Pe7lc7nbRpAcVi8Uj/q1UX8VisdtFk0DANg94pmddwzgd2O7uj7r7fuBG4Ny6Y84FtkTvbwHONDOL/tENmlk/sBTYDzyVcXkF9c6S1qhzxuKRdcB4IfBYzeed0bbYY9z9IPAkUKASPPYCPwJ2AP/D3WcyLm/X9FITkB4A0gp1zlg8sg4YFrOtfom/pGNOB2aBFwAnAn9iZicd9QVmG8xsm5lt27VrV7vl7YpeawPWA0Baoc4Zi0fWAWMncELN51XA40nHRM1PxwEzVHIYX3T3A+7+U+Au4KglBN193N3Xufu6lStXZnAL2eu1JiA9AKQVmmdt8cg6YNwNnGxmJ5rZEipJ7a11x2wFLo7enwd8JUrC7AB+1yoGgZcD38u4vKlppYmp15qA9ACQVnVjnjXpPKs8mzP8ArP1wF9T6TF1nbtvNLMrqWTlt5rZscANwG9SqVlc4O6Pmtky4HpgDZVmq+vd/RONvmvdunW+bdu2LG+nqZGREa655hoOHTp0xPZ8Pp/40B0aGmJqauqo7cVikcnJyayKKiICgJnd4+5HteAcdVzWAaOTuh0wRkZG2Lx5c+L+pABQP8kgNA4wIiJpCg0YGumdovHx8Yb7k5qYQpqAeqkXlYgsTqphpKgyfCTZXJuYVAMRkSyphtEFuVwucV9SL6ORkRH6+/sxM/r7+xkZGTnqmF7rRSUii5MCRoqqixvVGxwcjK0NVHMes7OzAMzOzrJ58+ajgkav9aISkcVJASNFY2NjlEqlwzWNXC5HqVRiz549sU1HSTmPa6655ojPGkgnIr1AASNlY2NjHDx4EHfn4MGDjI2NJR5brVnUO3To0BFJ7biBdGbG+vXr0ym0iEgABYwuapTzqM1PDA8Pc/HFFx+RVHd3tmzZot5SItIxChhdlJTzgKPzE7feeiv1PdqU+BaRTlLA6KKxsTEGBwdj99XnJ5T4FpFuU8DosPoBeBdddFHQRH9KfItItylgdFDcNObXXnvtEbmJQqEQ2wW3l2aQ1ahzkcVJAaOD4gbg7d+/n7179x7+/POf/zz23F6ZQbbX1u4Qkc7R1CAd1NfXd1TiOk4vz1KrmXVFFh5NDdKDQvMNvZzIVvJdZPFSwOiguDxEHHefc24g6/yCku8ii5cCRoctXbr08PvBwUEGBgZij2uUG0gKCp3IL/RS8l1EOszdF8xr7dq13qvK5bLn83kHDr/y+byXSiUvFotHbK99FYvFoOuUy+XE69RfI417KRaLbmZeLBa9XC6nen0R6SwqK6A2fcYq6d0hzZLFSQlxMztiuddG19mxY0fQNUREainp3QW1TUUrVqxgxYoVh5uN4h7y8EyyODQ30CjprPyCiGRJASMl9fmD6elppqenD+cSklbjqz7MQ3MDy5cvj73O8uXLlV8QWeC6Pmg2pN1qvry6mcNolIeovswsNvdQFZIbKBQKsdcuFArB1xCR+adR/rJdKIfRWa0Myqs2H23cuLHlkdqhuQ4RWViyHDSrHEaHheYJpqamDjcfJQWLRtVO5SlEFqdeGDSrgJGS0EF5ANPT01xyySWJYyzqx1JceOGFrFixgomJCeUpRBapXvhlUQEjJfWTAxYKBQqFQuLxBw4ciF38KG6CQqgEmeqCS52ahHBkZIT+/n7MjP7+fkZGRlo6v+sJOpEFpCd+WQxJdMyXV9ZJ77kklOsT3dQlwVs5ngwG4SUplUqx318qlYLOzzJBJ7JYZdWphcCkd9cf8mm+sgwYrTwAG426jnv4l8tlP/bYY5senxRkspDL5WK/P5fLBZ3fqVHnItK+0IDRsJeUmX07+o+eVDs5tUkFpqOy7CUV2kOhmoOIa1aqNTAwwPXXX89dd93F5s2bg8vRqWnEk8aNAEG9wdSbS2T+SKuX1OuBNwBfjF7D0etW4JZ2CzmfhPZQSMpB1Lv00ksBuPrqq4PL0G57ZSs5hVwu19L2er2QoBORlIVUQ4C7QrZ1+5Vlk1RoE0vcMUnnhTRbVV9mFpw/iNNqTkE5DJHFgzRzGMB9wKtqPv8WcF/IuZ18dTuHUS6XmyatawNA6LFJwakVc8kplEqlw7mMXC7XcsDSqHOR+SE0YASN9DaztcB1wHHRg+ZJ4D+7+71NT+6gNHMYExMTjI6OHjEqGzhqW2131kaTDNYrFosAwcdDe+3/yimISJLQHEZ/yMXc/R7gN8zsWVTWAX+yhYKcDWwCcsCn3f2jdfuPAT4LrAWmgT9098lo36nANcCzgEPAS939F6HfPVf1ievqQkTj4+MNE86hIy5rcxEhCfKqdtr/V69eHRuclFMQkWAh1RDgucC1wBeiz2uAdwSclwMeAU4ClgD3A2vqjhkBro7eXwDcFL3vBx4AfiP6XAByjb4vrSapuXYJTTqvUCgkNs2Uy2Xv6+tr2hzVbvu/cgoikoSUcxhfAN4M3O/PPMy/HXDeK4Dbaj6/H3h/3TG3Aa+oue5uwID1QDmkfNVXWgEjKbfQbAzEXB/K5XLZlyxZcsR5/f39XigUUm3/V05BROKkHTDujv78Vs22pklv4DwqzVDVz28DPll3zHeAVTWfHwFWAH8M3BAFlHuBP034jg3ANmDb6tWrU/nLa2fQWehDuf646lKtepiLSKelHTDuiJqE7o0+vxy4M+C882MCxt/UHfNgTMAoAO8B/l8UPPLA14EzG31fWjWMdmoK1WBT7V0U9/APvX5c8FEtQUTSlnbAOA24i0rvqLuA7wOnBpzXTpPUBcBnao77IPDeRt+XZrfaVh/McUEgKRiE1GDirjcwMHBU05XyECLSrtCA0bRbrZn1RTWKbwL/MXqYP+zuBxqeWDm3PwouZwI/BO4G3uruD9Yc807gFHe/zMwuAN7o7m82s+OBLwOvAvZTGWl+lbv/a9L3dXMBpWZdamun9Ajp4tpqF91OTBciIgtTat1q3f2Qmf1Pd38FleajYO5+0Mwup1KLyAHXufuDZnYllYi2lUrvqxvMbDswQ6Vmgbs/YWZ/RSXIOHBro2DRbc261NbuT+ri6u6YGblcjtnZ2dS+W0QkDaED9z5MpYvrP3rICV3SzRrGihUrmJ6eTtxfWwsInaAwlGoYItKOtJdofTfwOWC/mT1lZk+b2VNtlXARyefzrF+/nqGhIcyMiy++mH379gVP5FeVy+VYsmTJUdv37NlzxESCWrhIRLIQVMOYL7pZw0jKSwCUSiW2bNkSW6PI5/PBNY2BgQEuvfRSbr755qNqM/l8nvHxcSB+9HihUGDTpk2ZrMwnIvNbaA0jOGCY2RupJKAd+Dd3/3x7RUxfLzZJFQoFli1b1tKcUY00moOq2fxU1aCioCEitVINGGY2BrwI+Pto0x8Cj7j7O9sqZcp6NWDMzMwk1j5aVV3YKKmXVdK+KuU7RKRe2jmM3wZe6+7Xu/v1VKbtOKON8i04MzMziduXL1/e8NxisUipVKKvr/mPY/Xq1Q0XJ2o2maB6VInIXIUGjIeB2ifRCVR6TUkk6UG9fPlynn766cTzqjPXjo2NMTs7S7lcPty0VL9MavXYjRs3ks/ng/eFlFNEpKmQ0X3AncA+KlOE3AHsBb4EbAW2hlyjE68sF1BqJmm6j0KhkDgDbbMR5I1GmzfbF/e9GhUuInFIeQGl324SdO5sNVBloZs5DDhy0aVqM1SjsRnlcjnTBHTcIlBKeItIvdR7STX5sq97ZSR4V3U7YFSFDsyrJqD1YBeRbko76d3MsSldZ0EYHR0NGlsxNTV1OLhMTU3h7odX92s02E4D80SkG9KqYdzr7qelUJ629EoNo9Egvlq5XI5Vq1YljqmI6/4aV3vR+AoRaUenaxgCjIyM0N/fHzzmYnZ2NnGQXVL317jay759+xgdHT1im2ohIpK2oIBhZpdH040nHpJSeeatkZERNm/e3NIss40kdX9NCiS12+fSzCUi0kxoDeN5wN1mdrOZnW31AwQqK+ktatV5nNJQHVMRJymQ9PX1HQ4IobUQEZFWNF0PA8Dd/9zMPgicBVwCfNLMbgaudfdH3P07WRZyPkirZlEsFhN7SU1MTLBnz57E79+wYQMQVgsREWlVUMAAcHc3sx8DPwYOAscDt5jZ7e7+p1kVcL4IWfSoUCgAyWMzGs3zFNJVt1qLSFqgSaO8RaQdoTmMd5nZPcDHqazpfYq7l4C1wJsyLN+8Uf3tPk6xWKRcLrN79242bdoUu6bFwMBAYjMUhHfV3bFjR8OpQ0RE5ixkODhwJVBM2PfrIdfoxKubU4O4u5dKJc/lcg54LpfzUqkUe1z91B2Dg4NeKBRip/moMrPEKUaom26k+h1JU4eIiNQicGqQrj/k03x1O2A0kvQAT5qDqlQqHRFUQgKG5ooSkblQwOghSUGhGkRCag4hr7kEi9BakYgsXKEBQ0u0dsDQ0FBsEjrNxZXmsjBSdexIvVKpxNjYWNtlEpH5QSO9u6x2pHXSaO7p6emmiyuFMLM5JbSTxo6kOaZERBaO4G61Em5iYoJLLrmEAwcOBB2fz+eDekAlueyyy+Y0j1RSN+C0xpSIyMKiGkYGrrjiiuBgMTMz09Zv9MuWLeOVr3zlnM7N5XItbReRxU0BIwONFk2qt3r1aoaHhw8vy5qkUChQKpUOD/6r2rNnz5zniUoaO9JoTImILF4KGF1kZqxfvx4gcbBduVzG3dm9ezdjY2MsW7bsqOvMdZ6osbExSqXS4RpFLpdTwltEkoV0pZovr251q60fY7Fs2bLgrrC1YydCBtsljccws07ftogsEKhbbWfEzfE0MDDA7Owshw4dCrpGK11ik7rozqVbrYgIqFttx1xxxRVH9XA6cOBAcLCA1maR1TxRItItChhtmJiYaCnBnaSVsRjDw8OMj49TLBYxM4rFopZnFZGOUJNUG5Kah1o1ODiYuM6FiEjWeqZJKlqh72Ez225m74vZf4yZ3RTt/4aZDdXtX21me8zsPVmXtVVpLUi0d+/eVK4jIpKlTAOGmeWATwGvA9YAbzGzNXWHvQN4wt1fBFwFfKxu/1XAF7Is51xpQSIRWUyyrmGcDmx390fdfT9wI3Bu3THnAlui97cAZ1bXDDezPwAeBR7MuJxzEpeAnov6wXgiIr0o64DxQuCxms87o22xx7j7QeBJoGBmg8CfAR/OuIxzVp+AnoslS5awadOmlEsmIpK+rANG3FO0PsuedMyHgavcvWE22Mw2mNk2M9u2a9euORZz7oaHh5mcnOTQoUNNp/eASoAoFAqHezhdd911bfVwqp0Vd2hoaE5ThIiIhMg6YOwETqj5vAp4POkYM+sHjgNmgJcBHzezSeCPgQ+Y2eX1X+Du4+6+zt3XrVy5Mv07CFB9aE9NTR1V04gLELt37+bQoUNMTk62HSw2bNjA1NQU7s7U1NSc55USEWkqZDj4XF9Upk9/FDgRWALcD7y47ph3AldH7y8Abo65zl8A72n2fd2YGiRuNb3q9B2N1tKunwakVCq1vAZ30mp91XW9RURC0CtLtALrge8DjwCj0bYrgXOi98cCnwO2A98EToq5Rs8GjLk8tEulUtM1uhutz91saVfNKyUirQgNGBq416a+vj7i/g7NLHZ6kImJCS688MKga8fNDxU3d1XIeSIiSXpm4N5ClzQWY2BggP7+fsyM/v5+RkZGgMrcU6HiBgaOjo42DBaaV0pEsqKA0aaNGzeyZMmSo7bv37//8FKns7OzbN68mZGRkZYXV6rXaHS55pUSkSypSSoFK1asSGUSwlr5fD724a/pzUUkbWqS6qCZmZlUr5fL5RJrCpreXES6RQEjBWnOKZXP59myZUtis5KmNxeRblHASEFac0oBLF26tOkxtaPL2x38JyISSgEjBXG/9Z955pnkcrmWrzU9Pa3R2iLSk5T07oC5TEyoJLaIdIqS3j0kZFLCemktziQikhYFjBQ0mzG2UY6jry/+R6DFmUSk1/R3uwDzXf1UHdUZY4HDyejqn1dcccVR4zXipg9RN1kR6UXKYbSplYF0ScdCJc/h7hSLRTZu3KieTyLSMaE5DNUw2pSUa4jb3igvUQ0WSnSLSK9SDqNNSbmGuO3N8hJKdItIL1PAaFMrU3U0G+AXmujWsqwi0g0KGG1qZaqO6rGFQiH2Wnv27Dni4R8XGLQsq4h0i5LeXTIxMRHba6o6Sy1w1EJJ+XyepUuXxs6Mq/yHiMxVaNJbAaOLGvWwAhJ7VMVJWuFPRKQZ9ZKaB1rpYdWMBvqJSNaUw+iiRj2skvYVCgWthyEiXaGA0UWNelgl7du0aZPWwxCR7nD3BfNau3at96pyuezFYtHNzIvFopfL5Ybbm+0TEUkLsM0DnrFKendA/XxTkLxmt4hIp2l68w6rjpkwM/r7+zGzw2MnRkdHjwgWAPv27WN0dLRLpRURaZ1qGCmIq0FU5fP52O2grrAi0htUw+iguBpE1b59+xKXalVXWBGZTxQwUtBs3MTs7Ky6worIvKeAkYJmNYVq11d1hRWR+Uwjvds0MjLScAqPak1ieHhYAUJE5jXVMNowMjLC5s2bE/erJiEiC4lqGG2oziobR7PHishCk3kNw8zONrOHzWy7mb0vZv8xZnZTtP8bZjYUbf89M7vHzL4d/fm7WZe1VbOzs4n7tHqeiCw0mQYMM8sBnwJeB6wB3mJma+oOewfwhLu/CLgK+Fi0fTfwBnc/BbgYuCHLss5FUndZUJdZEVl4sq5hnA5sd/dH3X0/cCNwbt0x5wJbove3AGeambn7t9z98Wj7g8CxZnZMxuVtyYYNG2K353I5dZkVkQUn64DxQuCxms87o22xx7j7QeBJoH4N0zcB33L3X2ZUzjkZGxujVCrR1/fMX+Pg4CBbtmxRoltEFpysk94Ws61+LpKGx5jZi6k0U50V+wVmG4AN0J1moLGxMcbGxjr+vSIinZZ1DWMncELN51XA40nHmFk/cBwwE31eBfwTcJG7PxL3Be4+7u7r3H3dypUrUy6+iIhUZR0w7gZONrMTzWwJcAGwte6YrVSS2gDnAV9xdzezZwP/Crzf3e/KuJwiItJEpgEjyklcDtwGPATc7O4PmtmVZnZOdNi1QMHMtgPvBqpdby8HXgR80Mzui17PybK8IiKSTNObi4gscpreXEREUqWAISIiQRQwREQkiAKGiIgEUcAQEZEgChgiIhJEAUNERIIoYIiISBAFDBERCaKAISIiQRQwREQkiAKGiIgEUcAQEZEgChgiIhJEAUNERIIoYIiISBAFDBERCaKAISIiQRQwREQkiAKGiIgEUcAQEZEgChgiIhJEAUNERIIoYIiISBAFDBERCaKAISIiQRQwREQkiAKGiIgEMXfvdhlSY2a7gKmUL7sC2J3yNXvJQr8/WPj3uNDvDxb+PXb7/oruvrLZQQsqYGTBzLa5+7pulyMrC/3+YOHf40K/P1j49zhf7k9NUiIiEkQBQ0REgihgNDfe7QJkbKHfHyz8e1zo9wcL/x7nxf0phyEiIkFUwxARkSAKGCIiEkQBAzCzs83sYTPbbmbvi9l/jJndFO3/hpkNdb6U7Qm4x9eY2b1mdtDMzutGGdsRcH/vNrPvmtkDZvZlMyt2o5ztCLjHy8zs22Z2n5n9HzNb041ytqPZPdYcd56ZuZn1fFfUWgE/w7eb2a7oZ3ifmV3ajXImcvdF/QJywCPAScAS4H5gTd0xI8DV0fsLgJu6Xe4M7nEIOBX4LHBet8ucwf39DpCP3pcW6M/wWTXvzwG+2O1yp32P0XG/AnwN+HdgXbfLnfLP8O3AJ7td1qSXahhwOrDd3R919/3AjcC5dcecC2yJ3t8CnGlm1sEytqvpPbr7pLs/ABzqRgHbFHJ/X3X3fdHHfwdWdbiM7Qq5x6dqPg4C861HS8j/RYCPAB8HftHJwqUg9P56lgIGvBB4rObzzmhb7DHufhB4Eih0pHTpCLnH+azV+3sH8IXYuZKKAAADmElEQVRMS5S+oHs0s3ea2SNUHqjv6lDZ0tL0Hs3sN4ET3P1fOlmwlIT+O31T1HR6i5md0JmihVHAgLiaQv1vZiHH9LL5Xv5mgu/PzC4E1gGfyLRE6Qu6R3f/lLv/B+DPgD/PvFTpaniPZtYHXAX8ScdKlK6Qn+E/A0PufirwJZ5p2egJChiVKF8bxVcBjycdY2b9wHHATEdKl46Qe5zPgu7PzP4TMAqc4+6/7FDZ0tLqz/BG4A8yLVH6mt3jrwAvAe4ws0ng5cDWeZT4bvozdPfpmn+bfwus7VDZgihgwN3AyWZ2opktoZLU3lp3zFbg4uj9ecBXPMpQzRMh9zifNb2/qCnjGirB4qddKGO7Qu7x5JqPvw/8oIPlS0PDe3T3J919hbsPufsQlVzUOe6+rTvFbVnIz/D5NR/PAR7qYPma63bWvRdewHrg+1R6MIxG266k8o8R4Fjgc8B24JvASd0ucwb3+FIqvwHtBaaBB7td5pTv70vAT4D7otfWbpc5g3vcBDwY3d9XgRd3u8xp32PdsXcwj3pJBf4M/zL6Gd4f/Qx/rdtlrn1pahAREQmiJikREQmigCEiIkEUMEREJIgChoiIBFHAEMmAmQ2Z2VvbOP8DaZZHJA0KGCLZGALmHDAABQzpOQoYIi0ws4+Y2RU1nzeaWdycTR8FXh1NUf1fzSxnZp8ws7ujeYL+KDr/+Wb2tei475jZq83so8DSaNtEh25NpCmNwxBpQbQWyj+6+2nR3EY/AE539+m6484A3uPur48+bwCe4+7/3cyOAe4CzgfeCBzr7hvNLEdlCvanzWyPuy/r2I2JBOjvdgFE5hN3nzSz6WiqkecC36oPFgnOAk6tWZzqOOBkKtNFXGdmA8Dn3f2+TAoukgIFDJHWfZrKQjfPA64LPMeA/+Lutx21w+w1VOZ+usHMPuHun02roCJpUg5DpHX/BJxNZf6towJA5Gkqs6tW3QaUopoEZvarZjYYLRX7U3f/W+Ba4LTo+APVY0V6hWoYIi1y9/1m9lXgZ+4+m3DYA8BBM7sf+AyViQGHgHuj1Rp3UZl+/AzgvWZ2ANgDXBSdPw48YGb3uvtwVvci0golvUVaFCW77wXOd/f5NoW4yJypSUqkBWa2hso0919WsJDFRjUMkTaY2SnADXWbf+nuL+tGeUSypIAhIiJB1CQlIiJBFDBERCSIAoaIiARRwBARkSAKGCIiEkQBQ0REgvx/t53zR30RtlgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, y_pred, color = 'black')\n",
    "plt.title('y_pred vs y_test')\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('y_pred')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08780257188201801"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.score(X_test, y_test, sample_weight = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(687, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   21.01</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 14 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>2.40e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:16:34</td>     <th>  Log-Likelihood:    </th> <td>  1197.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   686</td>      <th>  AIC:               </th> <td>  -2385.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   681</td>      <th>  BIC:               </th> <td>  -2362.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0106</td> <td>    0.005</td> <td>    2.013</td> <td> 0.045</td> <td>    0.000</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0106</td> <td>    0.005</td> <td>    2.013</td> <td> 0.045</td> <td>    0.000</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-2.477e-05</td> <td> 4.83e-06</td> <td>   -5.125</td> <td> 0.000</td> <td>-3.43e-05</td> <td>-1.53e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0129</td> <td>    0.002</td> <td>    7.585</td> <td> 0.000</td> <td>    0.010</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0001</td> <td> 5.05e-05</td> <td>   -2.193</td> <td> 0.029</td> <td>   -0.000</td> <td>-1.16e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.0001</td> <td>    0.000</td> <td>   -0.518</td> <td> 0.605</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>915.179</td> <th>  Durbin-Watson:     </th>  <td>   1.751</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>156804.456</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 6.913</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>75.765</td>  <th>  Cond. No.          </th>  <td>2.99e+17</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 3.71e-26. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.110\n",
       "Model:                            OLS   Adj. R-squared:                  0.105\n",
       "Method:                 Least Squares   F-statistic:                     21.01\n",
       "Date:                Wed, 14 Apr 2021   Prob (F-statistic):           2.40e-16\n",
       "Time:                        16:16:34   Log-Likelihood:                 1197.5\n",
       "No. Observations:                 686   AIC:                            -2385.\n",
       "Df Residuals:                     681   BIC:                            -2362.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0106      0.005      2.013      0.045       0.000       0.021\n",
       "x1             0.0106      0.005      2.013      0.045       0.000       0.021\n",
       "x2         -2.477e-05   4.83e-06     -5.125      0.000   -3.43e-05   -1.53e-05\n",
       "x3             0.0129      0.002      7.585      0.000       0.010       0.016\n",
       "x4            -0.0001   5.05e-05     -2.193      0.029      -0.000   -1.16e-05\n",
       "x5            -0.0001      0.000     -0.518      0.605      -0.001       0.000\n",
       "==============================================================================\n",
       "Omnibus:                      915.179   Durbin-Watson:                   1.751\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           156804.456\n",
       "Skew:                           6.913   Prob(JB):                         0.00\n",
       "Kurtosis:                      75.765   Cond. No.                     2.99e+17\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 3.71e-26. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Building the optimal Model using Backward Elimination\"\"\" \n",
    "#The backwards elimination function will give us the optimal variables from our data,\n",
    "# Beta0 has x^0=1. Add a column of for the the first term of the MultiLinear Regression equation.\n",
    "import statsmodels.formula.api  as sm \n",
    "#The 0th column contains only 1 in each 352 rows \n",
    "X= np.append(arr = np.ones((686,1)).astype(int), values = X, axis=1) \n",
    "X_opt= X[:,[0,1,2,3,4,5]] #Optimal X contains the highly impacted independent variables\n",
    "#OLS: Oridnary Least Square Class. endog is the dependent variable, exog is the number of observations\n",
    "regressor_OLS=sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary() \n",
    "\n",
    "#constant for Beta0, x1 and x2 are the dummy variables for state, x3 is R&D,\n",
    "#x4 is Administration, x5 is the marketing spends \n",
    "#Look at the highest p-values and remove it. In this condition x2(second \n",
    "#dummy variable has the highest one (0,990)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   27.95</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 14 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>4.71e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:17:10</td>     <th>  Log-Likelihood:    </th> <td>  1197.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   686</td>      <th>  AIC:               </th> <td>  -2387.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   682</td>      <th>  BIC:               </th> <td>  -2369.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0095</td> <td>    0.005</td> <td>    1.978</td> <td> 0.048</td> <td> 6.81e-05</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0095</td> <td>    0.005</td> <td>    1.978</td> <td> 0.048</td> <td> 6.81e-05</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-2.546e-05</td> <td> 4.65e-06</td> <td>   -5.479</td> <td> 0.000</td> <td>-3.46e-05</td> <td>-1.63e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0131</td> <td>    0.002</td> <td>    8.134</td> <td> 0.000</td> <td>    0.010</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0001</td> <td> 5.04e-05</td> <td>   -2.215</td> <td> 0.027</td> <td>   -0.000</td> <td>-1.27e-05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>916.121</td> <th>  Durbin-Watson:     </th>  <td>   1.753</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>157460.998</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 6.926</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>75.918</td>  <th>  Cond. No.          </th>  <td>1.28e+18</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 2.03e-27. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.109\n",
       "Model:                            OLS   Adj. R-squared:                  0.106\n",
       "Method:                 Least Squares   F-statistic:                     27.95\n",
       "Date:                Wed, 14 Apr 2021   Prob (F-statistic):           4.71e-17\n",
       "Time:                        16:17:10   Log-Likelihood:                 1197.3\n",
       "No. Observations:                 686   AIC:                            -2387.\n",
       "Df Residuals:                     682   BIC:                            -2369.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0095      0.005      1.978      0.048    6.81e-05       0.019\n",
       "x1             0.0095      0.005      1.978      0.048    6.81e-05       0.019\n",
       "x2         -2.546e-05   4.65e-06     -5.479      0.000   -3.46e-05   -1.63e-05\n",
       "x3             0.0131      0.002      8.134      0.000       0.010       0.016\n",
       "x4            -0.0001   5.04e-05     -2.215      0.027      -0.000   -1.27e-05\n",
       "==============================================================================\n",
       "Omnibus:                      916.121   Durbin-Watson:                   1.753\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           157460.998\n",
       "Skew:                           6.926   Prob(JB):                         0.00\n",
       "Kurtosis:                      75.918   Cond. No.                     1.28e+18\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 2.03e-27. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt= X[:, [0,1,2,3,4]] \n",
    "regressor_OLS=sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary() \n",
    "#Run the three lines code and Look at the highest p-value again. First\n",
    "#dummy variable, x1's p-value is 0,940. Remove this one\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   26.26</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 14 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>4.42e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:17:33</td>     <th>  Log-Likelihood:    </th> <td>  1195.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   686</td>      <th>  AIC:               </th> <td>  -2382.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   682</td>      <th>  BIC:               </th> <td>  -2364.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0056</td> <td>    0.008</td> <td>    0.715</td> <td> 0.475</td> <td>   -0.010</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-2.035e-05</td> <td>  4.4e-06</td> <td>   -4.620</td> <td> 0.000</td> <td> -2.9e-05</td> <td>-1.17e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0112</td> <td>    0.002</td> <td>    7.365</td> <td> 0.000</td> <td>    0.008</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0001</td> <td>    0.000</td> <td>   -0.595</td> <td> 0.552</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>915.274</td> <th>  Durbin-Watson:     </th>  <td>   1.738</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>154013.629</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 6.924</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>75.086</td>  <th>  Cond. No.          </th>  <td>1.06e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.06e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.104\n",
       "Model:                            OLS   Adj. R-squared:                  0.100\n",
       "Method:                 Least Squares   F-statistic:                     26.26\n",
       "Date:                Wed, 14 Apr 2021   Prob (F-statistic):           4.42e-16\n",
       "Time:                        16:17:33   Log-Likelihood:                 1195.1\n",
       "No. Observations:                 686   AIC:                            -2382.\n",
       "Df Residuals:                     682   BIC:                            -2364.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0056      0.008      0.715      0.475      -0.010       0.021\n",
       "x1         -2.035e-05    4.4e-06     -4.620      0.000    -2.9e-05   -1.17e-05\n",
       "x2             0.0112      0.002      7.365      0.000       0.008       0.014\n",
       "x3            -0.0001      0.000     -0.595      0.552      -0.001       0.000\n",
       "==============================================================================\n",
       "Omnibus:                      915.274   Durbin-Watson:                   1.738\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           154013.629\n",
       "Skew:                           6.924   Prob(JB):                         0.00\n",
       "Kurtosis:                      75.086   Cond. No.                     1.06e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.06e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt= X[:, [0,2,3,5]] \n",
    "regressor_OLS=sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary() \n",
    "#Run the three lines code and Look at the highest p-value again. First\n",
    "#dummy variable, x1's p-value is 0,940. Remove this one\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   26.26</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 14 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>4.42e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:21:32</td>     <th>  Log-Likelihood:    </th> <td>  1195.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   686</td>      <th>  AIC:               </th> <td>  -2382.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   682</td>      <th>  BIC:               </th> <td>  -2364.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0028</td> <td>    0.004</td> <td>    0.715</td> <td> 0.475</td> <td>   -0.005</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0028</td> <td>    0.004</td> <td>    0.715</td> <td> 0.475</td> <td>   -0.005</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-2.035e-05</td> <td>  4.4e-06</td> <td>   -4.620</td> <td> 0.000</td> <td> -2.9e-05</td> <td>-1.17e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0112</td> <td>    0.002</td> <td>    7.365</td> <td> 0.000</td> <td>    0.008</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0001</td> <td>    0.000</td> <td>   -0.595</td> <td> 0.552</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>915.274</td> <th>  Durbin-Watson:     </th>  <td>   1.738</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>154013.629</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 6.924</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>75.086</td>  <th>  Cond. No.          </th>  <td>2.71e+20</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 4.48e-32. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.104\n",
       "Model:                            OLS   Adj. R-squared:                  0.100\n",
       "Method:                 Least Squares   F-statistic:                     26.26\n",
       "Date:                Wed, 14 Apr 2021   Prob (F-statistic):           4.42e-16\n",
       "Time:                        16:21:32   Log-Likelihood:                 1195.1\n",
       "No. Observations:                 686   AIC:                            -2382.\n",
       "Df Residuals:                     682   BIC:                            -2364.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0028      0.004      0.715      0.475      -0.005       0.010\n",
       "x1             0.0028      0.004      0.715      0.475      -0.005       0.010\n",
       "x2         -2.035e-05    4.4e-06     -4.620      0.000    -2.9e-05   -1.17e-05\n",
       "x3             0.0112      0.002      7.365      0.000       0.008       0.014\n",
       "x4            -0.0001      0.000     -0.595      0.552      -0.001       0.000\n",
       "==============================================================================\n",
       "Omnibus:                      915.274   Durbin-Watson:                   1.738\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           154013.629\n",
       "Skew:                           6.924   Prob(JB):                         0.00\n",
       "Kurtosis:                      75.086   Cond. No.                     2.71e+20\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 4.48e-32. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt= X[:, [0,1,2,3,5]] \n",
    "regressor_OLS=sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary() \n",
    "#Run the three lines code and Look at the highest p-value again. First\n",
    "#dummy variable, x1's p-value is 0,940. Remove this one\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple Linear Regression Model \n",
    "#We will on modelling how R&D, Administration and Marketing Spending and the state will\n",
    "#influence the profit of a company. There are 50 startups data in dataset.\n",
    "\n",
    "#1 Importing the libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#2 Importing the dataset: \n",
    "dataset = pd.read_csv(r'C:\\Users\\shubh\\Desktop\\IITM\\Courses\\Sem 2\\ML in civil eng\\term paper\\CE6051- vehicular emission data set - Sheet16.csv')\n",
    "#Y: dependent variable vector\n",
    "#In the first run X's type is object due to the different types of independent variables. \n",
    "#State column contains categorical variables\n",
    "X = dataset.iloc[1:,1:5].values\n",
    "y = dataset.iloc[1:,0:1].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     HC emissions (g/km)      fuel type  Age of vehicle  engine capacity (cc)  \\\n",
      "0                  0.000         Diesel           14.00                  2188   \n",
      "1                  0.000         Diesel           14.00                  2188   \n",
      "2                  0.001         Diesel           14.00                  1991   \n",
      "3                  0.008         Diesel           14.00                  1991   \n",
      "4                  0.008         Diesel           14.00                  1991   \n",
      "5                  0.009         Diesel           14.00                  1991   \n",
      "6                  0.010         Petrol           16.00                  2488   \n",
      "7                  0.010         Diesel           12.00                  2953   \n",
      "8                  0.010         Diesel           11.00                  2953   \n",
      "9                  0.011         Diesel           14.00                  1991   \n",
      "10                 0.015         Diesel           12.00                  1995   \n",
      "11                 0.016         Diesel           12.00                  1461   \n",
      "12                 0.016         Diesel           11.00                  1461   \n",
      "13                 0.016         Diesel           10.00                  1461   \n",
      "14                 0.018         Diesel            9.00                  1461   \n",
      "15                 0.018         Diesel            5.00                  1461   \n",
      "16                 0.018         Diesel            4.00                  1461   \n",
      "17                 0.018         Petrol           20.00                  1495   \n",
      "18                 0.018         Petrol           17.00                  1495   \n",
      "19                 0.018         Petrol           13.00                  1798   \n",
      "20                 0.019         Petrol           10.00                  3696   \n",
      "21                 0.019         Petrol            9.00                  3696   \n",
      "22                 0.019         Petrol            8.00                  3696   \n",
      "23                 0.019         Petrol            7.00                  3696   \n",
      "24                 0.019         Petrol            6.00                  3696   \n",
      "25                 0.019         Petrol            5.00                  3696   \n",
      "26                 0.019         Petrol            4.00                  3696   \n",
      "27                 0.019         Petrol            3.00                  3696   \n",
      "28                 0.019         Petrol            2.00                  3696   \n",
      "29                 0.019         Petrol           17.00                  1086   \n",
      "..                   ...            ...             ...                   ...   \n",
      "685                0.036  Petrol hybrid            2.25                  1798   \n",
      "686                0.036         Petrol            5.83                  1329   \n",
      "687                0.036         Petrol            5.83                  1598   \n",
      "688                0.036         Petrol            5.83                  1598   \n",
      "689                0.036         Petrol            5.83                  1598   \n",
      "690                0.036  Petrol hybrid            4.83                  1798   \n",
      "691                0.036  Petrol hybrid            4.83                  1798   \n",
      "692                0.037         Petrol            7.58                  1329   \n",
      "693                0.037  Petrol hybrid            2.25                  1798   \n",
      "694                0.037  Petrol hybrid            2.25                  1798   \n",
      "695                0.037         Petrol            5.83                  1329   \n",
      "696                0.038         Petrol            7.58                  1598   \n",
      "697                0.038         Petrol            5.83                  1598   \n",
      "698                0.039         Petrol            7.58                  1598   \n",
      "699                0.039         Petrol            5.83                  1598   \n",
      "700                0.040         Petrol           11.00                  1329   \n",
      "701                0.040         Petrol           11.00                  1329   \n",
      "702                0.041         Petrol            7.58                  1329   \n",
      "703                0.041  Petrol hybrid            2.25                  2494   \n",
      "704                0.041  Petrol hybrid            2.25                  2494   \n",
      "705                0.041         Petrol            5.83                  1329   \n",
      "706                0.041         Petrol            4.83                  1329   \n",
      "707                0.042         Petrol            2.25                  1987   \n",
      "708                0.042         Petrol            2.25                  1998   \n",
      "709                0.047         Petrol            2.25                  1798   \n",
      "710                0.047         Petrol            2.25                  1798   \n",
      "711                0.058  Petrol hybrid           11.00                  1798   \n",
      "712                0.058  Petrol hybrid           11.00                  1798   \n",
      "713                0.058  Petrol hybrid           11.00                  1798   \n",
      "714                0.080            LPG           17.00                  1769   \n",
      "\n",
      "     Fuel consumption (metric combined)  gearbox_4AT  gearbox_5MT  \\\n",
      "0                                   8.1            0            0   \n",
      "1                                   8.2            0            0   \n",
      "2                                   7.3            0            0   \n",
      "3                                   7.0            0            0   \n",
      "4                                   7.1            0            0   \n",
      "5                                   8.0            0            0   \n",
      "6                                   9.4            0            0   \n",
      "7                                  11.8            1            0   \n",
      "8                                  11.8            1            0   \n",
      "9                                   6.1            0            0   \n",
      "10                                  8.1            0            0   \n",
      "11                                  4.6            0            0   \n",
      "12                                  4.6            0            0   \n",
      "13                                  4.6            0            0   \n",
      "14                                  5.1            0            0   \n",
      "15                                  4.0            0            0   \n",
      "16                                  4.0            0            0   \n",
      "17                                  6.9            0            0   \n",
      "18                                  6.9            0            0   \n",
      "19                                  7.1            0            0   \n",
      "20                                 10.6            0            0   \n",
      "21                                 10.6            0            0   \n",
      "22                                 10.6            0            0   \n",
      "23                                 10.6            0            0   \n",
      "24                                 10.6            0            0   \n",
      "25                                 10.6            0            0   \n",
      "26                                 10.6            0            0   \n",
      "27                                 10.6            0            0   \n",
      "28                                 10.6            0            0   \n",
      "29                                  5.8            0            0   \n",
      "..                                  ...          ...          ...   \n",
      "685                                 3.6            0            0   \n",
      "686                                 5.4            0            0   \n",
      "687                                 5.8            0            0   \n",
      "688                                 5.8            0            0   \n",
      "689                                 5.7            0            0   \n",
      "690                                 3.5            0            0   \n",
      "691                                 3.6            0            0   \n",
      "692                                 5.6            0            0   \n",
      "693                                 3.6            0            0   \n",
      "694                                 3.9            0            0   \n",
      "695                                 5.6            0            0   \n",
      "696                                 6.2            0            0   \n",
      "697                                 6.2            0            0   \n",
      "698                                 6.1            0            0   \n",
      "699                                 6.1            0            0   \n",
      "700                                 5.8            0            0   \n",
      "701                                 5.8            0            0   \n",
      "702                                 5.5            0            0   \n",
      "703                                 4.9            0            0   \n",
      "704                                 5.0            0            0   \n",
      "705                                 5.5            0            0   \n",
      "706                                 5.5            0            0   \n",
      "707                                 6.5            0            0   \n",
      "708                                 6.5            0            0   \n",
      "709                                 6.5            0            0   \n",
      "710                                 6.6            0            0   \n",
      "711                                 3.9            0            0   \n",
      "712                                 4.0            0            0   \n",
      "713                                 3.9            0            0   \n",
      "714                                 9.5            0            1   \n",
      "\n",
      "     gearbox_6AT  gearbox_6MT  gearbox_A4     ...       gearbox_MULTI5  \\\n",
      "0              0            0           0     ...                    0   \n",
      "1              0            0           0     ...                    0   \n",
      "2              0            0           1     ...                    0   \n",
      "3              0            0           0     ...                    0   \n",
      "4              0            0           0     ...                    0   \n",
      "5              0            0           1     ...                    0   \n",
      "6              0            0           0     ...                    0   \n",
      "7              0            0           0     ...                    0   \n",
      "8              0            0           0     ...                    0   \n",
      "9              0            0           0     ...                    0   \n",
      "10             0            0           0     ...                    0   \n",
      "11             0            0           0     ...                    0   \n",
      "12             0            0           0     ...                    0   \n",
      "13             0            0           0     ...                    0   \n",
      "14             0            0           0     ...                    0   \n",
      "15             0            0           0     ...                    0   \n",
      "16             0            0           0     ...                    0   \n",
      "17             0            0           0     ...                    0   \n",
      "18             0            0           0     ...                    0   \n",
      "19             0            0           0     ...                    0   \n",
      "20             0            0           0     ...                    0   \n",
      "21             0            0           0     ...                    0   \n",
      "22             0            0           0     ...                    0   \n",
      "23             0            0           0     ...                    0   \n",
      "24             0            0           0     ...                    0   \n",
      "25             0            0           0     ...                    0   \n",
      "26             0            0           0     ...                    0   \n",
      "27             0            0           0     ...                    0   \n",
      "28             0            0           0     ...                    0   \n",
      "29             0            0           0     ...                    0   \n",
      "..           ...          ...         ...     ...                  ...   \n",
      "685            0            0           0     ...                    0   \n",
      "686            0            1           0     ...                    0   \n",
      "687            0            0           0     ...                    0   \n",
      "688            0            0           0     ...                    0   \n",
      "689            0            0           0     ...                    0   \n",
      "690            0            0           0     ...                    0   \n",
      "691            0            0           0     ...                    0   \n",
      "692            0            1           0     ...                    0   \n",
      "693            0            0           0     ...                    0   \n",
      "694            0            0           0     ...                    0   \n",
      "695            0            1           0     ...                    0   \n",
      "696            0            1           0     ...                    0   \n",
      "697            0            1           0     ...                    0   \n",
      "698            0            0           0     ...                    0   \n",
      "699            0            0           0     ...                    0   \n",
      "700            0            0           0     ...                    0   \n",
      "701            0            0           0     ...                    0   \n",
      "702            0            1           0     ...                    0   \n",
      "703            0            0           0     ...                    0   \n",
      "704            0            0           0     ...                    0   \n",
      "705            0            1           0     ...                    0   \n",
      "706            0            1           0     ...                    0   \n",
      "707            0            0           0     ...                    0   \n",
      "708            0            0           0     ...                    0   \n",
      "709            0            0           0     ...                    0   \n",
      "710            0            0           0     ...                    0   \n",
      "711            0            0           0     ...                    0   \n",
      "712            0            0           0     ...                    0   \n",
      "713            0            0           0     ...                    0   \n",
      "714            0            0           0     ...                    0   \n",
      "\n",
      "     gearbox_Multi5  gearbox_Multi6  gearbox_MultiDriv  gearbox_QA5  \\\n",
      "0                 0               0                  0            0   \n",
      "1                 0               0                  0            0   \n",
      "2                 0               0                  0            0   \n",
      "3                 0               0                  0            0   \n",
      "4                 0               0                  0            0   \n",
      "5                 0               0                  0            0   \n",
      "6                 0               0                  0            0   \n",
      "7                 0               0                  0            0   \n",
      "8                 0               0                  0            0   \n",
      "9                 0               0                  0            0   \n",
      "10                0               0                  0            0   \n",
      "11                0               0                  0            0   \n",
      "12                0               0                  0            0   \n",
      "13                0               0                  0            0   \n",
      "14                0               0                  0            0   \n",
      "15                0               0                  0            0   \n",
      "16                0               0                  0            0   \n",
      "17                0               0                  0            0   \n",
      "18                0               0                  0            0   \n",
      "19                0               0                  0            0   \n",
      "20                0               0                  0            0   \n",
      "21                0               0                  0            0   \n",
      "22                0               0                  0            0   \n",
      "23                0               0                  0            0   \n",
      "24                0               0                  0            0   \n",
      "25                0               0                  0            0   \n",
      "26                0               0                  0            0   \n",
      "27                0               0                  0            0   \n",
      "28                0               0                  0            0   \n",
      "29                0               0                  0            0   \n",
      "..              ...             ...                ...          ...   \n",
      "685               0               0                  0            0   \n",
      "686               0               0                  0            0   \n",
      "687               0               0                  0            0   \n",
      "688               0               0                  0            0   \n",
      "689               0               0                  0            0   \n",
      "690               0               0                  0            0   \n",
      "691               0               0                  0            0   \n",
      "692               0               0                  0            0   \n",
      "693               0               0                  0            0   \n",
      "694               0               0                  0            0   \n",
      "695               0               0                  0            0   \n",
      "696               0               0                  0            0   \n",
      "697               0               0                  0            0   \n",
      "698               0               0                  0            0   \n",
      "699               0               0                  0            0   \n",
      "700               0               0                  0            0   \n",
      "701               0               0                  0            0   \n",
      "702               0               0                  0            0   \n",
      "703               0               0                  0            0   \n",
      "704               0               0                  0            0   \n",
      "705               0               0                  0            0   \n",
      "706               0               0                  0            0   \n",
      "707               0               0                  0            0   \n",
      "708               0               0                  0            0   \n",
      "709               0               0                  1            0   \n",
      "710               0               0                  1            0   \n",
      "711               0               0                  0            0   \n",
      "712               0               0                  0            0   \n",
      "713               0               0                  0            0   \n",
      "714               0               0                  0            0   \n",
      "\n",
      "     gearbox_QA6  gearbox_QD6  gearbox_QD7  gearbox_QM5  gearbox_QM6  \n",
      "0              0            0            0            0            0  \n",
      "1              0            0            0            0            0  \n",
      "2              0            0            0            0            0  \n",
      "3              0            0            0            0            0  \n",
      "4              0            0            0            0            0  \n",
      "5              0            0            0            0            0  \n",
      "6              0            0            0            0            0  \n",
      "7              0            0            0            0            0  \n",
      "8              0            0            0            0            0  \n",
      "9              0            0            0            0            0  \n",
      "10             0            0            0            0            0  \n",
      "11             0            0            0            0            0  \n",
      "12             0            0            0            0            0  \n",
      "13             0            0            0            0            0  \n",
      "14             0            0            0            0            0  \n",
      "15             0            0            0            0            0  \n",
      "16             0            0            0            0            0  \n",
      "17             0            0            0            0            0  \n",
      "18             0            0            0            0            0  \n",
      "19             0            0            0            0            0  \n",
      "20             0            0            0            0            0  \n",
      "21             0            0            0            0            0  \n",
      "22             0            0            0            0            0  \n",
      "23             0            0            0            0            0  \n",
      "24             0            0            0            0            0  \n",
      "25             0            0            0            0            0  \n",
      "26             0            0            0            0            0  \n",
      "27             0            0            0            0            0  \n",
      "28             0            0            0            0            0  \n",
      "29             0            0            0            0            0  \n",
      "..           ...          ...          ...          ...          ...  \n",
      "685            0            0            0            0            0  \n",
      "686            0            0            0            0            0  \n",
      "687            0            0            0            0            0  \n",
      "688            0            0            0            0            0  \n",
      "689            0            0            0            0            0  \n",
      "690            0            0            0            0            0  \n",
      "691            0            0            0            0            0  \n",
      "692            0            0            0            0            0  \n",
      "693            0            0            0            0            0  \n",
      "694            0            0            0            0            0  \n",
      "695            0            0            0            0            0  \n",
      "696            0            0            0            0            0  \n",
      "697            0            0            0            0            0  \n",
      "698            0            0            0            0            0  \n",
      "699            0            0            0            0            0  \n",
      "700            0            0            0            0            0  \n",
      "701            0            0            0            0            0  \n",
      "702            0            0            0            0            0  \n",
      "703            0            0            0            0            0  \n",
      "704            0            0            0            0            0  \n",
      "705            0            0            0            0            0  \n",
      "706            0            0            0            0            0  \n",
      "707            0            0            0            0            0  \n",
      "708            0            0            0            0            0  \n",
      "709            0            0            0            0            0  \n",
      "710            0            0            0            0            0  \n",
      "711            0            0            0            0            0  \n",
      "712            0            0            0            0            0  \n",
      "713            0            0            0            0            0  \n",
      "714            0            0            0            0            0  \n",
      "\n",
      "[715 rows x 41 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HC emissions (g/km)</th>\n",
       "      <th>fuel type</th>\n",
       "      <th>Age of vehicle</th>\n",
       "      <th>engine capacity (cc)</th>\n",
       "      <th>Fuel consumption (metric combined)</th>\n",
       "      <th>gearbox_4AT</th>\n",
       "      <th>gearbox_5MT</th>\n",
       "      <th>gearbox_6AT</th>\n",
       "      <th>gearbox_6MT</th>\n",
       "      <th>gearbox_A4</th>\n",
       "      <th>...</th>\n",
       "      <th>gearbox_MULTI5</th>\n",
       "      <th>gearbox_Multi5</th>\n",
       "      <th>gearbox_Multi6</th>\n",
       "      <th>gearbox_MultiDriv</th>\n",
       "      <th>gearbox_QA5</th>\n",
       "      <th>gearbox_QA6</th>\n",
       "      <th>gearbox_QD6</th>\n",
       "      <th>gearbox_QD7</th>\n",
       "      <th>gearbox_QM5</th>\n",
       "      <th>gearbox_QM6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2188</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2188</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1991</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HC emissions (g/km) fuel type  Age of vehicle  engine capacity (cc)  \\\n",
       "0                0.000    Diesel            14.0                  2188   \n",
       "1                0.000    Diesel            14.0                  2188   \n",
       "2                0.001    Diesel            14.0                  1991   \n",
       "\n",
       "   Fuel consumption (metric combined)  gearbox_4AT  gearbox_5MT  gearbox_6AT  \\\n",
       "0                                 8.1            0            0            0   \n",
       "1                                 8.2            0            0            0   \n",
       "2                                 7.3            0            0            0   \n",
       "\n",
       "   gearbox_6MT  gearbox_A4     ...       gearbox_MULTI5  gearbox_Multi5  \\\n",
       "0            0           0     ...                    0               0   \n",
       "1            0           0     ...                    0               0   \n",
       "2            0           1     ...                    0               0   \n",
       "\n",
       "   gearbox_Multi6  gearbox_MultiDriv  gearbox_QA5  gearbox_QA6  gearbox_QD6  \\\n",
       "0               0                  0            0            0            0   \n",
       "1               0                  0            0            0            0   \n",
       "2               0                  0            0            0            0   \n",
       "\n",
       "   gearbox_QD7  gearbox_QM5  gearbox_QM6  \n",
       "0            0            0            0  \n",
       "1            0            0            0  \n",
       "2            0            0            0  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3 Encoding the categorical variables: \n",
    "#from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "#labelencoder_X = LabelEncoder() #Change the text into numbers 0,1,2\n",
    "\n",
    "dataset=pd.get_dummies(dataset, columns=['gearbox'],prefix=['gearbox'])\n",
    "print(dataset)\n",
    "dataset.head(3)\n",
    "#onehotencoder= OneHotEncoder(categorical_features=[3])\n",
    "#turn the numbers to dummy variables. Each column represents one state\n",
    "#Compare the X and dataset tables to understand the relationship between the state and the columns \n",
    "#X= onehotencoder.fit_transform(X).toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     HC emissions (g/km)  Age of vehicle  engine capacity (cc)  \\\n",
      "0                  0.000           14.00                  2188   \n",
      "1                  0.000           14.00                  2188   \n",
      "2                  0.001           14.00                  1991   \n",
      "3                  0.008           14.00                  1991   \n",
      "4                  0.008           14.00                  1991   \n",
      "5                  0.009           14.00                  1991   \n",
      "6                  0.010           16.00                  2488   \n",
      "7                  0.010           12.00                  2953   \n",
      "8                  0.010           11.00                  2953   \n",
      "9                  0.011           14.00                  1991   \n",
      "10                 0.015           12.00                  1995   \n",
      "11                 0.016           12.00                  1461   \n",
      "12                 0.016           11.00                  1461   \n",
      "13                 0.016           10.00                  1461   \n",
      "14                 0.018            9.00                  1461   \n",
      "15                 0.018            5.00                  1461   \n",
      "16                 0.018            4.00                  1461   \n",
      "17                 0.018           20.00                  1495   \n",
      "18                 0.018           17.00                  1495   \n",
      "19                 0.018           13.00                  1798   \n",
      "20                 0.019           10.00                  3696   \n",
      "21                 0.019            9.00                  3696   \n",
      "22                 0.019            8.00                  3696   \n",
      "23                 0.019            7.00                  3696   \n",
      "24                 0.019            6.00                  3696   \n",
      "25                 0.019            5.00                  3696   \n",
      "26                 0.019            4.00                  3696   \n",
      "27                 0.019            3.00                  3696   \n",
      "28                 0.019            2.00                  3696   \n",
      "29                 0.019           17.00                  1086   \n",
      "..                   ...             ...                   ...   \n",
      "685                0.036            2.25                  1798   \n",
      "686                0.036            5.83                  1329   \n",
      "687                0.036            5.83                  1598   \n",
      "688                0.036            5.83                  1598   \n",
      "689                0.036            5.83                  1598   \n",
      "690                0.036            4.83                  1798   \n",
      "691                0.036            4.83                  1798   \n",
      "692                0.037            7.58                  1329   \n",
      "693                0.037            2.25                  1798   \n",
      "694                0.037            2.25                  1798   \n",
      "695                0.037            5.83                  1329   \n",
      "696                0.038            7.58                  1598   \n",
      "697                0.038            5.83                  1598   \n",
      "698                0.039            7.58                  1598   \n",
      "699                0.039            5.83                  1598   \n",
      "700                0.040           11.00                  1329   \n",
      "701                0.040           11.00                  1329   \n",
      "702                0.041            7.58                  1329   \n",
      "703                0.041            2.25                  2494   \n",
      "704                0.041            2.25                  2494   \n",
      "705                0.041            5.83                  1329   \n",
      "706                0.041            4.83                  1329   \n",
      "707                0.042            2.25                  1987   \n",
      "708                0.042            2.25                  1998   \n",
      "709                0.047            2.25                  1798   \n",
      "710                0.047            2.25                  1798   \n",
      "711                0.058           11.00                  1798   \n",
      "712                0.058           11.00                  1798   \n",
      "713                0.058           11.00                  1798   \n",
      "714                0.080           17.00                  1769   \n",
      "\n",
      "     Fuel consumption (metric combined)  gearbox_4AT  gearbox_5MT  \\\n",
      "0                                   8.1            0            0   \n",
      "1                                   8.2            0            0   \n",
      "2                                   7.3            0            0   \n",
      "3                                   7.0            0            0   \n",
      "4                                   7.1            0            0   \n",
      "5                                   8.0            0            0   \n",
      "6                                   9.4            0            0   \n",
      "7                                  11.8            1            0   \n",
      "8                                  11.8            1            0   \n",
      "9                                   6.1            0            0   \n",
      "10                                  8.1            0            0   \n",
      "11                                  4.6            0            0   \n",
      "12                                  4.6            0            0   \n",
      "13                                  4.6            0            0   \n",
      "14                                  5.1            0            0   \n",
      "15                                  4.0            0            0   \n",
      "16                                  4.0            0            0   \n",
      "17                                  6.9            0            0   \n",
      "18                                  6.9            0            0   \n",
      "19                                  7.1            0            0   \n",
      "20                                 10.6            0            0   \n",
      "21                                 10.6            0            0   \n",
      "22                                 10.6            0            0   \n",
      "23                                 10.6            0            0   \n",
      "24                                 10.6            0            0   \n",
      "25                                 10.6            0            0   \n",
      "26                                 10.6            0            0   \n",
      "27                                 10.6            0            0   \n",
      "28                                 10.6            0            0   \n",
      "29                                  5.8            0            0   \n",
      "..                                  ...          ...          ...   \n",
      "685                                 3.6            0            0   \n",
      "686                                 5.4            0            0   \n",
      "687                                 5.8            0            0   \n",
      "688                                 5.8            0            0   \n",
      "689                                 5.7            0            0   \n",
      "690                                 3.5            0            0   \n",
      "691                                 3.6            0            0   \n",
      "692                                 5.6            0            0   \n",
      "693                                 3.6            0            0   \n",
      "694                                 3.9            0            0   \n",
      "695                                 5.6            0            0   \n",
      "696                                 6.2            0            0   \n",
      "697                                 6.2            0            0   \n",
      "698                                 6.1            0            0   \n",
      "699                                 6.1            0            0   \n",
      "700                                 5.8            0            0   \n",
      "701                                 5.8            0            0   \n",
      "702                                 5.5            0            0   \n",
      "703                                 4.9            0            0   \n",
      "704                                 5.0            0            0   \n",
      "705                                 5.5            0            0   \n",
      "706                                 5.5            0            0   \n",
      "707                                 6.5            0            0   \n",
      "708                                 6.5            0            0   \n",
      "709                                 6.5            0            0   \n",
      "710                                 6.6            0            0   \n",
      "711                                 3.9            0            0   \n",
      "712                                 4.0            0            0   \n",
      "713                                 3.9            0            0   \n",
      "714                                 9.5            0            1   \n",
      "\n",
      "     gearbox_6AT  gearbox_6MT  gearbox_A4  gearbox_A4*2  \\\n",
      "0              0            0           0             0   \n",
      "1              0            0           0             0   \n",
      "2              0            0           1             0   \n",
      "3              0            0           0             0   \n",
      "4              0            0           0             0   \n",
      "5              0            0           1             0   \n",
      "6              0            0           0             0   \n",
      "7              0            0           0             0   \n",
      "8              0            0           0             0   \n",
      "9              0            0           0             0   \n",
      "10             0            0           0             0   \n",
      "11             0            0           0             0   \n",
      "12             0            0           0             0   \n",
      "13             0            0           0             0   \n",
      "14             0            0           0             0   \n",
      "15             0            0           0             0   \n",
      "16             0            0           0             0   \n",
      "17             0            0           0             0   \n",
      "18             0            0           0             0   \n",
      "19             0            0           0             0   \n",
      "20             0            0           0             0   \n",
      "21             0            0           0             0   \n",
      "22             0            0           0             0   \n",
      "23             0            0           0             0   \n",
      "24             0            0           0             0   \n",
      "25             0            0           0             0   \n",
      "26             0            0           0             0   \n",
      "27             0            0           0             0   \n",
      "28             0            0           0             0   \n",
      "29             0            0           0             0   \n",
      "..           ...          ...         ...           ...   \n",
      "685            0            0           0             0   \n",
      "686            0            1           0             0   \n",
      "687            0            0           0             0   \n",
      "688            0            0           0             0   \n",
      "689            0            0           0             0   \n",
      "690            0            0           0             0   \n",
      "691            0            0           0             0   \n",
      "692            0            1           0             0   \n",
      "693            0            0           0             0   \n",
      "694            0            0           0             0   \n",
      "695            0            1           0             0   \n",
      "696            0            1           0             0   \n",
      "697            0            1           0             0   \n",
      "698            0            0           0             0   \n",
      "699            0            0           0             0   \n",
      "700            0            0           0             0   \n",
      "701            0            0           0             0   \n",
      "702            0            1           0             0   \n",
      "703            0            0           0             0   \n",
      "704            0            0           0             0   \n",
      "705            0            1           0             0   \n",
      "706            0            1           0             0   \n",
      "707            0            0           0             0   \n",
      "708            0            0           0             0   \n",
      "709            0            0           0             0   \n",
      "710            0            0           0             0   \n",
      "711            0            0           0             0   \n",
      "712            0            0           0             0   \n",
      "713            0            0           0             0   \n",
      "714            0            0           0             0   \n",
      "\n",
      "              ...            gearbox_QA5  gearbox_QA6  gearbox_QD6  \\\n",
      "0             ...                      0            0            0   \n",
      "1             ...                      0            0            0   \n",
      "2             ...                      0            0            0   \n",
      "3             ...                      0            0            0   \n",
      "4             ...                      0            0            0   \n",
      "5             ...                      0            0            0   \n",
      "6             ...                      0            0            0   \n",
      "7             ...                      0            0            0   \n",
      "8             ...                      0            0            0   \n",
      "9             ...                      0            0            0   \n",
      "10            ...                      0            0            0   \n",
      "11            ...                      0            0            0   \n",
      "12            ...                      0            0            0   \n",
      "13            ...                      0            0            0   \n",
      "14            ...                      0            0            0   \n",
      "15            ...                      0            0            0   \n",
      "16            ...                      0            0            0   \n",
      "17            ...                      0            0            0   \n",
      "18            ...                      0            0            0   \n",
      "19            ...                      0            0            0   \n",
      "20            ...                      0            0            0   \n",
      "21            ...                      0            0            0   \n",
      "22            ...                      0            0            0   \n",
      "23            ...                      0            0            0   \n",
      "24            ...                      0            0            0   \n",
      "25            ...                      0            0            0   \n",
      "26            ...                      0            0            0   \n",
      "27            ...                      0            0            0   \n",
      "28            ...                      0            0            0   \n",
      "29            ...                      0            0            0   \n",
      "..            ...                    ...          ...          ...   \n",
      "685           ...                      0            0            0   \n",
      "686           ...                      0            0            0   \n",
      "687           ...                      0            0            0   \n",
      "688           ...                      0            0            0   \n",
      "689           ...                      0            0            0   \n",
      "690           ...                      0            0            0   \n",
      "691           ...                      0            0            0   \n",
      "692           ...                      0            0            0   \n",
      "693           ...                      0            0            0   \n",
      "694           ...                      0            0            0   \n",
      "695           ...                      0            0            0   \n",
      "696           ...                      0            0            0   \n",
      "697           ...                      0            0            0   \n",
      "698           ...                      0            0            0   \n",
      "699           ...                      0            0            0   \n",
      "700           ...                      0            0            0   \n",
      "701           ...                      0            0            0   \n",
      "702           ...                      0            0            0   \n",
      "703           ...                      0            0            0   \n",
      "704           ...                      0            0            0   \n",
      "705           ...                      0            0            0   \n",
      "706           ...                      0            0            0   \n",
      "707           ...                      0            0            0   \n",
      "708           ...                      0            0            0   \n",
      "709           ...                      0            0            0   \n",
      "710           ...                      0            0            0   \n",
      "711           ...                      0            0            0   \n",
      "712           ...                      0            0            0   \n",
      "713           ...                      0            0            0   \n",
      "714           ...                      0            0            0   \n",
      "\n",
      "     gearbox_QD7  gearbox_QM5  gearbox_QM6  fueltype_Diesel  fueltype_LPG  \\\n",
      "0              0            0            0                1             0   \n",
      "1              0            0            0                1             0   \n",
      "2              0            0            0                1             0   \n",
      "3              0            0            0                1             0   \n",
      "4              0            0            0                1             0   \n",
      "5              0            0            0                1             0   \n",
      "6              0            0            0                0             0   \n",
      "7              0            0            0                1             0   \n",
      "8              0            0            0                1             0   \n",
      "9              0            0            0                1             0   \n",
      "10             0            0            0                1             0   \n",
      "11             0            0            0                1             0   \n",
      "12             0            0            0                1             0   \n",
      "13             0            0            0                1             0   \n",
      "14             0            0            0                1             0   \n",
      "15             0            0            0                1             0   \n",
      "16             0            0            0                1             0   \n",
      "17             0            0            0                0             0   \n",
      "18             0            0            0                0             0   \n",
      "19             0            0            0                0             0   \n",
      "20             0            0            0                0             0   \n",
      "21             0            0            0                0             0   \n",
      "22             0            0            0                0             0   \n",
      "23             0            0            0                0             0   \n",
      "24             0            0            0                0             0   \n",
      "25             0            0            0                0             0   \n",
      "26             0            0            0                0             0   \n",
      "27             0            0            0                0             0   \n",
      "28             0            0            0                0             0   \n",
      "29             0            0            0                0             0   \n",
      "..           ...          ...          ...              ...           ...   \n",
      "685            0            0            0                0             0   \n",
      "686            0            0            0                0             0   \n",
      "687            0            0            0                0             0   \n",
      "688            0            0            0                0             0   \n",
      "689            0            0            0                0             0   \n",
      "690            0            0            0                0             0   \n",
      "691            0            0            0                0             0   \n",
      "692            0            0            0                0             0   \n",
      "693            0            0            0                0             0   \n",
      "694            0            0            0                0             0   \n",
      "695            0            0            0                0             0   \n",
      "696            0            0            0                0             0   \n",
      "697            0            0            0                0             0   \n",
      "698            0            0            0                0             0   \n",
      "699            0            0            0                0             0   \n",
      "700            0            0            0                0             0   \n",
      "701            0            0            0                0             0   \n",
      "702            0            0            0                0             0   \n",
      "703            0            0            0                0             0   \n",
      "704            0            0            0                0             0   \n",
      "705            0            0            0                0             0   \n",
      "706            0            0            0                0             0   \n",
      "707            0            0            0                0             0   \n",
      "708            0            0            0                0             0   \n",
      "709            0            0            0                0             0   \n",
      "710            0            0            0                0             0   \n",
      "711            0            0            0                0             0   \n",
      "712            0            0            0                0             0   \n",
      "713            0            0            0                0             0   \n",
      "714            0            0            0                0             1   \n",
      "\n",
      "     fueltype_Petrol  fueltype_Petrol hybrid  \n",
      "0                  0                       0  \n",
      "1                  0                       0  \n",
      "2                  0                       0  \n",
      "3                  0                       0  \n",
      "4                  0                       0  \n",
      "5                  0                       0  \n",
      "6                  1                       0  \n",
      "7                  0                       0  \n",
      "8                  0                       0  \n",
      "9                  0                       0  \n",
      "10                 0                       0  \n",
      "11                 0                       0  \n",
      "12                 0                       0  \n",
      "13                 0                       0  \n",
      "14                 0                       0  \n",
      "15                 0                       0  \n",
      "16                 0                       0  \n",
      "17                 1                       0  \n",
      "18                 1                       0  \n",
      "19                 1                       0  \n",
      "20                 1                       0  \n",
      "21                 1                       0  \n",
      "22                 1                       0  \n",
      "23                 1                       0  \n",
      "24                 1                       0  \n",
      "25                 1                       0  \n",
      "26                 1                       0  \n",
      "27                 1                       0  \n",
      "28                 1                       0  \n",
      "29                 1                       0  \n",
      "..               ...                     ...  \n",
      "685                0                       1  \n",
      "686                1                       0  \n",
      "687                1                       0  \n",
      "688                1                       0  \n",
      "689                1                       0  \n",
      "690                0                       1  \n",
      "691                0                       1  \n",
      "692                1                       0  \n",
      "693                0                       1  \n",
      "694                0                       1  \n",
      "695                1                       0  \n",
      "696                1                       0  \n",
      "697                1                       0  \n",
      "698                1                       0  \n",
      "699                1                       0  \n",
      "700                1                       0  \n",
      "701                1                       0  \n",
      "702                1                       0  \n",
      "703                0                       1  \n",
      "704                0                       1  \n",
      "705                1                       0  \n",
      "706                1                       0  \n",
      "707                1                       0  \n",
      "708                1                       0  \n",
      "709                1                       0  \n",
      "710                1                       0  \n",
      "711                0                       1  \n",
      "712                0                       1  \n",
      "713                0                       1  \n",
      "714                0                       0  \n",
      "\n",
      "[715 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset=pd.get_dummies(dataset, columns=['fuel type'],prefix=['fueltype'])\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HC emissions (g/km)', 'Age of vehicle', 'engine capacity (cc)',\n",
       "       'Fuel consumption (metric combined)', 'gearbox_4AT', 'gearbox_5MT',\n",
       "       'gearbox_6AT', 'gearbox_6MT', 'gearbox_A4', 'gearbox_A4*2',\n",
       "       'gearbox_A5', 'gearbox_A5*2', 'gearbox_A6', 'gearbox_A6-AWD',\n",
       "       'gearbox_A6x2', 'gearbox_A7', 'gearbox_A8', 'gearbox_AT', 'gearbox_AV',\n",
       "       'gearbox_CVT', 'gearbox_D6', 'gearbox_D7', 'gearbox_E-CVT',\n",
       "       'gearbox_M5', 'gearbox_M6', 'gearbox_M6x2', 'gearbox_MCVT',\n",
       "       'gearbox_MT', 'gearbox_MULTI 5', 'gearbox_MULTI 5 ', 'gearbox_MULTI5',\n",
       "       'gearbox_Multi5', 'gearbox_Multi6', 'gearbox_MultiDriv', 'gearbox_QA5',\n",
       "       'gearbox_QA6', 'gearbox_QD6', 'gearbox_QD7', 'gearbox_QM5',\n",
       "       'gearbox_QM6', 'fueltype_Diesel', 'fueltype_LPG', 'fueltype_Petrol',\n",
       "       'fueltype_Petrol hybrid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HC emissions (g/km)</th>\n",
       "      <th>Age of vehicle</th>\n",
       "      <th>engine capacity (cc)</th>\n",
       "      <th>Fuel consumption (metric combined)</th>\n",
       "      <th>gearbox_4AT</th>\n",
       "      <th>gearbox_5MT</th>\n",
       "      <th>gearbox_6AT</th>\n",
       "      <th>gearbox_6MT</th>\n",
       "      <th>gearbox_A4</th>\n",
       "      <th>gearbox_A4*2</th>\n",
       "      <th>...</th>\n",
       "      <th>gearbox_QA5</th>\n",
       "      <th>gearbox_QA6</th>\n",
       "      <th>gearbox_QD6</th>\n",
       "      <th>gearbox_QD7</th>\n",
       "      <th>gearbox_QM5</th>\n",
       "      <th>gearbox_QM6</th>\n",
       "      <th>fueltype_Diesel</th>\n",
       "      <th>fueltype_LPG</th>\n",
       "      <th>fueltype_Petrol</th>\n",
       "      <th>fueltype_Petrol hybrid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2188</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HC emissions (g/km)  Age of vehicle  engine capacity (cc)  \\\n",
       "0                  0.0            14.0                  2188   \n",
       "\n",
       "   Fuel consumption (metric combined)  gearbox_4AT  gearbox_5MT  gearbox_6AT  \\\n",
       "0                                 8.1            0            0            0   \n",
       "\n",
       "   gearbox_6MT  gearbox_A4  gearbox_A4*2           ...            gearbox_QA5  \\\n",
       "0            0           0             0           ...                      0   \n",
       "\n",
       "   gearbox_QA6  gearbox_QD6  gearbox_QD7  gearbox_QM5  gearbox_QM6  \\\n",
       "0            0            0            0            0            0   \n",
       "\n",
       "   fueltype_Diesel  fueltype_LPG  fueltype_Petrol  fueltype_Petrol hybrid  \n",
       "0                1             0                0                       0  \n",
       "\n",
       "[1 rows x 44 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[1:,1:].values.astype(float)\n",
    "y = dataset.iloc[1:,0:1].values.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.10958576, 0.11027145, 0.11027145, 0.11027145, 0.11027145,\n",
       "       0.10474269, 0.11027145, 0.11027145, 0.11027145, 0.11027145,\n",
       "       0.11027145, 0.11026752, 0.10953279, 0.10965933, 0.11027145,\n",
       "       0.11027145, 0.11027145, 0.11027145, 0.11027145, 0.11027145,\n",
       "       0.11027145, 0.11027145, 0.10765401, 0.10969671, 0.11027145,\n",
       "       0.1097598 , 0.11027145, 0.10995426, 0.12254198, 0.11027145,\n",
       "       0.10524784, 0.11027145, 0.10959938, 0.11027145, 0.11027145,\n",
       "       0.11027145, 0.10773078, 0.10462838, 0.11027145, 0.11027145,\n",
       "       0.11026583, 0.11027145, 0.11027145, 0.11027145, 0.11027145,\n",
       "       0.11027145, 0.11027145, 0.11027145, 0.11027145, 0.11027145,\n",
       "       0.11027145, 0.15146112, 0.10956109, 0.11027145, 0.11027145,\n",
       "       0.10956439, 0.12147308, 0.11027145, 0.11027145, 0.11027145,\n",
       "       0.1096151 , 0.11027145, 0.11027145, 0.109887  , 0.11027145,\n",
       "       0.11027145, 0.11027145, 0.10948089, 0.11027145, 0.14343563,\n",
       "       0.11027145, 0.11027145, 0.11027145, 0.11027145, 0.10951918,\n",
       "       0.10948217, 0.10960896, 0.11027145, 0.11027145, 0.11027145,\n",
       "       0.11027145, 0.10420371, 0.11027145, 0.11027145, 0.11027145,\n",
       "       0.04696501, 0.11027145, 0.11027145, 0.10931033, 0.11027145,\n",
       "       0.1124192 , 0.11027145, 0.11027145, 0.11027145, 0.10983667,\n",
       "       0.11027145, 0.11027145, 0.11027145, 0.10929683, 0.11027145,\n",
       "       0.11027145, 0.11027145, 0.10939795, 0.11027145, 0.11027145,\n",
       "       0.11027145, 0.11027145, 0.11027145, 0.11027145, 0.11027145,\n",
       "       0.10885322, 0.11027145, 0.11027145, 0.10939306, 0.10503058,\n",
       "       0.11027145, 0.11027145, 0.11027145, 0.151955  , 0.11027145,\n",
       "       0.11027145, 0.11027145, 0.11027145, 0.11027145, 0.11027145,\n",
       "       0.11027145, 0.11027145, 0.11027145, 0.11027145, 0.10565022,\n",
       "       0.10892051, 0.11027145, 0.11027145, 0.11027145, 0.11027145,\n",
       "       0.11027145, 0.11027145, 0.11027145, 0.11027145, 0.10671321,\n",
       "       0.11027145, 0.10474269, 0.11027145])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4 Avoid the dummy variables trap\n",
    "#Delete the first column represent the California \n",
    "#X= X[:, 1:]\n",
    "\n",
    "#5 Splitting the dataset into the Training and Test dataset\n",
    "#train_set_split: Split arrays or matrices into random train and test subsets\n",
    "##random_state değeri sonuçların her seferinde aynı çıkmasını sağlamak için kullanılıyor.\n",
    "#%20 of the dataset to the test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "regressor = SVR(kernel='rbf')\n",
    "regressor.fit(X_train, y_train, sample_weight = None)\n",
    "\n",
    "\n",
    "#6 Fit multiple Linear Regression model to our Train set\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "#Create an object called regressor in the LinearRegression class...\n",
    "#regressor = LinearRegression()\n",
    "#Fit the linear regression model to the training set... We use the fit method\n",
    "#the arguments of the fit method will be training sets \n",
    "#regressor.fit(X_train,y_train)\n",
    "\n",
    "#7 Predicting the Test set results: \n",
    "y_pred= regressor.predict(X_test)\n",
    "y_pred\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6654269098503127"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, y_pred, color = 'black')\n",
    "plt.title('y_pred vs y_test')\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('y_pred')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.000e+00 1.400e+01 2.188e+03 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [1.000e+00 1.400e+01 1.991e+03 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [1.000e+00 1.400e+01 1.991e+03 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " ...\n",
      " [1.000e+00 1.100e+01 1.798e+03 ... 0.000e+00 0.000e+00 1.000e+00]\n",
      " [1.000e+00 1.100e+01 1.798e+03 ... 0.000e+00 0.000e+00 1.000e+00]\n",
      " [1.000e+00 1.700e+01 1.769e+03 ... 1.000e+00 0.000e+00 0.000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HC emissions (g/km)</th>\n",
       "      <th>Age of vehicle</th>\n",
       "      <th>engine capacity (cc)</th>\n",
       "      <th>Fuel consumption (metric combined)</th>\n",
       "      <th>gearbox_4AT</th>\n",
       "      <th>gearbox_5MT</th>\n",
       "      <th>gearbox_6AT</th>\n",
       "      <th>gearbox_6MT</th>\n",
       "      <th>gearbox_A4</th>\n",
       "      <th>gearbox_A4*2</th>\n",
       "      <th>...</th>\n",
       "      <th>gearbox_QA5</th>\n",
       "      <th>gearbox_QA6</th>\n",
       "      <th>gearbox_QD6</th>\n",
       "      <th>gearbox_QD7</th>\n",
       "      <th>gearbox_QM5</th>\n",
       "      <th>gearbox_QM6</th>\n",
       "      <th>fueltype_Diesel</th>\n",
       "      <th>fueltype_LPG</th>\n",
       "      <th>fueltype_Petrol</th>\n",
       "      <th>fueltype_Petrol hybrid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2188</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HC emissions (g/km)  Age of vehicle  engine capacity (cc)  \\\n",
       "0                  0.0            14.0                  2188   \n",
       "\n",
       "   Fuel consumption (metric combined)  gearbox_4AT  gearbox_5MT  gearbox_6AT  \\\n",
       "0                                 8.1            0            0            0   \n",
       "\n",
       "   gearbox_6MT  gearbox_A4  gearbox_A4*2           ...            gearbox_QA5  \\\n",
       "0            0           0             0           ...                      0   \n",
       "\n",
       "   gearbox_QA6  gearbox_QD6  gearbox_QD7  gearbox_QM5  gearbox_QM6  \\\n",
       "0            0            0            0            0            0   \n",
       "\n",
       "   fueltype_Diesel  fueltype_LPG  fueltype_Petrol  fueltype_Petrol hybrid  \n",
       "0                1             0                0                       0  \n",
       "\n",
       "[1 rows x 44 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "print(X)\n",
    "\n",
    "#5 Splitting the dataset into the Training and Test dataset\n",
    "#train_set_split: Split arrays or matrices into random train and test subsets\n",
    "##random_state değeri sonuçların her seferinde aynı çıkmasını sağlamak için kullanılıyor.\n",
    "#%20 of the dataset to the test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "dataset.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y_train,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.274</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 14 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>2.71e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:49:53</td>     <th>  Log-Likelihood:    </th> <td>  1154.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   571</td>      <th>  AIC:               </th> <td>  -2228.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   531</td>      <th>  BIC:               </th> <td>  -2054.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    39</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0183</td> <td>    0.010</td> <td>    1.865</td> <td> 0.063</td> <td>   -0.001</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0024</td> <td>    0.000</td> <td>    5.779</td> <td> 0.000</td> <td>    0.002</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td> 1.384e-06</td> <td> 3.02e-06</td> <td>    0.459</td> <td> 0.647</td> <td>-4.55e-06</td> <td> 7.31e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0002</td> <td>    0.000</td> <td>    0.496</td> <td> 0.620</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0218</td> <td>    0.017</td> <td>   -1.310</td> <td> 0.191</td> <td>   -0.055</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.0123</td> <td>    0.018</td> <td>   -0.700</td> <td> 0.485</td> <td>   -0.047</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.0102</td> <td>    0.017</td> <td>   -0.594</td> <td> 0.553</td> <td>   -0.044</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0050</td> <td>    0.010</td> <td>   -0.498</td> <td> 0.618</td> <td>   -0.025</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.0101</td> <td>    0.005</td> <td>   -1.849</td> <td> 0.065</td> <td>   -0.021</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.0575</td> <td>    0.033</td> <td>    1.756</td> <td> 0.080</td> <td>   -0.007</td> <td>    0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.0923</td> <td>    0.012</td> <td>    7.604</td> <td> 0.000</td> <td>    0.068</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.0616</td> <td>    0.020</td> <td>    3.118</td> <td> 0.002</td> <td>    0.023</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.0112</td> <td>    0.010</td> <td>   -1.083</td> <td> 0.279</td> <td>   -0.032</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.0072</td> <td>    0.020</td> <td>    0.363</td> <td> 0.717</td> <td>   -0.032</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.0041</td> <td>    0.015</td> <td>    0.282</td> <td> 0.778</td> <td>   -0.025</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -0.0194</td> <td>    0.013</td> <td>   -1.526</td> <td> 0.128</td> <td>   -0.044</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   -0.0055</td> <td>    0.033</td> <td>   -0.169</td> <td> 0.866</td> <td>   -0.069</td> <td>    0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.0228</td> <td>    0.019</td> <td>    1.191</td> <td> 0.234</td> <td>   -0.015</td> <td>    0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>   -0.0046</td> <td>    0.010</td> <td>   -0.443</td> <td> 0.658</td> <td>   -0.025</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.0027</td> <td>    0.007</td> <td>    0.399</td> <td> 0.690</td> <td>   -0.011</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>   -0.0024</td> <td>    0.019</td> <td>   -0.129</td> <td> 0.898</td> <td>   -0.040</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.0005</td> <td>    0.033</td> <td>    0.015</td> <td> 0.988</td> <td>   -0.064</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.0189</td> <td>    0.032</td> <td>    0.582</td> <td> 0.560</td> <td>   -0.045</td> <td>    0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>   -0.0166</td> <td>    0.005</td> <td>   -3.280</td> <td> 0.001</td> <td>   -0.027</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>   -0.0162</td> <td>    0.005</td> <td>   -3.061</td> <td> 0.002</td> <td>   -0.027</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>   -0.0191</td> <td>    0.033</td> <td>   -0.584</td> <td> 0.559</td> <td>   -0.083</td> <td>    0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>   -0.0101</td> <td>    0.033</td> <td>   -0.311</td> <td> 0.756</td> <td>   -0.074</td> <td>    0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>   -0.0110</td> <td>    0.008</td> <td>   -1.445</td> <td> 0.149</td> <td>   -0.026</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td> 2.156e-17</td> <td>    1e-17</td> <td>    2.148</td> <td> 0.032</td> <td> 1.85e-18</td> <td> 4.13e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>-5.695e-18</td> <td> 1.41e-17</td> <td>   -0.405</td> <td> 0.686</td> <td>-3.33e-17</td> <td> 2.19e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>   -0.0241</td> <td>    0.023</td> <td>   -1.031</td> <td> 0.303</td> <td>   -0.070</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>   -0.0140</td> <td>    0.023</td> <td>   -0.600</td> <td> 0.549</td> <td>   -0.060</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>    0.0009</td> <td>    0.023</td> <td>    0.038</td> <td> 0.969</td> <td>   -0.045</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>    0.0009</td> <td>    0.019</td> <td>    0.048</td> <td> 0.961</td> <td>   -0.037</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>   -0.0002</td> <td>    0.010</td> <td>   -0.022</td> <td> 0.982</td> <td>   -0.019</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>    0.0111</td> <td>    0.011</td> <td>    1.017</td> <td> 0.310</td> <td>   -0.010</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>   -0.0190</td> <td>    0.023</td> <td>   -0.815</td> <td> 0.415</td> <td>   -0.065</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>    0.0032</td> <td>    0.032</td> <td>    0.099</td> <td> 0.921</td> <td>   -0.061</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>   -0.0377</td> <td>    0.023</td> <td>   -1.618</td> <td> 0.106</td> <td>   -0.083</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>    0.0053</td> <td>    0.012</td> <td>    0.458</td> <td> 0.647</td> <td>   -0.017</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>    0.0026</td> <td>    0.010</td> <td>    0.263</td> <td> 0.793</td> <td>   -0.017</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>    0.0317</td> <td>    0.022</td> <td>    1.470</td> <td> 0.142</td> <td>   -0.011</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>    0.0034</td> <td>    0.009</td> <td>    0.370</td> <td> 0.712</td> <td>   -0.015</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>   -0.0193</td> <td>    0.028</td> <td>   -0.694</td> <td> 0.488</td> <td>   -0.074</td> <td>    0.035</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>648.362</td> <th>  Durbin-Watson:     </th>  <td>   1.973</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>106906.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 4.967</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>69.293</td>  <th>  Cond. No.          </th>  <td>3.22e+18</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 2.62e-28. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.274\n",
       "Model:                            OLS   Adj. R-squared:                  0.221\n",
       "Method:                 Least Squares   F-statistic:                     5.143\n",
       "Date:                Wed, 14 Apr 2021   Prob (F-statistic):           2.71e-19\n",
       "Time:                        17:49:53   Log-Likelihood:                 1154.2\n",
       "No. Observations:                 571   AIC:                            -2228.\n",
       "Df Residuals:                     531   BIC:                            -2054.\n",
       "Df Model:                          39                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0183      0.010      1.865      0.063      -0.001       0.038\n",
       "x1             0.0024      0.000      5.779      0.000       0.002       0.003\n",
       "x2          1.384e-06   3.02e-06      0.459      0.647   -4.55e-06    7.31e-06\n",
       "x3             0.0002      0.000      0.496      0.620      -0.001       0.001\n",
       "x4            -0.0218      0.017     -1.310      0.191      -0.055       0.011\n",
       "x5            -0.0123      0.018     -0.700      0.485      -0.047       0.022\n",
       "x6            -0.0102      0.017     -0.594      0.553      -0.044       0.023\n",
       "x7            -0.0050      0.010     -0.498      0.618      -0.025       0.015\n",
       "x8            -0.0101      0.005     -1.849      0.065      -0.021       0.001\n",
       "x9             0.0575      0.033      1.756      0.080      -0.007       0.122\n",
       "x10            0.0923      0.012      7.604      0.000       0.068       0.116\n",
       "x11            0.0616      0.020      3.118      0.002       0.023       0.100\n",
       "x12           -0.0112      0.010     -1.083      0.279      -0.032       0.009\n",
       "x13            0.0072      0.020      0.363      0.717      -0.032       0.046\n",
       "x14            0.0041      0.015      0.282      0.778      -0.025       0.033\n",
       "x15           -0.0194      0.013     -1.526      0.128      -0.044       0.006\n",
       "x16           -0.0055      0.033     -0.169      0.866      -0.069       0.058\n",
       "x17            0.0228      0.019      1.191      0.234      -0.015       0.060\n",
       "x18           -0.0046      0.010     -0.443      0.658      -0.025       0.016\n",
       "x19            0.0027      0.007      0.399      0.690      -0.011       0.016\n",
       "x20           -0.0024      0.019     -0.129      0.898      -0.040       0.035\n",
       "x21            0.0005      0.033      0.015      0.988      -0.064       0.065\n",
       "x22            0.0189      0.032      0.582      0.560      -0.045       0.083\n",
       "x23           -0.0166      0.005     -3.280      0.001      -0.027      -0.007\n",
       "x24           -0.0162      0.005     -3.061      0.002      -0.027      -0.006\n",
       "x25           -0.0191      0.033     -0.584      0.559      -0.083       0.045\n",
       "x26           -0.0101      0.033     -0.311      0.756      -0.074       0.054\n",
       "x27           -0.0110      0.008     -1.445      0.149      -0.026       0.004\n",
       "x28         2.156e-17      1e-17      2.148      0.032    1.85e-18    4.13e-17\n",
       "x29        -5.695e-18   1.41e-17     -0.405      0.686   -3.33e-17    2.19e-17\n",
       "x30           -0.0241      0.023     -1.031      0.303      -0.070       0.022\n",
       "x31           -0.0140      0.023     -0.600      0.549      -0.060       0.032\n",
       "x32            0.0009      0.023      0.038      0.969      -0.045       0.047\n",
       "x33            0.0009      0.019      0.048      0.961      -0.037       0.039\n",
       "x34           -0.0002      0.010     -0.022      0.982      -0.019       0.019\n",
       "x35            0.0111      0.011      1.017      0.310      -0.010       0.032\n",
       "x36           -0.0190      0.023     -0.815      0.415      -0.065       0.027\n",
       "x37            0.0032      0.032      0.099      0.921      -0.061       0.067\n",
       "x38           -0.0377      0.023     -1.618      0.106      -0.083       0.008\n",
       "x39            0.0053      0.012      0.458      0.647      -0.017       0.028\n",
       "x40            0.0026      0.010      0.263      0.793      -0.017       0.022\n",
       "x41            0.0317      0.022      1.470      0.142      -0.011       0.074\n",
       "x42            0.0034      0.009      0.370      0.712      -0.015       0.022\n",
       "x43           -0.0193      0.028     -0.694      0.488      -0.074       0.035\n",
       "==============================================================================\n",
       "Omnibus:                      648.362   Durbin-Watson:                   1.973\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           106906.212\n",
       "Skew:                           4.967   Prob(JB):                         0.00\n",
       "Kurtosis:                      69.293   Cond. No.                     3.22e+18\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 2.62e-28. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 14 Apr 2021</td> <th>  Prob (F-statistic):</th> <td>2.37e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:53:03</td>     <th>  Log-Likelihood:    </th> <td>  1309.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   714</td>      <th>  AIC:               </th> <td>  -2535.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   672</td>      <th>  BIC:               </th> <td>  -2343.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    41</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>  <td>    0.0023</td> <td>    0.000</td> <td>    5.212</td> <td> 0.000</td> <td>    0.001</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>  <td> 4.192e-07</td> <td> 3.16e-06</td> <td>    0.133</td> <td> 0.895</td> <td>-5.79e-06</td> <td> 6.63e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>  <td>    0.0004</td> <td>    0.001</td> <td>    0.755</td> <td> 0.451</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>  <td>   -0.0201</td> <td>    0.020</td> <td>   -1.006</td> <td> 0.315</td> <td>   -0.059</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>  <td>   -0.0079</td> <td>    0.016</td> <td>   -0.504</td> <td> 0.615</td> <td>   -0.039</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>  <td>   -0.0094</td> <td>    0.020</td> <td>   -0.463</td> <td> 0.644</td> <td>   -0.049</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>  <td>   -0.0041</td> <td>    0.012</td> <td>   -0.350</td> <td> 0.727</td> <td>   -0.027</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>  <td>   -0.0078</td> <td>    0.006</td> <td>   -1.281</td> <td> 0.201</td> <td>   -0.020</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>  <td>    0.0603</td> <td>    0.039</td> <td>    1.529</td> <td> 0.127</td> <td>   -0.017</td> <td>    0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th> <td>    0.0699</td> <td>    0.013</td> <td>    5.284</td> <td> 0.000</td> <td>    0.044</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th> <td>    0.0644</td> <td>    0.024</td> <td>    2.720</td> <td> 0.007</td> <td>    0.018</td> <td>    0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th> <td>   -0.0098</td> <td>    0.012</td> <td>   -0.851</td> <td> 0.395</td> <td>   -0.033</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th> <td>    0.0091</td> <td>    0.024</td> <td>    0.387</td> <td> 0.699</td> <td>   -0.037</td> <td>    0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th> <td>    0.0026</td> <td>    0.016</td> <td>    0.161</td> <td> 0.872</td> <td>   -0.029</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th> <td>   -0.0158</td> <td>    0.014</td> <td>   -1.135</td> <td> 0.257</td> <td>   -0.043</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th> <td>   -0.0033</td> <td>    0.039</td> <td>   -0.085</td> <td> 0.933</td> <td>   -0.080</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th> <td>    0.0648</td> <td>    0.012</td> <td>    5.267</td> <td> 0.000</td> <td>    0.041</td> <td>    0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th> <td>   -0.0026</td> <td>    0.013</td> <td>   -0.203</td> <td> 0.839</td> <td>   -0.027</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th> <td>    0.0070</td> <td>    0.007</td> <td>    0.949</td> <td> 0.343</td> <td>   -0.007</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th> <td>   -0.0108</td> <td>    0.018</td> <td>   -0.605</td> <td> 0.545</td> <td>   -0.046</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th> <td>    0.0018</td> <td>    0.039</td> <td>    0.045</td> <td> 0.964</td> <td>   -0.075</td> <td>    0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th> <td>    0.0212</td> <td>    0.038</td> <td>    0.556</td> <td> 0.579</td> <td>   -0.054</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th> <td>   -0.0139</td> <td>    0.005</td> <td>   -2.522</td> <td> 0.012</td> <td>   -0.025</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th> <td>   -0.0143</td> <td>    0.006</td> <td>   -2.460</td> <td> 0.014</td> <td>   -0.026</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th> <td>   -0.0176</td> <td>    0.039</td> <td>   -0.448</td> <td> 0.654</td> <td>   -0.095</td> <td>    0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th> <td>   -0.0078</td> <td>    0.039</td> <td>   -0.199</td> <td> 0.842</td> <td>   -0.085</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th> <td>   -0.0100</td> <td>    0.009</td> <td>   -1.146</td> <td> 0.252</td> <td>   -0.027</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th> <td>   -0.0181</td> <td>    0.028</td> <td>   -0.650</td> <td> 0.516</td> <td>   -0.073</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th> <td>   -0.0047</td> <td>    0.039</td> <td>   -0.121</td> <td> 0.904</td> <td>   -0.082</td> <td>    0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th> <td>   -0.0165</td> <td>    0.023</td> <td>   -0.715</td> <td> 0.475</td> <td>   -0.062</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th> <td>   -0.0128</td> <td>    0.028</td> <td>   -0.458</td> <td> 0.647</td> <td>   -0.068</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th> <td>    0.0022</td> <td>    0.028</td> <td>    0.081</td> <td> 0.936</td> <td>   -0.052</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th> <td>    0.0024</td> <td>    0.018</td> <td>    0.131</td> <td> 0.896</td> <td>   -0.033</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th> <td>    0.0285</td> <td>    0.011</td> <td>    2.515</td> <td> 0.012</td> <td>    0.006</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th> <td>    0.0114</td> <td>    0.012</td> <td>    0.928</td> <td> 0.354</td> <td>   -0.013</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th> <td>   -0.0164</td> <td>    0.028</td> <td>   -0.585</td> <td> 0.559</td> <td>   -0.072</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th> <td>    0.0047</td> <td>    0.039</td> <td>    0.121</td> <td> 0.904</td> <td>   -0.072</td> <td>    0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th> <td>   -0.0356</td> <td>    0.028</td> <td>   -1.271</td> <td> 0.204</td> <td>   -0.091</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th> <td>   -0.0022</td> <td>    0.011</td> <td>   -0.193</td> <td> 0.847</td> <td>   -0.024</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th> <td>    0.0208</td> <td>    0.010</td> <td>    2.116</td> <td> 0.035</td> <td>    0.002</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th> <td>    0.0476</td> <td>    0.030</td> <td>    1.590</td> <td> 0.112</td> <td>   -0.011</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th> <td>    0.0216</td> <td>    0.009</td> <td>    2.428</td> <td> 0.015</td> <td>    0.004</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th> <td>   -0.0012</td> <td>    0.039</td> <td>   -0.031</td> <td> 0.975</td> <td>   -0.078</td> <td>    0.076</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>872.042</td> <th>  Durbin-Watson:     </th>  <td>   0.558</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>116180.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 5.972</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>64.340</td>  <th>  Cond. No.          </th>  <td>3.80e+19</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 2.34e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.229\n",
       "Model:                            OLS   Adj. R-squared:                  0.182\n",
       "Method:                 Least Squares   F-statistic:                     4.880\n",
       "Date:                Wed, 14 Apr 2021   Prob (F-statistic):           2.37e-19\n",
       "Time:                        17:53:03   Log-Likelihood:                 1309.3\n",
       "No. Observations:                 714   AIC:                            -2535.\n",
       "Df Residuals:                     672   BIC:                            -2343.\n",
       "Df Model:                          41                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             0.0023      0.000      5.212      0.000       0.001       0.003\n",
       "x2          4.192e-07   3.16e-06      0.133      0.895   -5.79e-06    6.63e-06\n",
       "x3             0.0004      0.001      0.755      0.451      -0.001       0.001\n",
       "x4            -0.0201      0.020     -1.006      0.315      -0.059       0.019\n",
       "x5            -0.0079      0.016     -0.504      0.615      -0.039       0.023\n",
       "x6            -0.0094      0.020     -0.463      0.644      -0.049       0.030\n",
       "x7            -0.0041      0.012     -0.350      0.727      -0.027       0.019\n",
       "x8            -0.0078      0.006     -1.281      0.201      -0.020       0.004\n",
       "x9             0.0603      0.039      1.529      0.127      -0.017       0.138\n",
       "x10            0.0699      0.013      5.284      0.000       0.044       0.096\n",
       "x11            0.0644      0.024      2.720      0.007       0.018       0.111\n",
       "x12           -0.0098      0.012     -0.851      0.395      -0.033       0.013\n",
       "x13            0.0091      0.024      0.387      0.699      -0.037       0.055\n",
       "x14            0.0026      0.016      0.161      0.872      -0.029       0.034\n",
       "x15           -0.0158      0.014     -1.135      0.257      -0.043       0.012\n",
       "x16           -0.0033      0.039     -0.085      0.933      -0.080       0.074\n",
       "x17            0.0648      0.012      5.267      0.000       0.041       0.089\n",
       "x18           -0.0026      0.013     -0.203      0.839      -0.027       0.022\n",
       "x19            0.0070      0.007      0.949      0.343      -0.007       0.021\n",
       "x20           -0.0108      0.018     -0.605      0.545      -0.046       0.024\n",
       "x21            0.0018      0.039      0.045      0.964      -0.075       0.079\n",
       "x22            0.0212      0.038      0.556      0.579      -0.054       0.096\n",
       "x23           -0.0139      0.005     -2.522      0.012      -0.025      -0.003\n",
       "x24           -0.0143      0.006     -2.460      0.014      -0.026      -0.003\n",
       "x25           -0.0176      0.039     -0.448      0.654      -0.095       0.060\n",
       "x26           -0.0078      0.039     -0.199      0.842      -0.085       0.069\n",
       "x27           -0.0100      0.009     -1.146      0.252      -0.027       0.007\n",
       "x28           -0.0181      0.028     -0.650      0.516      -0.073       0.037\n",
       "x29           -0.0047      0.039     -0.121      0.904      -0.082       0.072\n",
       "x30           -0.0165      0.023     -0.715      0.475      -0.062       0.029\n",
       "x31           -0.0128      0.028     -0.458      0.647      -0.068       0.042\n",
       "x32            0.0022      0.028      0.081      0.936      -0.052       0.057\n",
       "x33            0.0024      0.018      0.131      0.896      -0.033       0.038\n",
       "x34            0.0285      0.011      2.515      0.012       0.006       0.051\n",
       "x35            0.0114      0.012      0.928      0.354      -0.013       0.036\n",
       "x36           -0.0164      0.028     -0.585      0.559      -0.072       0.039\n",
       "x37            0.0047      0.039      0.121      0.904      -0.072       0.081\n",
       "x38           -0.0356      0.028     -1.271      0.204      -0.091       0.019\n",
       "x39           -0.0022      0.011     -0.193      0.847      -0.024       0.020\n",
       "x40            0.0208      0.010      2.116      0.035       0.002       0.040\n",
       "x41            0.0476      0.030      1.590      0.112      -0.011       0.106\n",
       "x42            0.0216      0.009      2.428      0.015       0.004       0.039\n",
       "x43           -0.0012      0.039     -0.031      0.975      -0.078       0.076\n",
       "==============================================================================\n",
       "Omnibus:                      872.042   Durbin-Watson:                   0.558\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           116180.131\n",
       "Skew:                           5.972   Prob(JB):                         0.00\n",
       "Kurtosis:                      64.340   Cond. No.                     3.80e+19\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 2.34e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Building the optimal Model using Backward Elimination\"\"\" \n",
    "#The backwards elimination function will give us the optimal variables from our data,\n",
    "# Beta0 has x^0=1. Add a column of for the the first term of the MultiLinear Regression equation.\n",
    "import statsmodels.formula.api  as sm \n",
    "#The 0th column contains only 1 in each 352 rows \n",
    "#X= np.append(arr = np.ones((686,1)).astype(int), values = X, axis=1) \n",
    "X_opt= X[:,1:44] #Optimal X contains the highly impacted independent variables\n",
    "#OLS: Oridnary Least Square Class. endog is the dependent variable, exog is the number of observations\n",
    "regressor_OLS=sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary() \n",
    "\n",
    "#constant for Beta0, x1 and x2 are the dummy variables for state, x3 is R&D,\n",
    "#x4 is Administration, x5 is the marketing spends \n",
    "#Look at the highest p-values and remove it. In this condition x2(second \n",
    "#dummy variable has the highest one (0,990)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#2 Importing the dataset: \n",
    "dataset = pd.read_csv(r'C:\\Users\\shubh\\Desktop\\IITM\\Courses\\Sem 2\\ML in civil eng\\term paper\\vehicularemission_modified2.csv')\n",
    "#y: dependent variable vector\n",
    "#In the first run X's type is object due to the different types of independent variables. \n",
    "#State column contains categorical variables\n",
    "X = dataset.iloc[1:,1:6].values.astype(float)\n",
    "y = dataset.iloc[1:,6:7].values.astype(float)\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "print(X)\n",
    "\n",
    "\n",
    "#5 Splitting the dataset into the Training and Test dataset\n",
    "#train_set_split: Split arrays or matrices into random train and test subsets\n",
    "##random_state değeri sonuçların her seferinde aynı çıkmasını sağlamak için kullanılıyor.\n",
    "#%20 of the dataset to the test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=0)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
